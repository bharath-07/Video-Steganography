{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "mount_file_id": "1Vcp4SEpse1YXCnMdxEV2oO1VJFYkA7Or",
      "authorship_tag": "ABX9TyPZHxtS6MTlMC3ukFclUEqw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharath-07/Video-Steganography/blob/master/groie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyx2ctaom3Hh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fa78965b-4256-4da1-85f9-c2af86e6b894"
      },
      "source": [
        "! wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
        "! chmod +x Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
        "! bash ./Miniconda3-py37_4.8.2-Linux-x86_64.sh -b -f -p /usr/local\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "\n",
        "\n",
        "! conda install -c rdkit rdkit -y"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-09 04:14:33--  https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 85055499 (81M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-py37_4.8.2-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-py37_4.8 100%[===================>]  81.12M   227MB/s    in 0.4s    \n",
            "\n",
            "2020-09-09 04:14:33 (227 MB/s) - ‘Miniconda3-py37_4.8.2-Linux-x86_64.sh’ saved [85055499/85055499]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.3.0=py37_0\n",
            "    - ca-certificates==2020.1.1=0\n",
            "    - certifi==2019.11.28=py37_0\n",
            "    - cffi==1.14.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.8.2=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.2=he6710b0_0\n",
            "    - openssl==1.1.1d=h7b6447c_4\n",
            "    - pip==20.0.2=py37_1\n",
            "    - pycosat==0.6.3=py37h7b6447c_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.1.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.6=h0371630_2\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_1\n",
            "    - ruamel_yaml==0.15.87=py37h7b6447c_0\n",
            "    - setuptools==45.2.0=py37_0\n",
            "    - six==1.14.0=py37_0\n",
            "    - sqlite==3.31.1=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.42.1=py_0\n",
            "    - urllib3==1.25.8=py37_0\n",
            "    - wheel==0.34.2=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  asn1crypto         pkgs/main/linux-64::asn1crypto-1.3.0-py37_0\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.1.1-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2019.11.28-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.14.0-py37h2e261b9_0\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.8.2-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.0-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.8-py37h1ba5d50_0\n",
            "  idna               pkgs/main/linux-64::idna-2.8-py37_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hd88cf55_4\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_0\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1d-h7b6447c_4\n",
            "  pip                pkgs/main/linux-64::pip-20.0.2-py37_1\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h7b6447c_0\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py37_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.1.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.6-h0371630_2\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  requests           pkgs/main/linux-64::requests-2.22.0-py37_1\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py37h7b6447c_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-45.2.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.14.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.31.1-h7b6447c_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.42.1-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.25.8-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.34.2-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.4-h14c3975_4\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    blas-1.0                   |              mkl           6 KB\n",
            "    bzip2-1.0.8                |       h7b6447c_0          78 KB\n",
            "    ca-certificates-2020.7.22  |                0         125 KB\n",
            "    cairo-1.14.12              |       h8948797_3         906 KB\n",
            "    certifi-2020.6.20          |           py37_0         156 KB\n",
            "    conda-4.8.4                |           py37_0         2.9 MB\n",
            "    fontconfig-2.13.0          |       h9420a91_0         227 KB\n",
            "    freetype-2.10.2            |       h5ab3b9f_0         608 KB\n",
            "    glib-2.63.1                |       h5a9c865_0         2.9 MB\n",
            "    icu-58.2                   |       he6710b0_3        10.5 MB\n",
            "    intel-openmp-2020.2        |              254         786 KB\n",
            "    jpeg-9b                    |       h024ee3a_2         214 KB\n",
            "    libboost-1.67.0            |       h46d08c1_4        13.0 MB\n",
            "    libpng-1.6.37              |       hbc83047_0         278 KB\n",
            "    libtiff-4.1.0              |       h2733197_0         447 KB\n",
            "    libuuid-1.0.3              |       h1bed415_2          15 KB\n",
            "    libxcb-1.14                |       h7b6447c_0         505 KB\n",
            "    libxml2-2.9.9              |       hea5a465_1         1.6 MB\n",
            "    mkl-2020.2                 |              256       138.3 MB\n",
            "    mkl-service-2.3.0          |   py37he904b0f_0         218 KB\n",
            "    mkl_fft-1.1.0              |   py37h23d657b_0         143 KB\n",
            "    mkl_random-1.1.1           |   py37h0573a6f_0         322 KB\n",
            "    numpy-1.19.1               |   py37hbc911f0_0          21 KB\n",
            "    numpy-base-1.19.1          |   py37hfa32c7d_0         4.1 MB\n",
            "    olefile-0.46               |           py37_0          50 KB\n",
            "    openssl-1.1.1g             |       h7b6447c_0         2.5 MB\n",
            "    pandas-1.1.1               |   py37he6710b0_0         8.2 MB\n",
            "    pcre-8.44                  |       he6710b0_0         212 KB\n",
            "    pillow-7.1.2               |   py37hb39fc2d_0         603 KB\n",
            "    pixman-0.40.0              |       h7b6447c_0         370 KB\n",
            "    py-boost-1.67.0            |   py37h04863e7_4         278 KB\n",
            "    python-dateutil-2.8.1      |             py_0         215 KB\n",
            "    pytz-2020.1                |             py_0         184 KB\n",
            "    rdkit-2020.03.3.0          |   py37hc20afe1_1        24.8 MB  rdkit\n",
            "    zstd-1.3.7                 |       h0b5b093_0         401 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       215.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  blas               pkgs/main/linux-64::blas-1.0-mkl\n",
            "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h7b6447c_0\n",
            "  cairo              pkgs/main/linux-64::cairo-1.14.12-h8948797_3\n",
            "  fontconfig         pkgs/main/linux-64::fontconfig-2.13.0-h9420a91_0\n",
            "  freetype           pkgs/main/linux-64::freetype-2.10.2-h5ab3b9f_0\n",
            "  glib               pkgs/main/linux-64::glib-2.63.1-h5a9c865_0\n",
            "  icu                pkgs/main/linux-64::icu-58.2-he6710b0_3\n",
            "  intel-openmp       pkgs/main/linux-64::intel-openmp-2020.2-254\n",
            "  jpeg               pkgs/main/linux-64::jpeg-9b-h024ee3a_2\n",
            "  libboost           pkgs/main/linux-64::libboost-1.67.0-h46d08c1_4\n",
            "  libpng             pkgs/main/linux-64::libpng-1.6.37-hbc83047_0\n",
            "  libtiff            pkgs/main/linux-64::libtiff-4.1.0-h2733197_0\n",
            "  libuuid            pkgs/main/linux-64::libuuid-1.0.3-h1bed415_2\n",
            "  libxcb             pkgs/main/linux-64::libxcb-1.14-h7b6447c_0\n",
            "  libxml2            pkgs/main/linux-64::libxml2-2.9.9-hea5a465_1\n",
            "  mkl                pkgs/main/linux-64::mkl-2020.2-256\n",
            "  mkl-service        pkgs/main/linux-64::mkl-service-2.3.0-py37he904b0f_0\n",
            "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.1.0-py37h23d657b_0\n",
            "  mkl_random         pkgs/main/linux-64::mkl_random-1.1.1-py37h0573a6f_0\n",
            "  numpy              pkgs/main/linux-64::numpy-1.19.1-py37hbc911f0_0\n",
            "  numpy-base         pkgs/main/linux-64::numpy-base-1.19.1-py37hfa32c7d_0\n",
            "  olefile            pkgs/main/linux-64::olefile-0.46-py37_0\n",
            "  pandas             pkgs/main/linux-64::pandas-1.1.1-py37he6710b0_0\n",
            "  pcre               pkgs/main/linux-64::pcre-8.44-he6710b0_0\n",
            "  pillow             pkgs/main/linux-64::pillow-7.1.2-py37hb39fc2d_0\n",
            "  pixman             pkgs/main/linux-64::pixman-0.40.0-h7b6447c_0\n",
            "  py-boost           pkgs/main/linux-64::py-boost-1.67.0-py37h04863e7_4\n",
            "  python-dateutil    pkgs/main/noarch::python-dateutil-2.8.1-py_0\n",
            "  pytz               pkgs/main/noarch::pytz-2020.1-py_0\n",
            "  rdkit              rdkit/linux-64::rdkit-2020.03.3.0-py37hc20afe1_1\n",
            "  zstd               pkgs/main/linux-64::zstd-1.3.7-h0b5b093_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                                2020.1.1-0 --> 2020.7.22-0\n",
            "  certifi                                 2019.11.28-py37_0 --> 2020.6.20-py37_0\n",
            "  conda                                        4.8.2-py37_0 --> 4.8.4-py37_0\n",
            "  openssl                                 1.1.1d-h7b6447c_4 --> 1.1.1g-h7b6447c_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "blas-1.0             | 6 KB      | : 100% 1.0/1 [00:00<00:00, 10.78it/s]\n",
            "numpy-base-1.19.1    | 4.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.81it/s]\n",
            "mkl_fft-1.1.0        | 143 KB    | : 100% 1.0/1 [00:00<00:00, 18.18it/s]\n",
            "libpng-1.6.37        | 278 KB    | : 100% 1.0/1 [00:00<00:00, 16.47it/s]\n",
            "conda-4.8.4          | 2.9 MB    | : 100% 1.0/1 [00:00<00:00,  5.51it/s]\n",
            "pcre-8.44            | 212 KB    | : 100% 1.0/1 [00:00<00:00, 18.18it/s]\n",
            "libuuid-1.0.3        | 15 KB     | : 100% 1.0/1 [00:00<00:00, 25.29it/s]\n",
            "ca-certificates-2020 | 125 KB    | : 100% 1.0/1 [00:00<00:00, 22.16it/s]\n",
            "libboost-1.67.0      | 13.0 MB   | : 100% 1.0/1 [00:02<00:00,  1.80s/it]               \n",
            "pillow-7.1.2         | 603 KB    | : 100% 1.0/1 [00:00<00:00, 10.59it/s]\n",
            "python-dateutil-2.8. | 215 KB    | : 100% 1.0/1 [00:00<00:00, 15.13it/s]\n",
            "fontconfig-2.13.0    | 227 KB    | : 100% 1.0/1 [00:00<00:00, 13.78it/s]\n",
            "pytz-2020.1          | 184 KB    | : 100% 1.0/1 [00:00<00:00, 10.06it/s]\n",
            "olefile-0.46         | 50 KB     | : 100% 1.0/1 [00:00<00:00, 15.06it/s]\n",
            "libtiff-4.1.0        | 447 KB    | : 100% 1.0/1 [00:00<00:00, 12.47it/s]\n",
            "numpy-1.19.1         | 21 KB     | : 100% 1.0/1 [00:00<00:00, 22.99it/s]\n",
            "icu-58.2             | 10.5 MB   | : 100% 1.0/1 [00:00<00:00,  1.99it/s]               \n",
            "cairo-1.14.12        | 906 KB    | : 100% 1.0/1 [00:00<00:00, 10.28it/s]\n",
            "mkl-2020.2           | 138.3 MB  | : 100% 1.0/1 [00:05<00:00,  5.48s/it]              \n",
            "glib-2.63.1          | 2.9 MB    | : 100% 1.0/1 [00:00<00:00,  4.98it/s]\n",
            "libxcb-1.14          | 505 KB    | : 100% 1.0/1 [00:00<00:00,  9.34it/s]\n",
            "libxml2-2.9.9        | 1.6 MB    | : 100% 1.0/1 [00:00<00:00,  7.16it/s]\n",
            "rdkit-2020.03.3.0    | 24.8 MB   | : 100% 1.0/1 [00:05<00:00,  5.81s/it]\n",
            "mkl-service-2.3.0    | 218 KB    | : 100% 1.0/1 [00:00<00:00,  1.25it/s]\n",
            "jpeg-9b              | 214 KB    | : 100% 1.0/1 [00:00<00:00, 10.27it/s]\n",
            "py-boost-1.67.0      | 278 KB    | : 100% 1.0/1 [00:00<00:00,  7.95it/s]\n",
            "freetype-2.10.2      | 608 KB    | : 100% 1.0/1 [00:00<00:00, 11.31it/s]\n",
            "bzip2-1.0.8          | 78 KB     | : 100% 1.0/1 [00:00<00:00, 19.69it/s]\n",
            "pixman-0.40.0        | 370 KB    | : 100% 1.0/1 [00:00<00:00, 18.02it/s]\n",
            "zstd-1.3.7           | 401 KB    | : 100% 1.0/1 [00:00<00:00, 16.33it/s]\n",
            "certifi-2020.6.20    | 156 KB    | : 100% 1.0/1 [00:00<00:00, 19.48it/s]\n",
            "intel-openmp-2020.2  | 786 KB    | : 100% 1.0/1 [00:00<00:00, 13.43it/s]\n",
            "openssl-1.1.1g       | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  7.66it/s]\n",
            "mkl_random-1.1.1     | 322 KB    | : 100% 1.0/1 [00:00<00:00, 18.30it/s]\n",
            "pandas-1.1.1         | 8.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.74it/s]\n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4Hp6Exxqrt_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "d2d41fec-c0e3-4218-c45c-1c325ed05113"
      },
      "source": [
        "!conda install pytorch torchvision cudatoolkit=10.0.130 -c pytorch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - cudatoolkit=10.0.130\n",
            "    - pytorch\n",
            "    - torchvision\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    cudatoolkit-10.0.130       |                0       261.2 MB\n",
            "    ninja-1.10.1               |   py37hfd86e86_0         1.4 MB\n",
            "    pytorch-1.4.0              |py3.7_cuda10.0.130_cudnn7.6.3_0       422.7 MB  pytorch\n",
            "    torchvision-0.5.0          |       py37_cu100         9.1 MB  pytorch\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       694.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.0.130-0\n",
            "  ninja              pkgs/main/linux-64::ninja-1.10.1-py37hfd86e86_0\n",
            "  pytorch            pytorch/linux-64::pytorch-1.4.0-py3.7_cuda10.0.130_cudnn7.6.3_0\n",
            "  torchvision        pytorch/linux-64::torchvision-0.5.0-py37_cu100\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "ninja-1.10.1         | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  7.51it/s]\n",
            "cudatoolkit-10.0.130 | 261.2 MB  | : 100% 1.0/1 [00:06<00:00,  6.91s/it]               \n",
            "pytorch-1.4.0        | 422.7 MB  | : 100% 1.0/1 [01:29<00:00, 89.99s/it]               \n",
            "torchvision-0.5.0    | 9.1 MB    | : 100% 1.0/1 [00:04<00:00,  4.73s/it]               \n",
            "Preparing transaction: - \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEok98liqwpD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74e25b9b-2df7-4a47-8312-b525b653ff5e"
      },
      "source": [
        "cd /content/drive/My Drive/mmdetection-master"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/mmdetection-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXbog54jq1ef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "b92b13b5-e8db-42cd-c1b7-843bb95e057f"
      },
      "source": [
        "!pip install -r requirements/build.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cython\n",
            "  Downloading Cython-0.29.21-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from -r requirements/build.txt (line 3)) (1.19.1)\n",
            "Installing collected packages: cython\n",
            "Successfully installed cython-0.29.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyGti5Khq5HH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "49ced30c-9f86-470c-8fad-5f4d182a76ae"
      },
      "source": [
        "\n",
        "!pip install \"git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-4hyfonbg\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-4hyfonbg\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/site-packages (from pycocotools==2.0) (45.2.0.post20200210)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/site-packages (from pycocotools==2.0) (0.29.21)\n",
            "Collecting matplotlib>=2.1.0\n",
            "  Downloading matplotlib-3.3.1-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6 MB 252 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.19.1)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (7.1.2)\n",
            "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2020.6.20)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.14.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=273358 sha256=b16a29eb21beab51ce3749c9405bc700de43b236491f590b773197bdd5d08b0d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-97yrigpt/wheels/e2/6b/1d/344ac773c7495ea0b85eb228bc66daec7400a143a92d36b7b1\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: cycler, kiwisolver, pyparsing, matplotlib, pycocotools\n",
            "Successfully installed cycler-0.10.0 kiwisolver-1.2.0 matplotlib-3.3.1 pycocotools-2.0 pyparsing-2.4.7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "kiwisolver",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8hchCmKq_nS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d2e67a07-dc12-41bf-c102-6c4f5340aebf"
      },
      "source": [
        "!pip install -v -e .  # or \"python setup.py develop\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Non-user install because site-packages writeable\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-osbegjbo\n",
            "Created temporary directory: /tmp/pip-req-tracker-cbf1h7xu\n",
            "Initialized build tracking at /tmp/pip-req-tracker-cbf1h7xu\n",
            "Created build tracker: /tmp/pip-req-tracker-cbf1h7xu\n",
            "Entered build tracker: /tmp/pip-req-tracker-cbf1h7xu\n",
            "Created temporary directory: /tmp/pip-install-1xe8gm0f\n",
            "Obtaining file:///content/drive/My%20Drive/mmdetection-master\n",
            "  Added file:///content/drive/My%20Drive/mmdetection-master to build tracker '/tmp/pip-req-tracker-cbf1h7xu'\n",
            "    Running setup.py (path:/content/drive/My Drive/mmdetection-master/setup.py) egg_info for package from file:///content/drive/My%20Drive/mmdetection-master\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    writing mmdet.egg-info/PKG-INFO\n",
            "    writing dependency_links to mmdet.egg-info/dependency_links.txt\n",
            "    writing requirements to mmdet.egg-info/requires.txt\n",
            "    writing top-level names to mmdet.egg-info/top_level.txt\n",
            "    reading manifest file 'mmdet.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'mmdet.egg-info/SOURCES.txt'\n",
            "  Source in /content/drive/My Drive/mmdetection-master has version 2.3.0, which satisfies requirement mmdet==2.3.0 from file:///content/drive/My%20Drive/mmdetection-master\n",
            "  Removed mmdet==2.3.0 from file:///content/drive/My%20Drive/mmdetection-master from build tracker '/tmp/pip-req-tracker-cbf1h7xu'\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/site-packages (from mmdet==2.3.0) (3.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from mmdet==2.3.0) (1.19.1)\n",
            "Requirement already satisfied: pycocotools@ git+https://github.com/open-mmlab/cocoapi.git#subdirectory=pycocotools from git+https://github.com/open-mmlab/cocoapi.git#subdirectory=pycocotools in /usr/local/lib/python3.7/site-packages (from mmdet==2.3.0) (2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from mmdet==2.3.0) (1.14.0)\n",
            "1 location(s) to search for versions of terminaltables:\n",
            "* https://pypi.org/simple/terminaltables/\n",
            "Fetching project page and analyzing links: https://pypi.org/simple/terminaltables/\n",
            "Getting page https://pypi.org/simple/terminaltables/\n",
            "Found index url https://pypi.org/simple\n",
            "Looking up \"https://pypi.org/simple/terminaltables/\" in the cache\n",
            "Request header has \"max_age\" as 0, cache bypassed\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/terminaltables/ HTTP/1.1\" 200 1186\n",
            "Updating cache with response from \"https://pypi.org/simple/terminaltables/\"\n",
            "Caching due to etag\n",
            "  Found link https://files.pythonhosted.org/packages/ec/82/6390ba7f110622d27b02451aaa294dc4b3133b7661e464db9a116e977324/terminaltables-1.0.0.tar.gz#sha256=4c909a5ee4a3d028b2c977d996f8b8cd9724ce8e4d9d834d65e78a98f7965b54 (from https://pypi.org/simple/terminaltables/), version: 1.0.0\n",
            "  Found link https://files.pythonhosted.org/packages/97/65/858bc3ea6cc60edc959ce427a94227932b5d9a95b0bce82f16071419885c/terminaltables-1.0.1.tar.gz#sha256=5548ac567d38d6ac88a5e0fec2d95f646249f37e1ef8fd2d17f8fcaefc6cf592 (from https://pypi.org/simple/terminaltables/), version: 1.0.1\n",
            "  Found link https://files.pythonhosted.org/packages/82/42/3f1140f6e538582fd514c765244662cca60885048cf610e7d00eaee8aeb1/terminaltables-1.0.2.tar.gz#sha256=cf97dd019af975cc64aa69aca435a43b0cffabb88df6f337c6b48de600c19f8e (from https://pypi.org/simple/terminaltables/), version: 1.0.2\n",
            "  Found link https://files.pythonhosted.org/packages/80/07/5663569dfd8fa4e4fa3cb645b70f4972e3d79d056b71da12df174668c145/terminaltables-1.1.0.tar.gz#sha256=94a15e1a295265d130de67e9c2efef9e1cad1e64dd6ae0b80882076581605f8c (from https://pypi.org/simple/terminaltables/), version: 1.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/0c/4a/9b80642ac2463908fe77c9dbe138c56902fbf5a5a95d07203c131ec9ba90/terminaltables-1.1.1.tar.gz#sha256=b02c516d6d521ce0fe6e2a2753268e86547bbccab6bfa7e269a0f51766283fab (from https://pypi.org/simple/terminaltables/), version: 1.1.1\n",
            "  Found link https://files.pythonhosted.org/packages/a8/65/f9c6bcfb1f81acdfcd1f8d633c6752cfdcc04b5fade7638a2a8dc7a720de/terminaltables-1.2.0.tar.gz#sha256=fff4aa62f296038d1526a91856f0b3de1e3bce31cfd1c5148cc3f795c1d396bf (from https://pypi.org/simple/terminaltables/), version: 1.2.0\n",
            "  Found link https://files.pythonhosted.org/packages/3d/17/14aa6521b337be46c51dd7b31e7e617801e9f8db7f48583c767c02e0e72a/terminaltables-1.2.1.tar.gz#sha256=cf5f0fb6c6c3070d7af73537ded030858c122f253c87e7221f9a6da3782ce787 (from https://pypi.org/simple/terminaltables/), version: 1.2.1\n",
            "  Found link https://files.pythonhosted.org/packages/d0/8e/9403573ff8aebc09ee0aacd57885050f74bd9f48a85c0735d33cacfa2469/terminaltables-2.0.0.tar.gz#sha256=2e0a6688071f2a881f8fa4455a362457dcd2317e374609f1a09baffa998e7492 (from https://pypi.org/simple/terminaltables/), version: 2.0.0\n",
            "  Found link https://files.pythonhosted.org/packages/10/da/9bbb21c1c2f9be4df2056b00b569689b9ece538ef39bf8db34be25f9e850/terminaltables-2.1.0.tar.gz#sha256=33b60f027964214f4ff5821f43958d03add81784f7c183d86a7ee8f010350cf5 (from https://pypi.org/simple/terminaltables/), version: 2.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/58/c9/f0c174c4e828365df3593c66ac32474cd994a8ec36fe19a798261c96c3bc/terminaltables-3.0.0.tar.gz#sha256=bd2504031f09f942a8f221266adc61aee04a0368d5de0dacb7a53e508af6a518 (from https://pypi.org/simple/terminaltables/), version: 3.0.0\n",
            "  Found link https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from https://pypi.org/simple/terminaltables/), version: 3.1.0\n",
            "Given no hashes to check 11 links for project 'terminaltables': discarding no candidates\n",
            "Using version 3.1.0 (newest of versions: 1.0.0, 1.0.1, 1.0.2, 1.1.0, 1.1.1, 1.2.0, 1.2.1, 2.0.0, 2.1.0, 3.0.0, 3.1.0)\n",
            "Collecting terminaltables\n",
            "  Created temporary directory: /tmp/pip-unpack-74o5jig5\n",
            "  Looking up \"https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\" in the cache\n",
            "  No cache entry available\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz HTTP/1.1\" 200 12478\n",
            "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\n",
            "  Ignoring unknown cache-control directive: immutable\n",
            "  Updating cache with response from \"https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\"\n",
            "  Caching due to etag\n",
            "  Added terminaltables from https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from mmdet==2.3.0) to build tracker '/tmp/pip-req-tracker-cbf1h7xu'\n",
            "    Running setup.py (path:/tmp/pip-install-1xe8gm0f/terminaltables/setup.py) egg_info for package terminaltables\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-install-1xe8gm0f/terminaltables/pip-egg-info/terminaltables.egg-info\n",
            "    writing /tmp/pip-install-1xe8gm0f/terminaltables/pip-egg-info/terminaltables.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-install-1xe8gm0f/terminaltables/pip-egg-info/terminaltables.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-install-1xe8gm0f/terminaltables/pip-egg-info/terminaltables.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-install-1xe8gm0f/terminaltables/pip-egg-info/terminaltables.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-install-1xe8gm0f/terminaltables/pip-egg-info/terminaltables.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-install-1xe8gm0f/terminaltables/pip-egg-info/terminaltables.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-install-1xe8gm0f/terminaltables has version 3.1.0, which satisfies requirement terminaltables from https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from mmdet==2.3.0)\n",
            "  Removed terminaltables from https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from mmdet==2.3.0) from build tracker '/tmp/pip-req-tracker-cbf1h7xu'\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib->mmdet==2.3.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib->mmdet==2.3.0) (2.8.1)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/site-packages (from matplotlib->mmdet==2.3.0) (2020.6.20)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib->mmdet==2.3.0) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/site-packages (from matplotlib->mmdet==2.3.0) (2.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/site-packages (from matplotlib->mmdet==2.3.0) (7.1.2)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/site-packages (from pycocotools@ git+https://github.com/open-mmlab/cocoapi.git#subdirectory=pycocotools->mmdet==2.3.0) (45.2.0.post20200210)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/site-packages (from pycocotools@ git+https://github.com/open-mmlab/cocoapi.git#subdirectory=pycocotools->mmdet==2.3.0) (0.29.21)\n",
            "Building wheels for collected packages: terminaltables\n",
            "  Created temporary directory: /tmp/pip-wheel-mn6xbuqk\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-mn6xbuqk\n",
            "  Running command /usr/local/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-1xe8gm0f/terminaltables/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-1xe8gm0f/terminaltables/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-mn6xbuqk\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib\n",
            "  creating build/lib/terminaltables\n",
            "  copying terminaltables/base_table.py -> build/lib/terminaltables\n",
            "  copying terminaltables/build.py -> build/lib/terminaltables\n",
            "  copying terminaltables/ascii_table.py -> build/lib/terminaltables\n",
            "  copying terminaltables/terminal_io.py -> build/lib/terminaltables\n",
            "  copying terminaltables/github_table.py -> build/lib/terminaltables\n",
            "  copying terminaltables/width_and_alignment.py -> build/lib/terminaltables\n",
            "  copying terminaltables/__init__.py -> build/lib/terminaltables\n",
            "  copying terminaltables/other_tables.py -> build/lib/terminaltables\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/base_table.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/build.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/ascii_table.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/terminal_io.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/github_table.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/width_and_alignment.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/__init__.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/other_tables.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing terminaltables.egg-info/PKG-INFO\n",
            "  writing dependency_links to terminaltables.egg-info/dependency_links.txt\n",
            "  writing top-level names to terminaltables.egg-info/top_level.txt\n",
            "  reading manifest file 'terminaltables.egg-info/SOURCES.txt'\n",
            "  writing manifest file 'terminaltables.egg-info/SOURCES.txt'\n",
            "  Copying terminaltables.egg-info to build/bdist.linux-x86_64/wheel/terminaltables-3.1.0-py3.7.egg-info\n",
            "  running install_scripts\n",
            "  creating build/bdist.linux-x86_64/wheel/terminaltables-3.1.0.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-mn6xbuqk/terminaltables-3.1.0-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'terminaltables/__init__.py'\n",
            "  adding 'terminaltables/ascii_table.py'\n",
            "  adding 'terminaltables/base_table.py'\n",
            "  adding 'terminaltables/build.py'\n",
            "  adding 'terminaltables/github_table.py'\n",
            "  adding 'terminaltables/other_tables.py'\n",
            "  adding 'terminaltables/terminal_io.py'\n",
            "  adding 'terminaltables/width_and_alignment.py'\n",
            "  adding 'terminaltables-3.1.0.dist-info/METADATA'\n",
            "  adding 'terminaltables-3.1.0.dist-info/WHEEL'\n",
            "  adding 'terminaltables-3.1.0.dist-info/top_level.txt'\n",
            "  adding 'terminaltables-3.1.0.dist-info/zip-safe'\n",
            "  adding 'terminaltables-3.1.0.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15354 sha256=7112a7aa973feef2b04166fe4281b1400d853421a9d0b1ad517b97f3fbfdd788\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/ad/c8/2d98360791161cd3db6daf6b5e730f34021fc9367d5879f497\n",
            "Successfully built terminaltables\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "  Created temporary directory: /tmp/pip-unpacked-wheel-l1457f9l\n",
            "\n",
            "  Running setup.py develop for mmdet\n",
            "    Running command /usr/local/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/content/drive/My Drive/mmdetection-master/setup.py'\"'\"'; __file__='\"'\"'/content/drive/My Drive/mmdetection-master/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\n",
            "    running develop\n",
            "    running egg_info\n",
            "    writing mmdet.egg-info/PKG-INFO\n",
            "    writing dependency_links to mmdet.egg-info/dependency_links.txt\n",
            "    writing requirements to mmdet.egg-info/requires.txt\n",
            "    writing top-level names to mmdet.egg-info/top_level.txt\n",
            "    reading manifest file 'mmdet.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'mmdet.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "    Creating /usr/local/lib/python3.7/site-packages/mmdet.egg-link (link to .)\n",
            "    Adding mmdet 2.3.0 to easy-install.pth file\n",
            "\n",
            "    Installed /content/drive/My Drive/mmdetection-master\n",
            "Successfully installed mmdet terminaltables-3.1.0\n",
            "Cleaning up...\n",
            "  Removing source in /tmp/pip-install-1xe8gm0f/terminaltables\n",
            "Removed build tracker: '/tmp/pip-req-tracker-cbf1h7xu'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKeddh0irDSi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "25bb0d5c-9ef9-4e98-aa28-953a3aca4cbb"
      },
      "source": [
        "!pip install mmcv-full"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mmcv-full\n",
            "  Downloading mmcv-full-1.1.2.tar.gz (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting addict\n",
            "  Downloading addict-2.2.1-py3-none-any.whl (3.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from mmcv-full) (1.19.1)\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
            "\u001b[K     |████████████████████████████████| 269 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting yapf\n",
            "  Downloading yapf-0.30.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 11.7 MB/s \n",
            "\u001b[?25hCollecting opencv-python>=3\n",
            "  Downloading opencv_python-4.4.0.42-cp37-cp37m-manylinux2014_x86_64.whl (49.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 49.4 MB 51 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mmcv-full, pyyaml\n",
            "  Building wheel for mmcv-full (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmcv-full: filename=mmcv_full-1.1.2-cp37-cp37m-linux_x86_64.whl size=16017362 sha256=d3c6a7a26754b3bc585a7aa465e27726e0ca9d5be7291f0ac57969a34c277318\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/dc/9c/b08cc3aaddc4dc75f57e1e522f208671645f7956b17bfcff9c\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=393708 sha256=c2cae85a43edec42a75d4130ea73c5b5345d61b552fd6eef02613b9376f07885\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n",
            "Successfully built mmcv-full pyyaml\n",
            "Installing collected packages: addict, pyyaml, yapf, opencv-python, mmcv-full\n",
            "Successfully installed addict-2.2.1 mmcv-full-1.1.2 opencv-python-4.4.0.42 pyyaml-5.3.1 yapf-0.30.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKNkpPpWrz-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b38cd025-cbc9-4164-f9ea-b88c08d32443"
      },
      "source": [
        "!pip install ipykernel"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipykernel\n",
            "  Downloading ipykernel-5.3.4-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting tornado>=4.2\n",
            "  Downloading tornado-6.0.4.tar.gz (496 kB)\n",
            "\u001b[K     |████████████████████████████████| 496 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting jupyter-client\n",
            "  Downloading jupyter_client-6.1.7-py3-none-any.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 6.9 MB/s \n",
            "\u001b[?25hCollecting ipython>=5.0.0\n",
            "  Downloading ipython-7.18.1-py3-none-any.whl (786 kB)\n",
            "\u001b[K     |████████████████████████████████| 786 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting traitlets>=4.1.0\n",
            "  Downloading traitlets-5.0.4-py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting pyzmq>=13\n",
            "  Downloading pyzmq-19.0.2-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 11.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/site-packages (from jupyter-client->ipykernel) (2.8.1)\n",
            "Collecting jupyter-core>=4.6.0\n",
            "  Downloading jupyter_core-4.6.3-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel) (45.2.0.post20200210)\n",
            "Collecting decorator\n",
            "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
            "Collecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 17.4 MB/s \n",
            "\u001b[?25hCollecting pygments\n",
            "  Downloading Pygments-2.6.1-py3-none-any.whl (914 kB)\n",
            "\u001b[K     |████████████████████████████████| 914 kB 21.7 MB/s \n",
            "\u001b[?25hCollecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.7-py3-none-any.whl (355 kB)\n",
            "\u001b[K     |████████████████████████████████| 355 kB 32.2 MB/s \n",
            "\u001b[?25hCollecting pexpect>4.3; sys_platform != \"win32\"\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting ipython-genutils\n",
            "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.1->jupyter-client->ipykernel) (1.14.0)\n",
            "Collecting parso<0.8.0,>=0.7.0\n",
            "  Downloading parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 31.1 MB/s \n",
            "\u001b[?25hCollecting wcwidth\n",
            "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
            "Collecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.6.0-py2.py3-none-any.whl (39 kB)\n",
            "Building wheels for collected packages: tornado\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tornado: filename=tornado-6.0.4-cp37-cp37m-linux_x86_64.whl size=428630 sha256=648270b9d598f5a3fee36b956a2a98b407ead27cb94691013e0d8178d507fde0\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/14/fa/d88fb5da77d813ea0ffca38a2ab2a052874e9e1142bad0b348\n",
            "Successfully built tornado\n",
            "Installing collected packages: tornado, pyzmq, ipython-genutils, traitlets, jupyter-core, jupyter-client, decorator, backcall, parso, jedi, pygments, pickleshare, wcwidth, prompt-toolkit, ptyprocess, pexpect, ipython, ipykernel\n",
            "Successfully installed backcall-0.2.0 decorator-4.4.2 ipykernel-5.3.4 ipython-7.18.1 ipython-genutils-0.2.0 jedi-0.17.2 jupyter-client-6.1.7 jupyter-core-4.6.3 parso-0.7.1 pexpect-4.8.0 pickleshare-0.7.5 prompt-toolkit-3.0.7 ptyprocess-0.6.0 pygments-2.6.1 pyzmq-19.0.2 tornado-6.0.4 traitlets-5.0.4 wcwidth-0.2.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "decorator",
                  "ipython_genutils",
                  "jupyter_core",
                  "pexpect",
                  "pickleshare",
                  "wcwidth",
                  "zmq"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7VvLhZUr245",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "outputId": "e6791ac7-df36-4c9e-db70-fab9c7e8d952"
      },
      "source": [
        "!pip install albumentations"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting albumentations\n",
            "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▉                             | 10 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 20 kB 1.7 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 30 kB 2.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 40 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 51 kB 2.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 61 kB 2.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 71 kB 2.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 81 kB 2.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 92 kB 2.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 102 kB 2.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 112 kB 2.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 117 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/site-packages (from albumentations) (1.19.1)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 7.2 kB/s \n",
            "\u001b[?25hCollecting imgaug>=0.4.0\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 41.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/site-packages (from albumentations) (5.3.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/site-packages (from albumentations) (4.4.0.42)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (3.3.1)\n",
            "Collecting Shapely\n",
            "  Downloading Shapely-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (7.1.2)\n",
            "Collecting scikit-image>=0.14.2\n",
            "  Downloading scikit_image-0.17.2-cp37-cp37m-manylinux1_x86_64.whl (12.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.5 MB 16 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (1.14.0)\n",
            "Collecting imageio\n",
            "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 46.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (1.2.0)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2020.6.20)\n",
            "Collecting networkx>=2.0\n",
            "  Downloading networkx-2.5-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 44.6 MB/s \n",
            "\u001b[?25hCollecting tifffile>=2019.7.26\n",
            "  Downloading tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
            "\u001b[K     |████████████████████████████████| 148 kB 44.6 MB/s \n",
            "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
            "  Downloading PyWavelets-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 38.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/site-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug>=0.4.0->albumentations) (4.4.2)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65162 sha256=45e02a75a3f96c61b203970b949529c6bb278b9c8fb57eafc1224fa1c274d80c\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n",
            "Successfully built albumentations\n",
            "Installing collected packages: scipy, Shapely, imageio, networkx, tifffile, PyWavelets, scikit-image, imgaug, albumentations\n",
            "Successfully installed PyWavelets-1.1.1 Shapely-1.7.1 albumentations-0.4.6 imageio-2.9.0 imgaug-0.4.0 networkx-2.5 scikit-image-0.17.2 scipy-1.5.2 tifffile-2020.9.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2aR7g_tr_G8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e192fc40-fbff-4494-9bed-fbf399cff920"
      },
      "source": [
        "!python tools/train.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py --resume-from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_11.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-07 04:04:12,418 - mmdet - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.7.6 (default, Jan  8 2020, 19:59:22) [GCC 7.3.0]\n",
            "CUDA available: True\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
            "GPU 0: Tesla T4\n",
            "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "PyTorch: 1.4.0\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CUDA Runtime 10.0\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.1\n",
            "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "TorchVision: 0.5.0\n",
            "OpenCV: 4.4.0\n",
            "MMCV: 1.1.2\n",
            "MMDetection: 2.3.0+\n",
            "MMDetection Compiler: GCC 7.5\n",
            "MMDetection CUDA Compiler: 10.1\n",
            "------------------------------------------------------------\n",
            "\n",
            "2020-09-07 04:04:13,126 - mmdet - INFO - Distributed training: False\n",
            "2020-09-07 04:04:13,863 - mmdet - INFO - Config:\n",
            "model = dict(\n",
            "    type='CascadeRCNN',\n",
            "    pretrained='open-mmlab://resnext101_32x4d',\n",
            "    backbone=dict(\n",
            "        type='DetectoRS_ResNeXt',\n",
            "        depth=101,\n",
            "        groups=32,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=True,\n",
            "        style='pytorch',\n",
            "        conv_cfg=dict(type='ConvAWS'),\n",
            "        sac=dict(type='SAC', use_deform=True),\n",
            "        stage_with_sac=(False, True, True, True),\n",
            "        output_img=True),\n",
            "    neck=dict(\n",
            "        type='RFP',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5,\n",
            "        rfp_steps=2,\n",
            "        aspp_out_channels=64,\n",
            "        aspp_dilations=(1, 3, 6, 1),\n",
            "        rfp_backbone=dict(\n",
            "            rfp_inplanes=256,\n",
            "            type='DetectoRS_ResNeXt',\n",
            "            depth=101,\n",
            "            num_stages=4,\n",
            "            out_indices=(0, 1, 2, 3),\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(type='BN', requires_grad=True),\n",
            "            norm_eval=True,\n",
            "            conv_cfg=dict(type='ConvAWS'),\n",
            "            sac=dict(type='SAC', use_deform=True),\n",
            "            stage_with_sac=(False, True, True, True),\n",
            "            pretrained='open-mmlab://resnext101_32x4d',\n",
            "            style='pytorch')),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(\n",
            "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='CascadeRoIHead',\n",
            "        num_stages=3,\n",
            "        stage_loss_weights=[1, 0.5, 0.25],\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='GenericRoIExtractor',\n",
            "            aggregation='sum',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32],\n",
            "            pre_cfg=dict(\n",
            "                type='ConvModule',\n",
            "                in_channels=256,\n",
            "                out_channels=256,\n",
            "                kernel_size=5,\n",
            "                padding=2,\n",
            "                inplace=False),\n",
            "            post_cfg=dict(\n",
            "                type='GeneralizedAttention',\n",
            "                in_channels=256,\n",
            "                spatial_range=-1,\n",
            "                num_heads=6,\n",
            "                attention_type='0100',\n",
            "                kv_stride=2)),\n",
            "        bbox_head=[\n",
            "            dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=10,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
            "                               loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=10,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
            "                               loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=10,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
            "        ]))\n",
            "train_cfg = dict(\n",
            "    rpn=dict(\n",
            "        assigner=dict(\n",
            "            type='MaxIoUAssigner',\n",
            "            pos_iou_thr=0.7,\n",
            "            neg_iou_thr=0.3,\n",
            "            min_pos_iou=0.3,\n",
            "            match_low_quality=True,\n",
            "            ignore_iof_thr=-1),\n",
            "        sampler=dict(\n",
            "            type='RandomSampler',\n",
            "            num=256,\n",
            "            pos_fraction=0.5,\n",
            "            neg_pos_ub=-1,\n",
            "            add_gt_as_proposals=False),\n",
            "        allowed_border=0,\n",
            "        pos_weight=-1,\n",
            "        debug=False),\n",
            "    rpn_proposal=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=2000,\n",
            "        nms_post=2000,\n",
            "        max_num=2000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=[\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.6,\n",
            "                neg_iou_thr=0.6,\n",
            "                min_pos_iou=0.6,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.7,\n",
            "                min_pos_iou=0.7,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)\n",
            "    ])\n",
            "test_cfg = dict(\n",
            "    rpn=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=1000,\n",
            "        nms_post=1000,\n",
            "        max_num=1000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=dict(\n",
            "        score_thr=0.05,\n",
            "        nms=dict(type='nms', iou_threshold=0.5),\n",
            "        max_per_img=100))\n",
            "dataset_type = 'CustomDataset'\n",
            "data_root = 'data/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "albu_train_transforms = [\n",
            "    dict(\n",
            "        type='ShiftScaleRotate',\n",
            "        shift_limit=0.0625,\n",
            "        scale_limit=0.0,\n",
            "        rotate_limit=0,\n",
            "        interpolation=1,\n",
            "        p=0.5),\n",
            "    dict(\n",
            "        type='RandomBrightnessContrast',\n",
            "        brightness_limit=[0.1, 0.3],\n",
            "        contrast_limit=[0.1, 0.3],\n",
            "        p=0.2),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='RGBShift',\n",
            "                r_shift_limit=10,\n",
            "                g_shift_limit=10,\n",
            "                b_shift_limit=10,\n",
            "                p=1.0),\n",
            "            dict(\n",
            "                type='HueSaturationValue',\n",
            "                hue_shift_limit=20,\n",
            "                sat_shift_limit=30,\n",
            "                val_shift_limit=20,\n",
            "                p=1.0)\n",
            "        ],\n",
            "        p=0.1),\n",
            "    dict(type='JpegCompression', quality_lower=85, quality_upper=95, p=0.2),\n",
            "    dict(type='ChannelShuffle', p=0.1),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "        ],\n",
            "        p=0.1)\n",
            "]\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "    dict(\n",
            "        type='Resize',\n",
            "        multiscale_mode='range',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        keep_ratio=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(\n",
            "        type='Albu',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='ShiftScaleRotate',\n",
            "                shift_limit=0.0625,\n",
            "                scale_limit=0.0,\n",
            "                rotate_limit=0,\n",
            "                interpolation=1,\n",
            "                p=0.5),\n",
            "            dict(\n",
            "                type='RandomBrightnessContrast',\n",
            "                brightness_limit=[0.1, 0.3],\n",
            "                contrast_limit=[0.1, 0.3],\n",
            "                p=0.2),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='RGBShift',\n",
            "                        r_shift_limit=10,\n",
            "                        g_shift_limit=10,\n",
            "                        b_shift_limit=10,\n",
            "                        p=1.0),\n",
            "                    dict(\n",
            "                        type='HueSaturationValue',\n",
            "                        hue_shift_limit=20,\n",
            "                        sat_shift_limit=30,\n",
            "                        val_shift_limit=20,\n",
            "                        p=1.0)\n",
            "                ],\n",
            "                p=0.1),\n",
            "            dict(\n",
            "                type='JpegCompression',\n",
            "                quality_lower=85,\n",
            "                quality_upper=95,\n",
            "                p=0.2),\n",
            "            dict(type='ChannelShuffle', p=0.1),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                    dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                ],\n",
            "                p=0.1)\n",
            "        ],\n",
            "        bbox_params=dict(\n",
            "            type='BboxParams',\n",
            "            format='pascal_voc',\n",
            "            label_fields=['gt_labels'],\n",
            "            min_visibility=0.0,\n",
            "            filter_lost_elements=True),\n",
            "        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "        update_pad_shape=False,\n",
            "        skip_img_without_anno=True),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(\n",
            "        type='Collect',\n",
            "        keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "        meta_keys=('filename', 'ori_shape', 'img_shape', 'img_norm_cfg',\n",
            "                   'pad_shape', 'scale_factor'))\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        transforms=[\n",
            "            dict(type='Resize', multiscale_mode='range', keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=1.0),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=1,\n",
            "    workers_per_gpu=1,\n",
            "    train=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/train_80_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                type='Resize',\n",
            "                multiscale_mode='range',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                keep_ratio=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(\n",
            "                type='Albu',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='ShiftScaleRotate',\n",
            "                        shift_limit=0.0625,\n",
            "                        scale_limit=0.0,\n",
            "                        rotate_limit=0,\n",
            "                        interpolation=1,\n",
            "                        p=0.5),\n",
            "                    dict(\n",
            "                        type='RandomBrightnessContrast',\n",
            "                        brightness_limit=[0.1, 0.3],\n",
            "                        contrast_limit=[0.1, 0.3],\n",
            "                        p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(\n",
            "                                type='RGBShift',\n",
            "                                r_shift_limit=10,\n",
            "                                g_shift_limit=10,\n",
            "                                b_shift_limit=10,\n",
            "                                p=1.0),\n",
            "                            dict(\n",
            "                                type='HueSaturationValue',\n",
            "                                hue_shift_limit=20,\n",
            "                                sat_shift_limit=30,\n",
            "                                val_shift_limit=20,\n",
            "                                p=1.0)\n",
            "                        ],\n",
            "                        p=0.1),\n",
            "                    dict(\n",
            "                        type='JpegCompression',\n",
            "                        quality_lower=75,\n",
            "                        quality_upper=95,\n",
            "                        p=0.2),\n",
            "                    dict(type='ChannelShuffle', p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                        ],\n",
            "                        p=0.1)\n",
            "                ],\n",
            "                bbox_params=dict(\n",
            "                    type='BboxParams',\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=['gt_labels'],\n",
            "                    min_visibility=0.0,\n",
            "                    filter_lost_elements=True),\n",
            "                keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "                update_pad_shape=False,\n",
            "                skip_img_without_anno=True),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(\n",
            "                type='Collect',\n",
            "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "                meta_keys=('filename', 'ori_shape', 'img_shape',\n",
            "                           'img_norm_cfg', 'pad_shape', 'scale_factor'))\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/val_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/test_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 200), (1999, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "evaluation = dict(interval=1, metric='mAP')\n",
            "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.3333333333333333,\n",
            "    step=[8, 11])\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=64, hooks=[dict(type='TextLoggerHook')])\n",
            "total_epochs = 20\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "work_dir = './work_dirs/cascade_rcnn_x101_32x4d_fpn_1x'\n",
            "load_from = None\n",
            "resume_from = 'work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_11.pth'\n",
            "workflow = [('train', 1)]\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "2020-09-07 04:04:17,974 - mmdet - INFO - load model from: open-mmlab://resnext101_32x4d\n",
            "Downloading: \"https://openmmlab.oss-accelerate.aliyuncs.com/pretrain/third_party/resnext101_32x4d-a5af3160.pth\" to /root/.cache/torch/checkpoints/resnext101_32x4d-a5af3160.pth\n",
            "100% 161M/161M [00:12<00:00, 13.2MB/s]\n",
            "2020-09-07 04:04:32,256 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "2020-09-07 04:04:32,789 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
            "size mismatch for layer1.0.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.1.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.2.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.2.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
            "size mismatch for layer2.0.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.0.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.1.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.1.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.2.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.2.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.2.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.3.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.3.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.3.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
            "size mismatch for layer3.0.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.0.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.1.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.2.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.2.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.2.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.3.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.3.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.3.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.4.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.4.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.4.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.5.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.5.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.5.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.6.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.6.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.6.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.7.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.7.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.7.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.8.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.8.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.8.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.9.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.9.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.9.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.10.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.10.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.10.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.11.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.11.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.11.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.12.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.12.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.12.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.13.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.13.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.13.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.14.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.14.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.14.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.15.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.15.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.15.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.16.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.16.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.16.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.17.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.17.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.17.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.18.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.18.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.18.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.19.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.19.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.19.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.20.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.20.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.20.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.21.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.21.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.21.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.22.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.22.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.22.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
            "size mismatch for layer4.0.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.0.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.1.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.1.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.2.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.2.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.2.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-07 04:04:38,898 - mmdet - INFO - load checkpoint from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_11.pth\n",
            "2020-09-07 04:04:51,795 - mmdet - INFO - resumed epoch 11, iter 58652\n",
            "2020-09-07 04:04:53,514 - mmdet - INFO - Start running, host: root@c7efd7195315, work_dir: /content/drive/My Drive/mmdetection-master/work_dirs/cascade_rcnn_x101_32x4d_fpn_1x\n",
            "2020-09-07 04:04:53,514 - mmdet - INFO - workflow: [('train', 1)], max: 20 epochs\n",
            "2020-09-07 04:07:03,432 - mmdet - INFO - Epoch [12][64/5332]\tlr: 1.000e-05, eta: 1 day, 3:01:02, time: 2.030, data_time: 0.045, memory: 7818, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0263, s0.acc: 98.9563, s0.loss_bbox: 0.0186, s1.loss_cls: 0.0183, s1.acc: 98.5840, s1.loss_bbox: 0.0316, s2.loss_cls: 0.0113, s2.acc: 97.9858, s2.loss_bbox: 0.0272, loss: 0.1394, grad_norm: 4.5538\n",
            "2020-09-07 04:09:11,964 - mmdet - INFO - Epoch [12][128/5332]\tlr: 1.000e-05, eta: 1 day, 2:50:28, time: 2.008, data_time: 0.005, memory: 7818, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0226, s0.acc: 99.0906, s0.loss_bbox: 0.0144, s1.loss_cls: 0.0152, s1.acc: 98.7274, s1.loss_bbox: 0.0262, s2.loss_cls: 0.0095, s2.acc: 98.2513, s2.loss_bbox: 0.0250, loss: 0.1210, grad_norm: 4.1245\n",
            "2020-09-07 04:11:22,017 - mmdet - INFO - Epoch [12][192/5332]\tlr: 1.000e-05, eta: 1 day, 2:51:47, time: 2.032, data_time: 0.005, memory: 7818, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0219, s0.acc: 99.1302, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0148, s1.acc: 98.7091, s1.loss_bbox: 0.0275, s2.loss_cls: 0.0090, s2.acc: 98.5413, s2.loss_bbox: 0.0251, loss: 0.1212, grad_norm: 4.1442\n",
            "2020-09-07 04:13:33,965 - mmdet - INFO - Epoch [12][256/5332]\tlr: 1.000e-05, eta: 1 day, 2:57:15, time: 2.062, data_time: 0.005, memory: 7818, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0233, s0.acc: 99.0692, s0.loss_bbox: 0.0168, s1.loss_cls: 0.0144, s1.acc: 98.7854, s1.loss_bbox: 0.0270, s2.loss_cls: 0.0089, s2.acc: 98.5992, s2.loss_bbox: 0.0223, loss: 0.1218, grad_norm: 3.9943\n",
            "2020-09-07 04:15:44,716 - mmdet - INFO - Epoch [12][320/5332]\tlr: 1.000e-05, eta: 1 day, 2:56:41, time: 2.043, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0185, s0.acc: 99.2706, s0.loss_bbox: 0.0134, s1.loss_cls: 0.0117, s1.acc: 99.1089, s1.loss_bbox: 0.0220, s2.loss_cls: 0.0080, s2.acc: 98.8159, s2.loss_bbox: 0.0189, loss: 0.0997, grad_norm: 3.3804\n",
            "2020-09-07 04:17:53,903 - mmdet - INFO - Epoch [12][384/5332]\tlr: 1.000e-05, eta: 1 day, 2:52:21, time: 2.019, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0254, s0.acc: 98.9807, s0.loss_bbox: 0.0169, s1.loss_cls: 0.0164, s1.acc: 98.7762, s1.loss_bbox: 0.0303, s2.loss_cls: 0.0103, s2.acc: 98.2574, s2.loss_bbox: 0.0250, loss: 0.1325, grad_norm: 4.2087\n",
            "2020-09-07 04:20:05,640 - mmdet - INFO - Epoch [12][448/5332]\tlr: 1.000e-05, eta: 1 day, 2:53:08, time: 2.058, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0306, s0.acc: 98.7427, s0.loss_bbox: 0.0220, s1.loss_cls: 0.0187, s1.acc: 98.4161, s1.loss_bbox: 0.0357, s2.loss_cls: 0.0126, s2.acc: 97.8790, s2.loss_bbox: 0.0252, loss: 0.1530, grad_norm: 4.7634\n",
            "2020-09-07 04:22:17,330 - mmdet - INFO - Epoch [12][512/5332]\tlr: 1.000e-05, eta: 1 day, 2:53:07, time: 2.058, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0265, s0.acc: 98.9136, s0.loss_bbox: 0.0154, s1.loss_cls: 0.0174, s1.acc: 98.5870, s1.loss_bbox: 0.0263, s2.loss_cls: 0.0110, s2.acc: 98.1476, s2.loss_bbox: 0.0232, loss: 0.1264, grad_norm: 4.4249\n",
            "2020-09-07 04:24:27,612 - mmdet - INFO - Epoch [12][576/5332]\tlr: 1.000e-05, eta: 1 day, 2:50:41, time: 2.036, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0250, s0.acc: 98.9899, s0.loss_bbox: 0.0148, s1.loss_cls: 0.0160, s1.acc: 98.6816, s1.loss_bbox: 0.0278, s2.loss_cls: 0.0103, s2.acc: 98.0988, s2.loss_bbox: 0.0240, loss: 0.1272, grad_norm: 4.2702\n",
            "2020-09-07 04:26:37,700 - mmdet - INFO - Epoch [12][640/5332]\tlr: 1.000e-05, eta: 1 day, 2:48:03, time: 2.033, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0245, s0.acc: 98.9624, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0157, s1.acc: 98.7274, s1.loss_bbox: 0.0365, s2.loss_cls: 0.0105, s2.acc: 98.3734, s2.loss_bbox: 0.0291, loss: 0.1409, grad_norm: 4.0500\n",
            "2020-09-07 04:28:47,951 - mmdet - INFO - Epoch [12][704/5332]\tlr: 1.000e-05, eta: 1 day, 2:45:42, time: 2.035, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0199, s0.acc: 99.2584, s0.loss_bbox: 0.0146, s1.loss_cls: 0.0121, s1.acc: 99.1425, s1.loss_bbox: 0.0230, s2.loss_cls: 0.0079, s2.acc: 98.7976, s2.loss_bbox: 0.0191, loss: 0.1034, grad_norm: 3.5791\n",
            "2020-09-07 04:30:57,804 - mmdet - INFO - Epoch [12][768/5332]\tlr: 1.000e-05, eta: 1 day, 2:42:57, time: 2.029, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0062, s0.loss_cls: 0.0201, s0.acc: 99.1913, s0.loss_bbox: 0.0191, s1.loss_cls: 0.0141, s1.acc: 98.8556, s1.loss_bbox: 0.0279, s2.loss_cls: 0.0090, s2.acc: 98.4650, s2.loss_bbox: 0.0200, loss: 0.1205, grad_norm: 3.6989\n",
            "2020-09-07 04:33:08,915 - mmdet - INFO - Epoch [12][832/5332]\tlr: 1.000e-05, eta: 1 day, 2:41:30, time: 2.049, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0162, s0.acc: 99.3652, s0.loss_bbox: 0.0122, s1.loss_cls: 0.0117, s1.acc: 99.0784, s1.loss_bbox: 0.0216, s2.loss_cls: 0.0081, s2.acc: 98.6511, s2.loss_bbox: 0.0206, loss: 0.0959, grad_norm: 3.6300\n",
            "2020-09-07 04:35:19,060 - mmdet - INFO - Epoch [12][896/5332]\tlr: 1.000e-05, eta: 1 day, 2:39:05, time: 2.033, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0277, s0.acc: 98.9685, s0.loss_bbox: 0.0221, s1.loss_cls: 0.0166, s1.acc: 98.6877, s1.loss_bbox: 0.0332, s2.loss_cls: 0.0103, s2.acc: 98.2574, s2.loss_bbox: 0.0247, loss: 0.1438, grad_norm: 4.2341\n",
            "2020-09-07 04:37:29,045 - mmdet - INFO - Epoch [12][960/5332]\tlr: 1.000e-05, eta: 1 day, 2:36:35, time: 2.031, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0247, s0.acc: 99.0448, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0142, s1.acc: 98.8464, s1.loss_bbox: 0.0278, s2.loss_cls: 0.0098, s2.acc: 98.1049, s2.loss_bbox: 0.0230, loss: 0.1250, grad_norm: 4.1306\n",
            "2020-09-07 04:39:39,531 - mmdet - INFO - Epoch [12][1024/5332]\tlr: 1.000e-05, eta: 1 day, 2:34:30, time: 2.039, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0300, s0.acc: 98.8617, s0.loss_bbox: 0.0200, s1.loss_cls: 0.0185, s1.acc: 98.5626, s1.loss_bbox: 0.0317, s2.loss_cls: 0.0118, s2.acc: 98.0988, s2.loss_bbox: 0.0294, loss: 0.1504, grad_norm: 4.9893\n",
            "2020-09-07 04:41:49,979 - mmdet - INFO - Epoch [12][1088/5332]\tlr: 1.000e-05, eta: 1 day, 2:32:23, time: 2.038, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0255, s0.acc: 98.9410, s0.loss_bbox: 0.0215, s1.loss_cls: 0.0153, s1.acc: 98.8251, s1.loss_bbox: 0.0319, s2.loss_cls: 0.0107, s2.acc: 98.2178, s2.loss_bbox: 0.0255, loss: 0.1395, grad_norm: 4.3112\n",
            "2020-09-07 04:43:59,150 - mmdet - INFO - Epoch [12][1152/5332]\tlr: 1.000e-05, eta: 1 day, 2:29:23, time: 2.018, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0213, s0.acc: 99.1760, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0141, s1.acc: 98.8403, s1.loss_bbox: 0.0282, s2.loss_cls: 0.0084, s2.acc: 98.6664, s2.loss_bbox: 0.0265, loss: 0.1219, grad_norm: 4.1453\n",
            "2020-09-07 04:46:09,302 - mmdet - INFO - Epoch [12][1216/5332]\tlr: 1.000e-05, eta: 1 day, 2:27:07, time: 2.034, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0239, s0.acc: 99.0387, s0.loss_bbox: 0.0173, s1.loss_cls: 0.0152, s1.acc: 98.7732, s1.loss_bbox: 0.0277, s2.loss_cls: 0.0089, s2.acc: 98.5840, s2.loss_bbox: 0.0226, loss: 0.1219, grad_norm: 3.9363\n",
            "2020-09-07 04:48:19,384 - mmdet - INFO - Epoch [12][1280/5332]\tlr: 1.000e-05, eta: 1 day, 2:24:48, time: 2.033, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0250, s0.acc: 99.0021, s0.loss_bbox: 0.0169, s1.loss_cls: 0.0169, s1.acc: 98.6755, s1.loss_bbox: 0.0306, s2.loss_cls: 0.0110, s2.acc: 98.3765, s2.loss_bbox: 0.0240, loss: 0.1321, grad_norm: 4.2622\n",
            "2020-09-07 04:50:28,564 - mmdet - INFO - Epoch [12][1344/5332]\tlr: 1.000e-05, eta: 1 day, 2:21:59, time: 2.018, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0229, s0.acc: 99.1058, s0.loss_bbox: 0.0208, s1.loss_cls: 0.0153, s1.acc: 98.7823, s1.loss_bbox: 0.0339, s2.loss_cls: 0.0103, s2.acc: 98.0499, s2.loss_bbox: 0.0263, loss: 0.1376, grad_norm: 4.1826\n",
            "2020-09-07 04:52:37,880 - mmdet - INFO - Epoch [12][1408/5332]\tlr: 1.000e-05, eta: 1 day, 2:19:19, time: 2.021, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0333, s0.acc: 98.8037, s0.loss_bbox: 0.0233, s1.loss_cls: 0.0201, s1.acc: 98.3887, s1.loss_bbox: 0.0346, s2.loss_cls: 0.0122, s2.acc: 98.1934, s2.loss_bbox: 0.0258, loss: 0.1595, grad_norm: 5.0225\n",
            "2020-09-07 04:54:49,152 - mmdet - INFO - Epoch [12][1472/5332]\tlr: 1.000e-05, eta: 1 day, 2:17:42, time: 2.051, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0219, s0.acc: 99.0479, s0.loss_bbox: 0.0153, s1.loss_cls: 0.0154, s1.acc: 98.6572, s1.loss_bbox: 0.0255, s2.loss_cls: 0.0112, s2.acc: 97.9828, s2.loss_bbox: 0.0199, loss: 0.1191, grad_norm: 4.3152\n",
            "2020-09-07 04:57:01,505 - mmdet - INFO - Epoch [12][1536/5332]\tlr: 1.000e-05, eta: 1 day, 2:16:36, time: 2.068, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0241, s0.acc: 99.0906, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0157, s1.acc: 98.7823, s1.loss_bbox: 0.0262, s2.loss_cls: 0.0102, s2.acc: 98.4100, s2.loss_bbox: 0.0241, loss: 0.1249, grad_norm: 3.9395\n",
            "2020-09-07 04:59:12,674 - mmdet - INFO - Epoch [12][1600/5332]\tlr: 1.000e-05, eta: 1 day, 2:14:50, time: 2.050, data_time: 0.022, memory: 7874, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0268, s0.acc: 98.9227, s0.loss_bbox: 0.0184, s1.loss_cls: 0.0165, s1.acc: 98.7152, s1.loss_bbox: 0.0343, s2.loss_cls: 0.0103, s2.acc: 98.3490, s2.loss_bbox: 0.0285, loss: 0.1416, grad_norm: 4.5555\n",
            "2020-09-07 05:01:22,569 - mmdet - INFO - Epoch [12][1664/5332]\tlr: 1.000e-05, eta: 1 day, 2:12:26, time: 2.030, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0256, s0.acc: 98.9838, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0157, s1.acc: 98.7885, s1.loss_bbox: 0.0293, s2.loss_cls: 0.0104, s2.acc: 98.2483, s2.loss_bbox: 0.0211, loss: 0.1280, grad_norm: 4.0826\n",
            "2020-09-07 05:03:35,057 - mmdet - INFO - Epoch [12][1728/5332]\tlr: 1.000e-05, eta: 1 day, 2:11:13, time: 2.070, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0198, s0.acc: 99.2310, s0.loss_bbox: 0.0165, s1.loss_cls: 0.0126, s1.acc: 98.9410, s1.loss_bbox: 0.0288, s2.loss_cls: 0.0087, s2.acc: 98.4955, s2.loss_bbox: 0.0223, loss: 0.1144, grad_norm: 3.6553\n",
            "2020-09-07 05:05:46,534 - mmdet - INFO - Epoch [12][1792/5332]\tlr: 1.000e-05, eta: 1 day, 2:09:30, time: 2.054, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0259, s0.acc: 98.9838, s0.loss_bbox: 0.0187, s1.loss_cls: 0.0185, s1.acc: 98.5779, s1.loss_bbox: 0.0291, s2.loss_cls: 0.0110, s2.acc: 98.3032, s2.loss_bbox: 0.0193, loss: 0.1323, grad_norm: 4.1078\n",
            "2020-09-07 05:07:56,691 - mmdet - INFO - Epoch [12][1856/5332]\tlr: 1.000e-05, eta: 1 day, 2:07:12, time: 2.034, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0261, s0.acc: 98.9716, s0.loss_bbox: 0.0190, s1.loss_cls: 0.0167, s1.acc: 98.6847, s1.loss_bbox: 0.0291, s2.loss_cls: 0.0109, s2.acc: 98.1537, s2.loss_bbox: 0.0246, loss: 0.1360, grad_norm: 4.4820\n",
            "2020-09-07 05:10:08,697 - mmdet - INFO - Epoch [12][1920/5332]\tlr: 1.000e-05, eta: 1 day, 2:05:39, time: 2.063, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0218, s0.acc: 99.0967, s0.loss_bbox: 0.0153, s1.loss_cls: 0.0141, s1.acc: 98.7762, s1.loss_bbox: 0.0279, s2.loss_cls: 0.0085, s2.acc: 98.4833, s2.loss_bbox: 0.0257, loss: 0.1198, grad_norm: 4.4608\n",
            "2020-09-07 05:12:20,942 - mmdet - INFO - Epoch [12][1984/5332]\tlr: 1.000e-05, eta: 1 day, 2:04:08, time: 2.066, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0229, s0.acc: 99.0784, s0.loss_bbox: 0.0169, s1.loss_cls: 0.0152, s1.acc: 98.7396, s1.loss_bbox: 0.0272, s2.loss_cls: 0.0099, s2.acc: 98.3124, s2.loss_bbox: 0.0231, loss: 0.1234, grad_norm: 4.1475\n",
            "2020-09-07 05:14:32,828 - mmdet - INFO - Epoch [12][2048/5332]\tlr: 1.000e-05, eta: 1 day, 2:02:28, time: 2.061, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0272, s0.acc: 98.9166, s0.loss_bbox: 0.0188, s1.loss_cls: 0.0183, s1.acc: 98.5809, s1.loss_bbox: 0.0273, s2.loss_cls: 0.0115, s2.acc: 98.0225, s2.loss_bbox: 0.0225, loss: 0.1334, grad_norm: 4.0915\n",
            "2020-09-07 05:16:45,862 - mmdet - INFO - Epoch [12][2112/5332]\tlr: 1.000e-05, eta: 1 day, 2:01:10, time: 2.079, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0284, s0.acc: 98.9532, s0.loss_bbox: 0.0166, s1.loss_cls: 0.0187, s1.acc: 98.6664, s1.loss_bbox: 0.0266, s2.loss_cls: 0.0117, s2.acc: 98.3398, s2.loss_bbox: 0.0216, loss: 0.1310, grad_norm: 4.2703\n",
            "2020-09-07 05:18:58,937 - mmdet - INFO - Epoch [12][2176/5332]\tlr: 1.000e-05, eta: 1 day, 1:59:50, time: 2.079, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0200, s0.acc: 99.2126, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0141, s1.acc: 98.8464, s1.loss_bbox: 0.0262, s2.loss_cls: 0.0091, s2.acc: 98.5962, s2.loss_bbox: 0.0218, loss: 0.1158, grad_norm: 4.0082\n",
            "2020-09-07 05:21:10,666 - mmdet - INFO - Epoch [12][2240/5332]\tlr: 1.000e-05, eta: 1 day, 1:57:59, time: 2.058, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0244, s0.acc: 99.0601, s0.loss_bbox: 0.0158, s1.loss_cls: 0.0143, s1.acc: 98.9166, s1.loss_bbox: 0.0278, s2.loss_cls: 0.0093, s2.acc: 98.4955, s2.loss_bbox: 0.0232, loss: 0.1228, grad_norm: 4.2904\n",
            "2020-09-07 05:23:22,105 - mmdet - INFO - Epoch [12][2304/5332]\tlr: 1.000e-05, eta: 1 day, 1:56:01, time: 2.054, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0290, s0.acc: 98.9227, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0180, s1.acc: 98.5504, s1.loss_bbox: 0.0237, s2.loss_cls: 0.0102, s2.acc: 98.3917, s2.loss_bbox: 0.0185, loss: 0.1255, grad_norm: 3.7170\n",
            "2020-09-07 05:25:36,133 - mmdet - INFO - Epoch [12][2368/5332]\tlr: 1.000e-05, eta: 1 day, 1:54:53, time: 2.094, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0257, s0.acc: 98.9807, s0.loss_bbox: 0.0169, s1.loss_cls: 0.0147, s1.acc: 98.9227, s1.loss_bbox: 0.0319, s2.loss_cls: 0.0097, s2.acc: 98.6145, s2.loss_bbox: 0.0289, loss: 0.1344, grad_norm: 4.3097\n",
            "2020-09-07 05:27:48,776 - mmdet - INFO - Epoch [12][2432/5332]\tlr: 1.000e-05, eta: 1 day, 1:53:15, time: 2.073, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0273, s0.acc: 99.0387, s0.loss_bbox: 0.0184, s1.loss_cls: 0.0177, s1.acc: 98.6359, s1.loss_bbox: 0.0290, s2.loss_cls: 0.0114, s2.acc: 98.1079, s2.loss_bbox: 0.0197, loss: 0.1307, grad_norm: 4.1480\n",
            "2020-09-07 05:30:02,077 - mmdet - INFO - Epoch [12][2496/5332]\tlr: 1.000e-05, eta: 1 day, 1:51:47, time: 2.083, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0076, s0.loss_cls: 0.0273, s0.acc: 99.0143, s0.loss_bbox: 0.0159, s1.loss_cls: 0.0149, s1.acc: 98.9899, s1.loss_bbox: 0.0299, s2.loss_cls: 0.0101, s2.acc: 98.4100, s2.loss_bbox: 0.0236, loss: 0.1337, grad_norm: 4.0350\n",
            "2020-09-07 05:32:14,638 - mmdet - INFO - Epoch [12][2560/5332]\tlr: 1.000e-05, eta: 1 day, 1:50:04, time: 2.071, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0269, s0.acc: 98.9044, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0196, s1.acc: 98.4253, s1.loss_bbox: 0.0297, s2.loss_cls: 0.0123, s2.acc: 97.7966, s2.loss_bbox: 0.0229, loss: 0.1390, grad_norm: 4.1912\n",
            "2020-09-07 05:34:25,715 - mmdet - INFO - Epoch [12][2624/5332]\tlr: 1.000e-05, eta: 1 day, 1:47:54, time: 2.048, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0193, s0.acc: 99.2371, s0.loss_bbox: 0.0132, s1.loss_cls: 0.0119, s1.acc: 99.1241, s1.loss_bbox: 0.0269, s2.loss_cls: 0.0082, s2.acc: 98.7854, s2.loss_bbox: 0.0242, loss: 0.1095, grad_norm: 3.9614\n",
            "2020-09-07 05:36:37,217 - mmdet - INFO - Epoch [12][2688/5332]\tlr: 1.000e-05, eta: 1 day, 1:45:51, time: 2.055, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0267, s0.acc: 99.0387, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0191, s1.acc: 98.4741, s1.loss_bbox: 0.0293, s2.loss_cls: 0.0123, s2.acc: 97.7875, s2.loss_bbox: 0.0233, loss: 0.1392, grad_norm: 4.3062\n",
            "2020-09-07 05:38:49,464 - mmdet - INFO - Epoch [12][2752/5332]\tlr: 1.000e-05, eta: 1 day, 1:44:00, time: 2.066, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0070, s0.loss_cls: 0.0222, s0.acc: 99.0356, s0.loss_bbox: 0.0166, s1.loss_cls: 0.0145, s1.acc: 98.8403, s1.loss_bbox: 0.0249, s2.loss_cls: 0.0085, s2.acc: 98.6084, s2.loss_bbox: 0.0208, loss: 0.1209, grad_norm: 3.9996\n",
            "2020-09-07 05:40:59,572 - mmdet - INFO - Epoch [12][2816/5332]\tlr: 1.000e-05, eta: 1 day, 1:41:33, time: 2.033, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0245, s0.acc: 99.0082, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0151, s1.acc: 98.7732, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0107, s2.acc: 98.3124, s2.loss_bbox: 0.0223, loss: 0.1253, grad_norm: 4.3830\n",
            "2020-09-07 05:43:11,699 - mmdet - INFO - Epoch [12][2880/5332]\tlr: 1.000e-05, eta: 1 day, 1:39:39, time: 2.064, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0258, s0.acc: 98.9349, s0.loss_bbox: 0.0202, s1.loss_cls: 0.0183, s1.acc: 98.3673, s1.loss_bbox: 0.0327, s2.loss_cls: 0.0112, s2.acc: 97.7966, s2.loss_bbox: 0.0222, loss: 0.1381, grad_norm: 4.4367\n",
            "2020-09-07 05:45:21,773 - mmdet - INFO - Epoch [12][2944/5332]\tlr: 1.000e-05, eta: 1 day, 1:37:13, time: 2.032, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0221, s0.acc: 99.1516, s0.loss_bbox: 0.0150, s1.loss_cls: 0.0144, s1.acc: 98.8464, s1.loss_bbox: 0.0242, s2.loss_cls: 0.0090, s2.acc: 98.5077, s2.loss_bbox: 0.0212, loss: 0.1162, grad_norm: 4.0157\n",
            "2020-09-07 05:47:33,538 - mmdet - INFO - Epoch [12][3008/5332]\tlr: 1.000e-05, eta: 1 day, 1:35:13, time: 2.059, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0235, s0.acc: 99.0570, s0.loss_bbox: 0.0160, s1.loss_cls: 0.0158, s1.acc: 98.8129, s1.loss_bbox: 0.0264, s2.loss_cls: 0.0095, s2.acc: 98.5413, s2.loss_bbox: 0.0244, loss: 0.1252, grad_norm: 4.2376\n",
            "2020-09-07 05:49:43,376 - mmdet - INFO - Epoch [12][3072/5332]\tlr: 1.000e-05, eta: 1 day, 1:32:44, time: 2.029, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0025, s0.loss_cls: 0.0222, s0.acc: 99.1211, s0.loss_bbox: 0.0171, s1.loss_cls: 0.0149, s1.acc: 98.8434, s1.loss_bbox: 0.0289, s2.loss_cls: 0.0102, s2.acc: 98.3856, s2.loss_bbox: 0.0259, loss: 0.1241, grad_norm: 3.9170\n",
            "2020-09-07 05:51:55,110 - mmdet - INFO - Epoch [12][3136/5332]\tlr: 1.000e-05, eta: 1 day, 1:30:42, time: 2.058, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0079, loss_rpn_bbox: 0.0071, s0.loss_cls: 0.0283, s0.acc: 98.8251, s0.loss_bbox: 0.0206, s1.loss_cls: 0.0190, s1.acc: 98.5596, s1.loss_bbox: 0.0331, s2.loss_cls: 0.0114, s2.acc: 98.0621, s2.loss_bbox: 0.0248, loss: 0.1522, grad_norm: 4.9725\n",
            "2020-09-07 05:54:06,195 - mmdet - INFO - Epoch [12][3200/5332]\tlr: 1.000e-05, eta: 1 day, 1:28:32, time: 2.048, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0062, s0.loss_cls: 0.0230, s0.acc: 99.1333, s0.loss_bbox: 0.0203, s1.loss_cls: 0.0147, s1.acc: 98.8586, s1.loss_bbox: 0.0354, s2.loss_cls: 0.0103, s2.acc: 98.2452, s2.loss_bbox: 0.0281, loss: 0.1405, grad_norm: 4.1867\n",
            "2020-09-07 05:56:17,290 - mmdet - INFO - Epoch [12][3264/5332]\tlr: 1.000e-05, eta: 1 day, 1:26:21, time: 2.048, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0067, s0.loss_cls: 0.0296, s0.acc: 98.8068, s0.loss_bbox: 0.0218, s1.loss_cls: 0.0205, s1.acc: 98.1995, s1.loss_bbox: 0.0345, s2.loss_cls: 0.0132, s2.acc: 97.6990, s2.loss_bbox: 0.0250, loss: 0.1573, grad_norm: 4.9117\n",
            "2020-09-07 05:58:28,704 - mmdet - INFO - Epoch [12][3328/5332]\tlr: 1.000e-05, eta: 1 day, 1:24:15, time: 2.053, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0256, s0.acc: 99.1180, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0152, s1.acc: 98.9685, s1.loss_bbox: 0.0263, s2.loss_cls: 0.0106, s2.acc: 98.6053, s2.loss_bbox: 0.0213, loss: 0.1208, grad_norm: 4.0212\n",
            "2020-09-07 06:00:40,162 - mmdet - INFO - Epoch [12][3392/5332]\tlr: 1.000e-05, eta: 1 day, 1:22:09, time: 2.054, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0065, s0.loss_cls: 0.0224, s0.acc: 99.1211, s0.loss_bbox: 0.0178, s1.loss_cls: 0.0148, s1.acc: 98.7762, s1.loss_bbox: 0.0304, s2.loss_cls: 0.0098, s2.acc: 98.3765, s2.loss_bbox: 0.0232, loss: 0.1281, grad_norm: 4.1124\n",
            "2020-09-07 06:02:50,733 - mmdet - INFO - Epoch [12][3456/5332]\tlr: 1.000e-05, eta: 1 day, 1:19:52, time: 2.040, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0064, s0.loss_cls: 0.0271, s0.acc: 98.9105, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0184, s1.acc: 98.5382, s1.loss_bbox: 0.0253, s2.loss_cls: 0.0118, s2.acc: 98.0865, s2.loss_bbox: 0.0198, loss: 0.1307, grad_norm: 4.2343\n",
            "2020-09-07 06:05:03,400 - mmdet - INFO - Epoch [12][3520/5332]\tlr: 1.000e-05, eta: 1 day, 1:18:01, time: 2.073, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0269, s0.acc: 98.9594, s0.loss_bbox: 0.0176, s1.loss_cls: 0.0177, s1.acc: 98.7183, s1.loss_bbox: 0.0274, s2.loss_cls: 0.0101, s2.acc: 98.5809, s2.loss_bbox: 0.0233, loss: 0.1330, grad_norm: 4.0665\n",
            "2020-09-07 06:07:14,621 - mmdet - INFO - Epoch [12][3584/5332]\tlr: 1.000e-05, eta: 1 day, 1:15:52, time: 2.050, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0244, s0.acc: 98.9777, s0.loss_bbox: 0.0147, s1.loss_cls: 0.0169, s1.acc: 98.5352, s1.loss_bbox: 0.0267, s2.loss_cls: 0.0100, s2.acc: 98.3521, s2.loss_bbox: 0.0238, loss: 0.1242, grad_norm: 4.4330\n",
            "2020-09-07 06:09:24,509 - mmdet - INFO - Epoch [12][3648/5332]\tlr: 1.000e-05, eta: 1 day, 1:13:26, time: 2.029, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0239, s0.acc: 99.0814, s0.loss_bbox: 0.0157, s1.loss_cls: 0.0155, s1.acc: 98.8800, s1.loss_bbox: 0.0273, s2.loss_cls: 0.0099, s2.acc: 98.4253, s2.loss_bbox: 0.0218, loss: 0.1203, grad_norm: 4.1185\n",
            "2020-09-07 06:11:34,819 - mmdet - INFO - Epoch [12][3712/5332]\tlr: 1.000e-05, eta: 1 day, 1:11:06, time: 2.036, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0287, s0.acc: 98.9136, s0.loss_bbox: 0.0184, s1.loss_cls: 0.0198, s1.acc: 98.4283, s1.loss_bbox: 0.0319, s2.loss_cls: 0.0128, s2.acc: 98.1171, s2.loss_bbox: 0.0242, loss: 0.1449, grad_norm: 4.4972\n",
            "2020-09-07 06:13:46,010 - mmdet - INFO - Epoch [12][3776/5332]\tlr: 1.000e-05, eta: 1 day, 1:08:56, time: 2.050, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0209, s0.acc: 99.1608, s0.loss_bbox: 0.0153, s1.loss_cls: 0.0140, s1.acc: 98.8739, s1.loss_bbox: 0.0247, s2.loss_cls: 0.0088, s2.acc: 98.6969, s2.loss_bbox: 0.0218, loss: 0.1121, grad_norm: 4.2729\n",
            "2020-09-07 06:15:57,422 - mmdet - INFO - Epoch [12][3840/5332]\tlr: 1.000e-05, eta: 1 day, 1:06:49, time: 2.053, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0239, s0.acc: 98.9777, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0187, s1.acc: 98.5657, s1.loss_bbox: 0.0292, s2.loss_cls: 0.0114, s2.acc: 98.0988, s2.loss_bbox: 0.0230, loss: 0.1313, grad_norm: 4.1610\n",
            "2020-09-07 06:18:09,570 - mmdet - INFO - Epoch [12][3904/5332]\tlr: 1.000e-05, eta: 1 day, 1:04:51, time: 2.065, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0065, s0.loss_cls: 0.0255, s0.acc: 99.0479, s0.loss_bbox: 0.0161, s1.loss_cls: 0.0163, s1.acc: 98.8037, s1.loss_bbox: 0.0275, s2.loss_cls: 0.0101, s2.acc: 98.5504, s2.loss_bbox: 0.0194, loss: 0.1269, grad_norm: 3.9641\n",
            "2020-09-07 06:20:20,822 - mmdet - INFO - Epoch [12][3968/5332]\tlr: 1.000e-05, eta: 1 day, 1:02:41, time: 2.051, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0262, s0.acc: 99.0021, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0154, s1.acc: 98.8281, s1.loss_bbox: 0.0346, s2.loss_cls: 0.0113, s2.acc: 98.2849, s2.loss_bbox: 0.0288, loss: 0.1438, grad_norm: 4.6299\n",
            "2020-09-07 06:22:31,696 - mmdet - INFO - Epoch [12][4032/5332]\tlr: 1.000e-05, eta: 1 day, 1:00:28, time: 2.045, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0206, s0.acc: 99.2493, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0129, s1.acc: 99.0631, s1.loss_bbox: 0.0289, s2.loss_cls: 0.0083, s2.acc: 98.7946, s2.loss_bbox: 0.0248, loss: 0.1172, grad_norm: 4.0126\n",
            "2020-09-07 06:24:42,747 - mmdet - INFO - Epoch [12][4096/5332]\tlr: 1.000e-05, eta: 1 day, 0:58:17, time: 2.048, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0240, s0.acc: 99.0387, s0.loss_bbox: 0.0144, s1.loss_cls: 0.0154, s1.acc: 98.7122, s1.loss_bbox: 0.0227, s2.loss_cls: 0.0100, s2.acc: 98.3185, s2.loss_bbox: 0.0217, loss: 0.1186, grad_norm: 4.1107\n",
            "2020-09-07 06:26:51,603 - mmdet - INFO - Epoch [12][4160/5332]\tlr: 1.000e-05, eta: 1 day, 0:55:42, time: 2.013, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0251, s0.acc: 99.0295, s0.loss_bbox: 0.0187, s1.loss_cls: 0.0177, s1.acc: 98.7183, s1.loss_bbox: 0.0335, s2.loss_cls: 0.0107, s2.acc: 98.1659, s2.loss_bbox: 0.0301, loss: 0.1470, grad_norm: 4.2036\n",
            "2020-09-07 06:29:01,800 - mmdet - INFO - Epoch [12][4224/5332]\tlr: 1.000e-05, eta: 1 day, 0:53:22, time: 2.034, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0241, s0.acc: 99.0051, s0.loss_bbox: 0.0186, s1.loss_cls: 0.0164, s1.acc: 98.6328, s1.loss_bbox: 0.0281, s2.loss_cls: 0.0108, s2.acc: 98.0988, s2.loss_bbox: 0.0227, loss: 0.1282, grad_norm: 4.1790\n",
            "2020-09-07 06:31:13,056 - mmdet - INFO - Epoch [12][4288/5332]\tlr: 1.000e-05, eta: 1 day, 0:51:13, time: 2.051, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0224, s0.acc: 99.1150, s0.loss_bbox: 0.0168, s1.loss_cls: 0.0140, s1.acc: 98.9105, s1.loss_bbox: 0.0257, s2.loss_cls: 0.0086, s2.acc: 98.5199, s2.loss_bbox: 0.0203, loss: 0.1141, grad_norm: 3.8923\n",
            "2020-09-07 06:33:23,565 - mmdet - INFO - Epoch [12][4352/5332]\tlr: 1.000e-05, eta: 1 day, 0:48:57, time: 2.039, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0222, s0.acc: 99.0875, s0.loss_bbox: 0.0154, s1.loss_cls: 0.0150, s1.acc: 98.7396, s1.loss_bbox: 0.0251, s2.loss_cls: 0.0098, s2.acc: 98.1689, s2.loss_bbox: 0.0196, loss: 0.1154, grad_norm: 3.9414\n",
            "2020-09-07 06:35:35,336 - mmdet - INFO - Epoch [12][4416/5332]\tlr: 1.000e-05, eta: 1 day, 0:46:53, time: 2.059, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0062, s0.loss_cls: 0.0333, s0.acc: 98.8007, s0.loss_bbox: 0.0219, s1.loss_cls: 0.0202, s1.acc: 98.3368, s1.loss_bbox: 0.0292, s2.loss_cls: 0.0124, s2.acc: 97.6807, s2.loss_bbox: 0.0209, loss: 0.1497, grad_norm: 4.7172\n",
            "2020-09-07 06:37:47,772 - mmdet - INFO - Epoch [12][4480/5332]\tlr: 1.000e-05, eta: 1 day, 0:44:56, time: 2.069, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0071, s0.loss_cls: 0.0220, s0.acc: 99.1241, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0145, s1.acc: 98.8617, s1.loss_bbox: 0.0289, s2.loss_cls: 0.0103, s2.acc: 98.4497, s2.loss_bbox: 0.0231, loss: 0.1256, grad_norm: 4.2034\n",
            "2020-09-07 06:39:59,207 - mmdet - INFO - Epoch [12][4544/5332]\tlr: 1.000e-05, eta: 1 day, 0:42:48, time: 2.054, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0255, s0.acc: 99.0021, s0.loss_bbox: 0.0164, s1.loss_cls: 0.0166, s1.acc: 98.7183, s1.loss_bbox: 0.0236, s2.loss_cls: 0.0103, s2.acc: 98.4894, s2.loss_bbox: 0.0180, loss: 0.1171, grad_norm: 4.0404\n",
            "2020-09-07 06:42:10,761 - mmdet - INFO - Epoch [12][4608/5332]\tlr: 1.000e-05, eta: 1 day, 0:40:42, time: 2.056, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0088, s0.loss_cls: 0.0253, s0.acc: 99.0417, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0163, s1.acc: 98.7610, s1.loss_bbox: 0.0266, s2.loss_cls: 0.0104, s2.acc: 98.3551, s2.loss_bbox: 0.0206, loss: 0.1313, grad_norm: 4.0674\n",
            "2020-09-07 06:44:23,058 - mmdet - INFO - Epoch [12][4672/5332]\tlr: 1.000e-05, eta: 1 day, 0:38:42, time: 2.067, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0253, s0.acc: 99.0051, s0.loss_bbox: 0.0195, s1.loss_cls: 0.0153, s1.acc: 98.7915, s1.loss_bbox: 0.0327, s2.loss_cls: 0.0097, s2.acc: 98.4100, s2.loss_bbox: 0.0259, loss: 0.1371, grad_norm: 4.3070\n",
            "2020-09-07 06:46:32,061 - mmdet - INFO - Epoch [12][4736/5332]\tlr: 1.000e-05, eta: 1 day, 0:36:12, time: 2.016, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0203, s0.acc: 99.2401, s0.loss_bbox: 0.0171, s1.loss_cls: 0.0130, s1.acc: 98.9502, s1.loss_bbox: 0.0326, s2.loss_cls: 0.0094, s2.acc: 98.5168, s2.loss_bbox: 0.0277, loss: 0.1269, grad_norm: 4.4428\n",
            "2020-09-07 06:48:44,395 - mmdet - INFO - Epoch [12][4800/5332]\tlr: 1.000e-05, eta: 1 day, 0:34:12, time: 2.068, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0062, s0.loss_cls: 0.0204, s0.acc: 99.2065, s0.loss_bbox: 0.0146, s1.loss_cls: 0.0134, s1.acc: 98.9960, s1.loss_bbox: 0.0245, s2.loss_cls: 0.0088, s2.acc: 98.5718, s2.loss_bbox: 0.0212, loss: 0.1142, grad_norm: 3.4451\n",
            "2020-09-07 06:50:54,877 - mmdet - INFO - Epoch [12][4864/5332]\tlr: 1.000e-05, eta: 1 day, 0:31:56, time: 2.039, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0076, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0241, s0.acc: 99.0997, s0.loss_bbox: 0.0150, s1.loss_cls: 0.0143, s1.acc: 98.9532, s1.loss_bbox: 0.0242, s2.loss_cls: 0.0091, s2.acc: 98.6359, s2.loss_bbox: 0.0242, loss: 0.1217, grad_norm: 4.4103\n",
            "2020-09-07 06:53:08,375 - mmdet - INFO - Epoch [12][4928/5332]\tlr: 1.000e-05, eta: 1 day, 0:30:06, time: 2.086, data_time: 0.026, memory: 7874, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0271, s0.acc: 99.0051, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0188, s1.acc: 98.4741, s1.loss_bbox: 0.0337, s2.loss_cls: 0.0120, s2.acc: 97.9462, s2.loss_bbox: 0.0279, loss: 0.1436, grad_norm: 4.8725\n",
            "2020-09-07 06:55:19,296 - mmdet - INFO - Epoch [12][4992/5332]\tlr: 1.000e-05, eta: 1 day, 0:27:54, time: 2.046, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0101, loss_rpn_bbox: 0.0064, s0.loss_cls: 0.0350, s0.acc: 98.5565, s0.loss_bbox: 0.0218, s1.loss_cls: 0.0233, s1.acc: 98.0072, s1.loss_bbox: 0.0289, s2.loss_cls: 0.0142, s2.acc: 97.6410, s2.loss_bbox: 0.0241, loss: 0.1640, grad_norm: 4.9141\n",
            "2020-09-07 06:57:29,803 - mmdet - INFO - Epoch [12][5056/5332]\tlr: 1.000e-05, eta: 1 day, 0:25:37, time: 2.039, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0310, s0.acc: 98.8251, s0.loss_bbox: 0.0242, s1.loss_cls: 0.0199, s1.acc: 98.5504, s1.loss_bbox: 0.0402, s2.loss_cls: 0.0133, s2.acc: 97.8302, s2.loss_bbox: 0.0267, loss: 0.1627, grad_norm: 5.0793\n",
            "2020-09-07 06:59:42,712 - mmdet - INFO - Epoch [12][5120/5332]\tlr: 1.000e-05, eta: 1 day, 0:23:42, time: 2.077, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0281, s0.acc: 98.8708, s0.loss_bbox: 0.0204, s1.loss_cls: 0.0192, s1.acc: 98.5046, s1.loss_bbox: 0.0332, s2.loss_cls: 0.0114, s2.acc: 97.9187, s2.loss_bbox: 0.0269, loss: 0.1476, grad_norm: 5.0166\n",
            "2020-09-07 07:01:55,066 - mmdet - INFO - Epoch [12][5184/5332]\tlr: 1.000e-05, eta: 1 day, 0:21:41, time: 2.068, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0265, s0.acc: 99.0173, s0.loss_bbox: 0.0192, s1.loss_cls: 0.0167, s1.acc: 98.6206, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0105, s2.acc: 98.1903, s2.loss_bbox: 0.0230, loss: 0.1334, grad_norm: 4.7130\n",
            "2020-09-07 07:04:07,566 - mmdet - INFO - Epoch [12][5248/5332]\tlr: 1.000e-05, eta: 1 day, 0:19:41, time: 2.070, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0279, s0.acc: 98.9227, s0.loss_bbox: 0.0212, s1.loss_cls: 0.0197, s1.acc: 98.4802, s1.loss_bbox: 0.0331, s2.loss_cls: 0.0135, s2.acc: 97.8668, s2.loss_bbox: 0.0279, loss: 0.1538, grad_norm: 5.1126\n",
            "2020-09-07 07:06:18,167 - mmdet - INFO - Epoch [12][5312/5332]\tlr: 1.000e-05, eta: 1 day, 0:17:25, time: 2.041, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0219, s0.acc: 99.2523, s0.loss_bbox: 0.0158, s1.loss_cls: 0.0137, s1.acc: 98.9655, s1.loss_bbox: 0.0268, s2.loss_cls: 0.0088, s2.acc: 98.6908, s2.loss_bbox: 0.0228, loss: 0.1172, grad_norm: 4.0749\n",
            "2020-09-07 07:06:58,938 - mmdet - INFO - Saving checkpoint at 12 epochs\n",
            "[>>] 667/667, 0.6 task/s, elapsed: 1183s, ETA:     0s2020-09-07 07:26:48,695 - mmdet - INFO - \n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 82  | 241  | 0.841  | 0.585 |\n",
            "| 3     | 22  | 107  | 0.818  | 0.704 |\n",
            "| 4     | 529 | 1182 | 0.928  | 0.833 |\n",
            "| 5     | 78  | 179  | 0.885  | 0.793 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.729 |\n",
            "+-------+-----+------+--------+-------+\n",
            "2020-09-07 07:26:48,699 - mmdet - INFO - Epoch(val) [12][5332]\tmAP: 0.7287\n",
            "2020-09-07 07:29:03,085 - mmdet - INFO - Epoch [13][64/5332]\tlr: 1.000e-05, eta: 1 day, 0:09:35, time: 2.099, data_time: 0.037, memory: 7874, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0255, s0.acc: 99.0265, s0.loss_bbox: 0.0212, s1.loss_cls: 0.0175, s1.acc: 98.5535, s1.loss_bbox: 0.0320, s2.loss_cls: 0.0116, s2.acc: 98.0286, s2.loss_bbox: 0.0242, loss: 0.1417, grad_norm: 4.1890\n",
            "2020-09-07 07:31:16,592 - mmdet - INFO - Epoch [13][128/5332]\tlr: 1.000e-05, eta: 1 day, 0:07:46, time: 2.086, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0186, s0.acc: 99.3103, s0.loss_bbox: 0.0144, s1.loss_cls: 0.0120, s1.acc: 99.1150, s1.loss_bbox: 0.0243, s2.loss_cls: 0.0080, s2.acc: 98.8495, s2.loss_bbox: 0.0234, loss: 0.1079, grad_norm: 3.9172\n",
            "2020-09-07 07:33:29,439 - mmdet - INFO - Epoch [13][192/5332]\tlr: 1.000e-05, eta: 1 day, 0:05:52, time: 2.076, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0082, loss_rpn_bbox: 0.0061, s0.loss_cls: 0.0227, s0.acc: 99.1272, s0.loss_bbox: 0.0146, s1.loss_cls: 0.0143, s1.acc: 98.8159, s1.loss_bbox: 0.0263, s2.loss_cls: 0.0097, s2.acc: 98.3398, s2.loss_bbox: 0.0217, loss: 0.1238, grad_norm: 4.3211\n",
            "2020-09-07 07:35:41,011 - mmdet - INFO - Epoch [13][256/5332]\tlr: 1.000e-05, eta: 1 day, 0:03:47, time: 2.056, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0241, s0.acc: 99.0723, s0.loss_bbox: 0.0139, s1.loss_cls: 0.0171, s1.acc: 98.7061, s1.loss_bbox: 0.0265, s2.loss_cls: 0.0117, s2.acc: 98.0560, s2.loss_bbox: 0.0191, loss: 0.1227, grad_norm: 3.9828\n",
            "2020-09-07 07:37:52,672 - mmdet - INFO - Epoch [13][320/5332]\tlr: 1.000e-05, eta: 1 day, 0:01:43, time: 2.057, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0230, s0.acc: 99.1333, s0.loss_bbox: 0.0169, s1.loss_cls: 0.0155, s1.acc: 98.8098, s1.loss_bbox: 0.0270, s2.loss_cls: 0.0099, s2.acc: 98.3459, s2.loss_bbox: 0.0226, loss: 0.1220, grad_norm: 3.9780\n",
            "2020-09-07 07:40:03,829 - mmdet - INFO - Epoch [13][384/5332]\tlr: 1.000e-05, eta: 23:59:35, time: 2.049, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0248, s0.acc: 98.9777, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0153, s1.acc: 98.7732, s1.loss_bbox: 0.0237, s2.loss_cls: 0.0103, s2.acc: 98.2239, s2.loss_bbox: 0.0188, loss: 0.1178, grad_norm: 3.8236\n",
            "2020-09-07 07:42:15,647 - mmdet - INFO - Epoch [13][448/5332]\tlr: 1.000e-05, eta: 23:57:32, time: 2.060, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0082, s0.loss_cls: 0.0296, s0.acc: 98.8831, s0.loss_bbox: 0.0206, s1.loss_cls: 0.0201, s1.acc: 98.3826, s1.loss_bbox: 0.0291, s2.loss_cls: 0.0112, s2.acc: 98.1750, s2.loss_bbox: 0.0224, loss: 0.1439, grad_norm: 4.9249\n",
            "2020-09-07 07:44:27,031 - mmdet - INFO - Epoch [13][512/5332]\tlr: 1.000e-05, eta: 23:55:26, time: 2.053, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0066, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0261, s0.acc: 98.8953, s0.loss_bbox: 0.0225, s1.loss_cls: 0.0181, s1.acc: 98.4039, s1.loss_bbox: 0.0309, s2.loss_cls: 0.0118, s2.acc: 97.8943, s2.loss_bbox: 0.0241, loss: 0.1454, grad_norm: 4.9429\n",
            "2020-09-07 07:46:36,811 - mmdet - INFO - Epoch [13][576/5332]\tlr: 1.000e-05, eta: 23:53:08, time: 2.028, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0241, s0.acc: 99.0631, s0.loss_bbox: 0.0212, s1.loss_cls: 0.0157, s1.acc: 98.7457, s1.loss_bbox: 0.0287, s2.loss_cls: 0.0093, s2.acc: 98.5870, s2.loss_bbox: 0.0244, loss: 0.1300, grad_norm: 4.0883\n",
            "2020-09-07 07:48:47,347 - mmdet - INFO - Epoch [13][640/5332]\tlr: 1.000e-05, eta: 23:50:55, time: 2.040, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0275, s0.acc: 98.9258, s0.loss_bbox: 0.0148, s1.loss_cls: 0.0194, s1.acc: 98.3704, s1.loss_bbox: 0.0223, s2.loss_cls: 0.0126, s2.acc: 97.8943, s2.loss_bbox: 0.0185, loss: 0.1220, grad_norm: 4.0633\n",
            "2020-09-07 07:51:00,033 - mmdet - INFO - Epoch [13][704/5332]\tlr: 1.000e-05, eta: 23:48:58, time: 2.073, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0231, s0.acc: 99.0051, s0.loss_bbox: 0.0158, s1.loss_cls: 0.0156, s1.acc: 98.6023, s1.loss_bbox: 0.0224, s2.loss_cls: 0.0096, s2.acc: 98.3429, s2.loss_bbox: 0.0200, loss: 0.1134, grad_norm: 4.0917\n",
            "2020-09-07 07:53:12,449 - mmdet - INFO - Epoch [13][768/5332]\tlr: 1.000e-05, eta: 23:46:58, time: 2.069, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0058, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0265, s0.acc: 99.0265, s0.loss_bbox: 0.0173, s1.loss_cls: 0.0167, s1.acc: 98.7091, s1.loss_bbox: 0.0296, s2.loss_cls: 0.0100, s2.acc: 98.4467, s2.loss_bbox: 0.0262, loss: 0.1377, grad_norm: 4.6382\n",
            "2020-09-07 07:55:23,176 - mmdet - INFO - Epoch [13][832/5332]\tlr: 1.000e-05, eta: 23:44:47, time: 2.043, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0068, s0.loss_cls: 0.0277, s0.acc: 98.8281, s0.loss_bbox: 0.0209, s1.loss_cls: 0.0179, s1.acc: 98.4772, s1.loss_bbox: 0.0338, s2.loss_cls: 0.0108, s2.acc: 98.1873, s2.loss_bbox: 0.0298, loss: 0.1540, grad_norm: 4.8544\n",
            "2020-09-07 07:57:34,040 - mmdet - INFO - Epoch [13][896/5332]\tlr: 1.000e-05, eta: 23:42:36, time: 2.045, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0266, s0.acc: 98.9655, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0166, s1.acc: 98.6115, s1.loss_bbox: 0.0307, s2.loss_cls: 0.0109, s2.acc: 98.3521, s2.loss_bbox: 0.0237, loss: 0.1348, grad_norm: 4.4504\n",
            "2020-09-07 07:59:44,014 - mmdet - INFO - Epoch [13][960/5332]\tlr: 1.000e-05, eta: 23:40:20, time: 2.031, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0243, s0.acc: 99.0326, s0.loss_bbox: 0.0153, s1.loss_cls: 0.0166, s1.acc: 98.6267, s1.loss_bbox: 0.0238, s2.loss_cls: 0.0101, s2.acc: 98.1384, s2.loss_bbox: 0.0197, loss: 0.1159, grad_norm: 4.1348\n",
            "2020-09-07 08:01:53,938 - mmdet - INFO - Epoch [13][1024/5332]\tlr: 1.000e-05, eta: 23:38:03, time: 2.030, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0018, s0.loss_cls: 0.0237, s0.acc: 99.1058, s0.loss_bbox: 0.0161, s1.loss_cls: 0.0183, s1.acc: 98.5352, s1.loss_bbox: 0.0255, s2.loss_cls: 0.0117, s2.acc: 98.1995, s2.loss_bbox: 0.0197, loss: 0.1201, grad_norm: 4.0770\n",
            "2020-09-07 08:04:05,166 - mmdet - INFO - Epoch [13][1088/5332]\tlr: 1.000e-05, eta: 23:35:55, time: 2.050, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0266, s0.acc: 98.9441, s0.loss_bbox: 0.0180, s1.loss_cls: 0.0156, s1.acc: 98.8434, s1.loss_bbox: 0.0292, s2.loss_cls: 0.0105, s2.acc: 98.3765, s2.loss_bbox: 0.0221, loss: 0.1310, grad_norm: 4.3680\n",
            "2020-09-07 08:06:16,619 - mmdet - INFO - Epoch [13][1152/5332]\tlr: 1.000e-05, eta: 23:33:49, time: 2.054, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0269, s0.acc: 98.8983, s0.loss_bbox: 0.0178, s1.loss_cls: 0.0189, s1.acc: 98.4833, s1.loss_bbox: 0.0283, s2.loss_cls: 0.0113, s2.acc: 98.1567, s2.loss_bbox: 0.0223, loss: 0.1356, grad_norm: 4.2822\n",
            "2020-09-07 08:08:27,551 - mmdet - INFO - Epoch [13][1216/5332]\tlr: 1.000e-05, eta: 23:31:38, time: 2.046, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0262, s0.acc: 98.9624, s0.loss_bbox: 0.0207, s1.loss_cls: 0.0164, s1.acc: 98.7183, s1.loss_bbox: 0.0365, s2.loss_cls: 0.0097, s2.acc: 98.4009, s2.loss_bbox: 0.0299, loss: 0.1482, grad_norm: 5.0882\n",
            "2020-09-07 08:10:38,327 - mmdet - INFO - Epoch [13][1280/5332]\tlr: 1.000e-05, eta: 23:29:27, time: 2.043, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0239, s0.acc: 99.1333, s0.loss_bbox: 0.0164, s1.loss_cls: 0.0155, s1.acc: 98.9471, s1.loss_bbox: 0.0289, s2.loss_cls: 0.0093, s2.acc: 98.5687, s2.loss_bbox: 0.0246, loss: 0.1261, grad_norm: 4.1464\n",
            "2020-09-07 08:12:50,525 - mmdet - INFO - Epoch [13][1344/5332]\tlr: 1.000e-05, eta: 23:27:25, time: 2.066, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0065, s0.loss_cls: 0.0256, s0.acc: 98.9563, s0.loss_bbox: 0.0209, s1.loss_cls: 0.0174, s1.acc: 98.5870, s1.loss_bbox: 0.0345, s2.loss_cls: 0.0122, s2.acc: 97.9645, s2.loss_bbox: 0.0267, loss: 0.1471, grad_norm: 4.6019\n",
            "2020-09-07 08:15:01,873 - mmdet - INFO - Epoch [13][1408/5332]\tlr: 1.000e-05, eta: 23:25:18, time: 2.052, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0074, s0.loss_cls: 0.0282, s0.acc: 98.9471, s0.loss_bbox: 0.0152, s1.loss_cls: 0.0193, s1.acc: 98.4985, s1.loss_bbox: 0.0272, s2.loss_cls: 0.0115, s2.acc: 98.0408, s2.loss_bbox: 0.0231, loss: 0.1356, grad_norm: 4.6710\n",
            "2020-09-07 08:17:13,198 - mmdet - INFO - Epoch [13][1472/5332]\tlr: 1.000e-05, eta: 23:23:10, time: 2.052, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0250, s0.acc: 98.9990, s0.loss_bbox: 0.0187, s1.loss_cls: 0.0171, s1.acc: 98.6298, s1.loss_bbox: 0.0320, s2.loss_cls: 0.0108, s2.acc: 98.1415, s2.loss_bbox: 0.0233, loss: 0.1336, grad_norm: 4.3607\n",
            "2020-09-07 08:19:24,227 - mmdet - INFO - Epoch [13][1536/5332]\tlr: 1.000e-05, eta: 23:21:00, time: 2.047, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0250, s0.acc: 98.9960, s0.loss_bbox: 0.0186, s1.loss_cls: 0.0148, s1.acc: 98.8373, s1.loss_bbox: 0.0305, s2.loss_cls: 0.0097, s2.acc: 98.4192, s2.loss_bbox: 0.0259, loss: 0.1306, grad_norm: 4.1464\n",
            "2020-09-07 08:21:37,366 - mmdet - INFO - Epoch [13][1600/5332]\tlr: 1.000e-05, eta: 23:19:03, time: 2.080, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0241, s0.acc: 99.0692, s0.loss_bbox: 0.0162, s1.loss_cls: 0.0160, s1.acc: 98.7762, s1.loss_bbox: 0.0308, s2.loss_cls: 0.0112, s2.acc: 98.1506, s2.loss_bbox: 0.0238, loss: 0.1295, grad_norm: 4.0935\n",
            "2020-09-07 08:23:46,897 - mmdet - INFO - Epoch [13][1664/5332]\tlr: 1.000e-05, eta: 23:16:44, time: 2.024, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0255, s0.acc: 98.9502, s0.loss_bbox: 0.0185, s1.loss_cls: 0.0169, s1.acc: 98.6542, s1.loss_bbox: 0.0323, s2.loss_cls: 0.0102, s2.acc: 98.3337, s2.loss_bbox: 0.0236, loss: 0.1388, grad_norm: 4.2297\n",
            "2020-09-07 08:25:59,211 - mmdet - INFO - Epoch [13][1728/5332]\tlr: 1.000e-05, eta: 23:14:42, time: 2.067, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0209, s0.acc: 99.1211, s0.loss_bbox: 0.0157, s1.loss_cls: 0.0136, s1.acc: 98.9349, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0096, s2.acc: 98.4253, s2.loss_bbox: 0.0234, loss: 0.1194, grad_norm: 3.8101\n",
            "2020-09-07 08:28:11,196 - mmdet - INFO - Epoch [13][1792/5332]\tlr: 1.000e-05, eta: 23:12:38, time: 2.062, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0225, s0.acc: 99.1547, s0.loss_bbox: 0.0130, s1.loss_cls: 0.0139, s1.acc: 98.8525, s1.loss_bbox: 0.0225, s2.loss_cls: 0.0075, s2.acc: 98.7518, s2.loss_bbox: 0.0202, loss: 0.1055, grad_norm: 4.0457\n",
            "2020-09-07 08:30:22,411 - mmdet - INFO - Epoch [13][1856/5332]\tlr: 1.000e-05, eta: 23:10:29, time: 2.050, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0066, s0.loss_cls: 0.0257, s0.acc: 98.9960, s0.loss_bbox: 0.0193, s1.loss_cls: 0.0180, s1.acc: 98.6755, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0117, s2.acc: 98.0347, s2.loss_bbox: 0.0231, loss: 0.1366, grad_norm: 4.0180\n",
            "2020-09-07 08:32:36,519 - mmdet - INFO - Epoch [13][1920/5332]\tlr: 1.000e-05, eta: 23:08:36, time: 2.095, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0247, s0.acc: 98.9838, s0.loss_bbox: 0.0216, s1.loss_cls: 0.0185, s1.acc: 98.4314, s1.loss_bbox: 0.0360, s2.loss_cls: 0.0117, s2.acc: 97.7478, s2.loss_bbox: 0.0253, loss: 0.1454, grad_norm: 4.4012\n",
            "2020-09-07 08:34:47,329 - mmdet - INFO - Epoch [13][1984/5332]\tlr: 1.000e-05, eta: 23:06:25, time: 2.044, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0200, s0.acc: 99.2065, s0.loss_bbox: 0.0122, s1.loss_cls: 0.0126, s1.acc: 98.9655, s1.loss_bbox: 0.0195, s2.loss_cls: 0.0082, s2.acc: 98.7183, s2.loss_bbox: 0.0163, loss: 0.0958, grad_norm: 3.5000\n",
            "2020-09-07 08:36:58,692 - mmdet - INFO - Epoch [13][2048/5332]\tlr: 1.000e-05, eta: 23:04:16, time: 2.053, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0327, s0.acc: 98.7549, s0.loss_bbox: 0.0197, s1.loss_cls: 0.0237, s1.acc: 98.3063, s1.loss_bbox: 0.0305, s2.loss_cls: 0.0127, s2.acc: 98.2635, s2.loss_bbox: 0.0227, loss: 0.1517, grad_norm: 4.8949\n",
            "2020-09-07 08:39:10,603 - mmdet - INFO - Epoch [13][2112/5332]\tlr: 1.000e-05, eta: 23:02:11, time: 2.061, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0218, s0.acc: 99.1241, s0.loss_bbox: 0.0193, s1.loss_cls: 0.0160, s1.acc: 98.6328, s1.loss_bbox: 0.0341, s2.loss_cls: 0.0103, s2.acc: 98.2971, s2.loss_bbox: 0.0297, loss: 0.1377, grad_norm: 4.2914\n",
            "2020-09-07 08:41:23,229 - mmdet - INFO - Epoch [13][2176/5332]\tlr: 1.000e-05, eta: 23:00:09, time: 2.072, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0252, s0.acc: 98.9990, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0169, s1.acc: 98.6023, s1.loss_bbox: 0.0310, s2.loss_cls: 0.0109, s2.acc: 98.1323, s2.loss_bbox: 0.0280, loss: 0.1358, grad_norm: 4.5775\n",
            "2020-09-07 08:43:35,330 - mmdet - INFO - Epoch [13][2240/5332]\tlr: 1.000e-05, eta: 22:58:05, time: 2.064, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0254, s0.acc: 99.0540, s0.loss_bbox: 0.0190, s1.loss_cls: 0.0166, s1.acc: 98.7122, s1.loss_bbox: 0.0301, s2.loss_cls: 0.0111, s2.acc: 98.2086, s2.loss_bbox: 0.0238, loss: 0.1344, grad_norm: 3.8997\n",
            "2020-09-07 08:45:47,460 - mmdet - INFO - Epoch [13][2304/5332]\tlr: 1.000e-05, eta: 22:56:00, time: 2.065, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0277, s0.acc: 98.8953, s0.loss_bbox: 0.0186, s1.loss_cls: 0.0188, s1.acc: 98.5443, s1.loss_bbox: 0.0301, s2.loss_cls: 0.0115, s2.acc: 98.1750, s2.loss_bbox: 0.0225, loss: 0.1349, grad_norm: 4.1970\n",
            "2020-09-07 08:47:59,374 - mmdet - INFO - Epoch [13][2368/5332]\tlr: 1.000e-05, eta: 22:53:54, time: 2.061, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0239, s0.acc: 99.0143, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0169, s1.acc: 98.5840, s1.loss_bbox: 0.0350, s2.loss_cls: 0.0115, s2.acc: 97.8821, s2.loss_bbox: 0.0309, loss: 0.1453, grad_norm: 4.8120\n",
            "2020-09-07 08:50:12,181 - mmdet - INFO - Epoch [13][2432/5332]\tlr: 1.000e-05, eta: 22:51:53, time: 2.075, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0268, s0.acc: 98.9319, s0.loss_bbox: 0.0191, s1.loss_cls: 0.0172, s1.acc: 98.7335, s1.loss_bbox: 0.0303, s2.loss_cls: 0.0116, s2.acc: 98.1201, s2.loss_bbox: 0.0245, loss: 0.1390, grad_norm: 4.5647\n",
            "2020-09-07 08:52:23,910 - mmdet - INFO - Epoch [13][2496/5332]\tlr: 1.000e-05, eta: 22:49:46, time: 2.058, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0258, s0.acc: 98.9807, s0.loss_bbox: 0.0202, s1.loss_cls: 0.0173, s1.acc: 98.6755, s1.loss_bbox: 0.0328, s2.loss_cls: 0.0095, s2.acc: 98.6267, s2.loss_bbox: 0.0253, loss: 0.1386, grad_norm: 4.4642\n",
            "2020-09-07 08:54:36,881 - mmdet - INFO - Epoch [13][2560/5332]\tlr: 1.000e-05, eta: 22:47:45, time: 2.078, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0197, s0.acc: 99.1699, s0.loss_bbox: 0.0140, s1.loss_cls: 0.0127, s1.acc: 99.0295, s1.loss_bbox: 0.0250, s2.loss_cls: 0.0087, s2.acc: 98.6176, s2.loss_bbox: 0.0219, loss: 0.1083, grad_norm: 3.8737\n",
            "2020-09-07 08:56:48,738 - mmdet - INFO - Epoch [13][2624/5332]\tlr: 1.000e-05, eta: 22:45:38, time: 2.060, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0244, s0.acc: 99.0051, s0.loss_bbox: 0.0168, s1.loss_cls: 0.0160, s1.acc: 98.6969, s1.loss_bbox: 0.0279, s2.loss_cls: 0.0092, s2.acc: 98.4985, s2.loss_bbox: 0.0225, loss: 0.1242, grad_norm: 4.2973\n",
            "2020-09-07 08:59:01,418 - mmdet - INFO - Epoch [13][2688/5332]\tlr: 1.000e-05, eta: 22:43:36, time: 2.073, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0231, s0.acc: 99.1119, s0.loss_bbox: 0.0188, s1.loss_cls: 0.0159, s1.acc: 98.8251, s1.loss_bbox: 0.0317, s2.loss_cls: 0.0104, s2.acc: 98.5077, s2.loss_bbox: 0.0260, loss: 0.1336, grad_norm: 4.1295\n",
            "2020-09-07 09:01:12,827 - mmdet - INFO - Epoch [13][2752/5332]\tlr: 1.000e-05, eta: 22:41:27, time: 2.053, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0111, loss_rpn_bbox: 0.0062, s0.loss_cls: 0.0239, s0.acc: 99.0265, s0.loss_bbox: 0.0173, s1.loss_cls: 0.0175, s1.acc: 98.6542, s1.loss_bbox: 0.0267, s2.loss_cls: 0.0115, s2.acc: 98.0957, s2.loss_bbox: 0.0212, loss: 0.1355, grad_norm: 4.4793\n",
            "2020-09-07 09:03:23,513 - mmdet - INFO - Epoch [13][2816/5332]\tlr: 1.000e-05, eta: 22:39:14, time: 2.042, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0221, s0.acc: 99.1180, s0.loss_bbox: 0.0158, s1.loss_cls: 0.0138, s1.acc: 98.8525, s1.loss_bbox: 0.0314, s2.loss_cls: 0.0097, s2.acc: 98.3429, s2.loss_bbox: 0.0255, loss: 0.1258, grad_norm: 4.4181\n",
            "2020-09-07 09:05:35,592 - mmdet - INFO - Epoch [13][2880/5332]\tlr: 1.000e-05, eta: 22:37:08, time: 2.064, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0256, s0.acc: 98.9319, s0.loss_bbox: 0.0178, s1.loss_cls: 0.0165, s1.acc: 98.6603, s1.loss_bbox: 0.0299, s2.loss_cls: 0.0099, s2.acc: 98.2819, s2.loss_bbox: 0.0263, loss: 0.1341, grad_norm: 4.9392\n",
            "2020-09-07 09:07:48,036 - mmdet - INFO - Epoch [13][2944/5332]\tlr: 1.000e-05, eta: 22:35:04, time: 2.069, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0226, s0.acc: 99.0967, s0.loss_bbox: 0.0195, s1.loss_cls: 0.0152, s1.acc: 98.7122, s1.loss_bbox: 0.0356, s2.loss_cls: 0.0102, s2.acc: 98.1506, s2.loss_bbox: 0.0269, loss: 0.1375, grad_norm: 4.4742\n",
            "2020-09-07 09:10:00,360 - mmdet - INFO - Epoch [13][3008/5332]\tlr: 1.000e-05, eta: 22:32:59, time: 2.068, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0061, s0.loss_cls: 0.0248, s0.acc: 98.9502, s0.loss_bbox: 0.0181, s1.loss_cls: 0.0168, s1.acc: 98.5443, s1.loss_bbox: 0.0318, s2.loss_cls: 0.0106, s2.acc: 97.9919, s2.loss_bbox: 0.0245, loss: 0.1364, grad_norm: 4.2568\n",
            "2020-09-07 09:12:11,023 - mmdet - INFO - Epoch [13][3072/5332]\tlr: 1.000e-05, eta: 22:30:46, time: 2.042, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0206, s0.acc: 99.1943, s0.loss_bbox: 0.0126, s1.loss_cls: 0.0132, s1.acc: 98.9868, s1.loss_bbox: 0.0260, s2.loss_cls: 0.0085, s2.acc: 98.7518, s2.loss_bbox: 0.0246, loss: 0.1129, grad_norm: 4.2070\n",
            "2020-09-07 09:14:22,644 - mmdet - INFO - Epoch [13][3136/5332]\tlr: 1.000e-05, eta: 22:28:38, time: 2.057, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0262, s0.acc: 99.0082, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0164, s1.acc: 98.7183, s1.loss_bbox: 0.0290, s2.loss_cls: 0.0104, s2.acc: 98.3307, s2.loss_bbox: 0.0228, loss: 0.1282, grad_norm: 4.5096\n",
            "2020-09-07 09:16:33,457 - mmdet - INFO - Epoch [13][3200/5332]\tlr: 1.000e-05, eta: 22:26:26, time: 2.044, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0231, s0.acc: 99.1089, s0.loss_bbox: 0.0142, s1.loss_cls: 0.0151, s1.acc: 98.7457, s1.loss_bbox: 0.0194, s2.loss_cls: 0.0095, s2.acc: 98.3551, s2.loss_bbox: 0.0167, loss: 0.1052, grad_norm: 3.6266\n",
            "2020-09-07 09:18:44,821 - mmdet - INFO - Epoch [13][3264/5332]\tlr: 1.000e-05, eta: 22:24:16, time: 2.053, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0236, s0.acc: 99.0295, s0.loss_bbox: 0.0171, s1.loss_cls: 0.0154, s1.acc: 98.7183, s1.loss_bbox: 0.0282, s2.loss_cls: 0.0098, s2.acc: 98.4619, s2.loss_bbox: 0.0253, loss: 0.1266, grad_norm: 4.0026\n",
            "2020-09-07 09:20:55,980 - mmdet - INFO - Epoch [13][3328/5332]\tlr: 1.000e-05, eta: 22:22:06, time: 2.049, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0237, s0.acc: 99.0387, s0.loss_bbox: 0.0157, s1.loss_cls: 0.0152, s1.acc: 98.7549, s1.loss_bbox: 0.0264, s2.loss_cls: 0.0092, s2.acc: 98.6572, s2.loss_bbox: 0.0220, loss: 0.1186, grad_norm: 4.2433\n",
            "2020-09-07 09:23:06,788 - mmdet - INFO - Epoch [13][3392/5332]\tlr: 1.000e-05, eta: 22:19:54, time: 2.044, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0023, s0.loss_cls: 0.0214, s0.acc: 99.1180, s0.loss_bbox: 0.0130, s1.loss_cls: 0.0134, s1.acc: 98.8770, s1.loss_bbox: 0.0232, s2.loss_cls: 0.0076, s2.acc: 98.7854, s2.loss_bbox: 0.0191, loss: 0.1022, grad_norm: 3.6504\n",
            "2020-09-07 09:25:18,607 - mmdet - INFO - Epoch [13][3456/5332]\tlr: 1.000e-05, eta: 22:17:46, time: 2.060, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0238, s0.acc: 99.1119, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0161, s1.acc: 98.7305, s1.loss_bbox: 0.0308, s2.loss_cls: 0.0107, s2.acc: 98.1384, s2.loss_bbox: 0.0233, loss: 0.1322, grad_norm: 4.5382\n",
            "2020-09-07 09:27:28,481 - mmdet - INFO - Epoch [13][3520/5332]\tlr: 1.000e-05, eta: 22:15:30, time: 2.029, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0200, s0.acc: 99.2920, s0.loss_bbox: 0.0142, s1.loss_cls: 0.0118, s1.acc: 99.1455, s1.loss_bbox: 0.0248, s2.loss_cls: 0.0081, s2.acc: 98.7762, s2.loss_bbox: 0.0244, loss: 0.1113, grad_norm: 3.9195\n",
            "2020-09-07 09:29:41,806 - mmdet - INFO - Epoch [13][3584/5332]\tlr: 1.000e-05, eta: 22:13:29, time: 2.083, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0078, loss_rpn_bbox: 0.0078, s0.loss_cls: 0.0301, s0.acc: 98.9594, s0.loss_bbox: 0.0194, s1.loss_cls: 0.0185, s1.acc: 98.7183, s1.loss_bbox: 0.0262, s2.loss_cls: 0.0101, s2.acc: 98.5535, s2.loss_bbox: 0.0222, loss: 0.1421, grad_norm: 4.4853\n",
            "2020-09-07 09:31:53,565 - mmdet - INFO - Epoch [13][3648/5332]\tlr: 1.000e-05, eta: 22:11:21, time: 2.059, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0238, s0.acc: 98.9380, s0.loss_bbox: 0.0187, s1.loss_cls: 0.0158, s1.acc: 98.5962, s1.loss_bbox: 0.0332, s2.loss_cls: 0.0100, s2.acc: 98.3002, s2.loss_bbox: 0.0254, loss: 0.1346, grad_norm: 4.8411\n",
            "2020-09-07 09:34:05,147 - mmdet - INFO - Epoch [13][3712/5332]\tlr: 1.000e-05, eta: 22:09:12, time: 2.056, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0269, s0.acc: 98.9716, s0.loss_bbox: 0.0188, s1.loss_cls: 0.0163, s1.acc: 98.7091, s1.loss_bbox: 0.0296, s2.loss_cls: 0.0106, s2.acc: 98.3673, s2.loss_bbox: 0.0269, loss: 0.1374, grad_norm: 4.5539\n",
            "2020-09-07 09:36:16,668 - mmdet - INFO - Epoch [13][3776/5332]\tlr: 1.000e-05, eta: 22:07:03, time: 2.055, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0217, s0.acc: 99.1608, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0143, s1.acc: 98.8342, s1.loss_bbox: 0.0297, s2.loss_cls: 0.0093, s2.acc: 98.3704, s2.loss_bbox: 0.0198, loss: 0.1197, grad_norm: 4.0786\n",
            "2020-09-07 09:38:27,343 - mmdet - INFO - Epoch [13][3840/5332]\tlr: 1.000e-05, eta: 22:04:50, time: 2.042, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0244, s0.acc: 99.1119, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0156, s1.acc: 98.7396, s1.loss_bbox: 0.0332, s2.loss_cls: 0.0109, s2.acc: 97.9675, s2.loss_bbox: 0.0269, loss: 0.1383, grad_norm: 4.4711\n",
            "2020-09-07 09:40:38,120 - mmdet - INFO - Epoch [13][3904/5332]\tlr: 1.000e-05, eta: 22:02:38, time: 2.043, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0067, s0.loss_cls: 0.0265, s0.acc: 98.9990, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0164, s1.acc: 98.5779, s1.loss_bbox: 0.0297, s2.loss_cls: 0.0109, s2.acc: 98.1140, s2.loss_bbox: 0.0239, loss: 0.1354, grad_norm: 4.4706\n",
            "2020-09-07 09:42:50,456 - mmdet - INFO - Epoch [13][3968/5332]\tlr: 1.000e-05, eta: 22:00:32, time: 2.068, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0021, s0.loss_cls: 0.0245, s0.acc: 99.0906, s0.loss_bbox: 0.0162, s1.loss_cls: 0.0142, s1.acc: 98.8770, s1.loss_bbox: 0.0314, s2.loss_cls: 0.0092, s2.acc: 98.3154, s2.loss_bbox: 0.0285, loss: 0.1291, grad_norm: 4.6014\n",
            "2020-09-07 09:45:01,088 - mmdet - INFO - Epoch [13][4032/5332]\tlr: 1.000e-05, eta: 21:58:19, time: 2.041, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0244, s0.acc: 99.1425, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0157, s1.acc: 98.9044, s1.loss_bbox: 0.0295, s2.loss_cls: 0.0111, s2.acc: 98.2361, s2.loss_bbox: 0.0247, loss: 0.1293, grad_norm: 4.1251\n",
            "2020-09-07 09:47:13,538 - mmdet - INFO - Epoch [13][4096/5332]\tlr: 1.000e-05, eta: 21:56:14, time: 2.070, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0261, s0.acc: 98.9349, s0.loss_bbox: 0.0178, s1.loss_cls: 0.0169, s1.acc: 98.6023, s1.loss_bbox: 0.0255, s2.loss_cls: 0.0096, s2.acc: 98.3521, s2.loss_bbox: 0.0193, loss: 0.1244, grad_norm: 3.9556\n",
            "2020-09-07 09:49:24,177 - mmdet - INFO - Epoch [13][4160/5332]\tlr: 1.000e-05, eta: 21:54:01, time: 2.041, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0230, s0.acc: 99.0173, s0.loss_bbox: 0.0161, s1.loss_cls: 0.0146, s1.acc: 98.8098, s1.loss_bbox: 0.0266, s2.loss_cls: 0.0085, s2.acc: 98.4497, s2.loss_bbox: 0.0222, loss: 0.1184, grad_norm: 3.9890\n",
            "2020-09-07 09:51:36,738 - mmdet - INFO - Epoch [13][4224/5332]\tlr: 1.000e-05, eta: 21:51:56, time: 2.071, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0223, s0.acc: 99.1425, s0.loss_bbox: 0.0158, s1.loss_cls: 0.0143, s1.acc: 99.0448, s1.loss_bbox: 0.0262, s2.loss_cls: 0.0087, s2.acc: 98.6450, s2.loss_bbox: 0.0233, loss: 0.1180, grad_norm: 4.1981\n",
            "2020-09-07 09:53:47,159 - mmdet - INFO - Epoch [13][4288/5332]\tlr: 1.000e-05, eta: 21:49:42, time: 2.038, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0072, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0235, s0.acc: 99.1241, s0.loss_bbox: 0.0162, s1.loss_cls: 0.0151, s1.acc: 98.7213, s1.loss_bbox: 0.0311, s2.loss_cls: 0.0099, s2.acc: 98.2391, s2.loss_bbox: 0.0249, loss: 0.1330, grad_norm: 4.5587\n",
            "2020-09-07 09:55:58,258 - mmdet - INFO - Epoch [13][4352/5332]\tlr: 1.000e-05, eta: 21:47:31, time: 2.048, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0061, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0228, s0.acc: 99.1638, s0.loss_bbox: 0.0133, s1.loss_cls: 0.0143, s1.acc: 98.8922, s1.loss_bbox: 0.0214, s2.loss_cls: 0.0089, s2.acc: 98.4741, s2.loss_bbox: 0.0194, loss: 0.1121, grad_norm: 4.0592\n",
            "2020-09-07 09:58:09,746 - mmdet - INFO - Epoch [13][4416/5332]\tlr: 1.000e-05, eta: 21:45:22, time: 2.054, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0243, s0.acc: 98.9594, s0.loss_bbox: 0.0200, s1.loss_cls: 0.0148, s1.acc: 98.7488, s1.loss_bbox: 0.0331, s2.loss_cls: 0.0095, s2.acc: 98.3795, s2.loss_bbox: 0.0266, loss: 0.1360, grad_norm: 4.4933\n",
            "2020-09-07 10:00:22,063 - mmdet - INFO - Epoch [13][4480/5332]\tlr: 1.000e-05, eta: 21:43:15, time: 2.067, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0226, s0.acc: 99.0875, s0.loss_bbox: 0.0176, s1.loss_cls: 0.0153, s1.acc: 98.7427, s1.loss_bbox: 0.0365, s2.loss_cls: 0.0098, s2.acc: 98.3154, s2.loss_bbox: 0.0315, loss: 0.1408, grad_norm: 4.9382\n",
            "2020-09-07 10:02:32,342 - mmdet - INFO - Epoch [13][4544/5332]\tlr: 1.000e-05, eta: 21:41:01, time: 2.036, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0067, s0.loss_cls: 0.0260, s0.acc: 98.9044, s0.loss_bbox: 0.0168, s1.loss_cls: 0.0165, s1.acc: 98.6938, s1.loss_bbox: 0.0246, s2.loss_cls: 0.0107, s2.acc: 98.3185, s2.loss_bbox: 0.0209, loss: 0.1256, grad_norm: 4.4013\n",
            "2020-09-07 10:04:42,814 - mmdet - INFO - Epoch [13][4608/5332]\tlr: 1.000e-05, eta: 21:38:48, time: 2.039, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0068, s0.loss_cls: 0.0237, s0.acc: 99.0356, s0.loss_bbox: 0.0185, s1.loss_cls: 0.0150, s1.acc: 98.7213, s1.loss_bbox: 0.0317, s2.loss_cls: 0.0093, s2.acc: 98.6542, s2.loss_bbox: 0.0257, loss: 0.1350, grad_norm: 4.6825\n",
            "2020-09-07 10:06:53,758 - mmdet - INFO - Epoch [13][4672/5332]\tlr: 1.000e-05, eta: 21:36:36, time: 2.046, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0207, s0.acc: 99.1882, s0.loss_bbox: 0.0161, s1.loss_cls: 0.0129, s1.acc: 98.9777, s1.loss_bbox: 0.0281, s2.loss_cls: 0.0091, s2.acc: 98.4283, s2.loss_bbox: 0.0233, loss: 0.1194, grad_norm: 3.9914\n",
            "2020-09-07 10:09:04,841 - mmdet - INFO - Epoch [13][4736/5332]\tlr: 1.000e-05, eta: 21:34:25, time: 2.048, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0326, s0.acc: 98.8220, s0.loss_bbox: 0.0206, s1.loss_cls: 0.0197, s1.acc: 98.4863, s1.loss_bbox: 0.0319, s2.loss_cls: 0.0125, s2.acc: 97.9431, s2.loss_bbox: 0.0254, loss: 0.1504, grad_norm: 4.7726\n",
            "2020-09-07 10:11:15,692 - mmdet - INFO - Epoch [13][4800/5332]\tlr: 1.000e-05, eta: 21:32:13, time: 2.045, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0075, s0.loss_cls: 0.0269, s0.acc: 98.9197, s0.loss_bbox: 0.0212, s1.loss_cls: 0.0180, s1.acc: 98.6450, s1.loss_bbox: 0.0291, s2.loss_cls: 0.0108, s2.acc: 98.3063, s2.loss_bbox: 0.0241, loss: 0.1426, grad_norm: 4.4869\n",
            "2020-09-07 10:13:26,351 - mmdet - INFO - Epoch [13][4864/5332]\tlr: 1.000e-05, eta: 21:30:00, time: 2.042, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0220, s0.acc: 99.1364, s0.loss_bbox: 0.0165, s1.loss_cls: 0.0140, s1.acc: 98.8495, s1.loss_bbox: 0.0306, s2.loss_cls: 0.0089, s2.acc: 98.5016, s2.loss_bbox: 0.0266, loss: 0.1266, grad_norm: 4.5958\n",
            "2020-09-07 10:15:39,539 - mmdet - INFO - Epoch [13][4928/5332]\tlr: 1.000e-05, eta: 21:27:57, time: 2.081, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0067, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0229, s0.acc: 99.1089, s0.loss_bbox: 0.0168, s1.loss_cls: 0.0141, s1.acc: 98.9227, s1.loss_bbox: 0.0268, s2.loss_cls: 0.0091, s2.acc: 98.5046, s2.loss_bbox: 0.0239, loss: 0.1255, grad_norm: 4.3661\n",
            "2020-09-07 10:17:50,824 - mmdet - INFO - Epoch [13][4992/5332]\tlr: 1.000e-05, eta: 21:25:47, time: 2.051, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0058, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0283, s0.acc: 98.8190, s0.loss_bbox: 0.0202, s1.loss_cls: 0.0182, s1.acc: 98.4161, s1.loss_bbox: 0.0333, s2.loss_cls: 0.0114, s2.acc: 97.8729, s2.loss_bbox: 0.0281, loss: 0.1483, grad_norm: 5.2944\n",
            "2020-09-07 10:20:02,905 - mmdet - INFO - Epoch [13][5056/5332]\tlr: 1.000e-05, eta: 21:23:39, time: 2.064, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0292, s0.acc: 98.9136, s0.loss_bbox: 0.0181, s1.loss_cls: 0.0200, s1.acc: 98.4497, s1.loss_bbox: 0.0260, s2.loss_cls: 0.0129, s2.acc: 97.9614, s2.loss_bbox: 0.0218, loss: 0.1375, grad_norm: 4.2823\n",
            "2020-09-07 10:22:15,195 - mmdet - INFO - Epoch [13][5120/5332]\tlr: 1.000e-05, eta: 21:21:32, time: 2.067, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0257, s0.acc: 99.0021, s0.loss_bbox: 0.0180, s1.loss_cls: 0.0155, s1.acc: 98.7793, s1.loss_bbox: 0.0318, s2.loss_cls: 0.0097, s2.acc: 98.4741, s2.loss_bbox: 0.0268, loss: 0.1353, grad_norm: 4.5628\n",
            "2020-09-07 10:24:26,879 - mmdet - INFO - Epoch [13][5184/5332]\tlr: 1.000e-05, eta: 21:19:23, time: 2.058, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0245, s0.acc: 99.0082, s0.loss_bbox: 0.0178, s1.loss_cls: 0.0166, s1.acc: 98.6572, s1.loss_bbox: 0.0287, s2.loss_cls: 0.0108, s2.acc: 98.4283, s2.loss_bbox: 0.0234, loss: 0.1303, grad_norm: 4.4649\n",
            "2020-09-07 10:26:37,828 - mmdet - INFO - Epoch [13][5248/5332]\tlr: 1.000e-05, eta: 21:17:12, time: 2.046, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0081, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0331, s0.acc: 98.7274, s0.loss_bbox: 0.0204, s1.loss_cls: 0.0189, s1.acc: 98.4344, s1.loss_bbox: 0.0307, s2.loss_cls: 0.0116, s2.acc: 98.2056, s2.loss_bbox: 0.0263, loss: 0.1545, grad_norm: 5.4998\n",
            "2020-09-07 10:28:50,249 - mmdet - INFO - Epoch [13][5312/5332]\tlr: 1.000e-05, eta: 21:15:05, time: 2.069, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0241, s0.acc: 99.1425, s0.loss_bbox: 0.0148, s1.loss_cls: 0.0141, s1.acc: 98.8953, s1.loss_bbox: 0.0241, s2.loss_cls: 0.0090, s2.acc: 98.5992, s2.loss_bbox: 0.0227, loss: 0.1147, grad_norm: 3.9856\n",
            "2020-09-07 10:29:31,932 - mmdet - INFO - Saving checkpoint at 13 epochs\n",
            "[>>] 667/667, 0.6 task/s, elapsed: 1189s, ETA:     0s2020-09-07 10:49:28,026 - mmdet - INFO - \n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 82  | 234  | 0.841  | 0.584 |\n",
            "| 3     | 22  | 100  | 0.818  | 0.713 |\n",
            "| 4     | 529 | 1178 | 0.924  | 0.830 |\n",
            "| 5     | 78  | 175  | 0.885  | 0.792 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.730 |\n",
            "+-------+-----+------+--------+-------+\n",
            "2020-09-07 10:49:28,030 - mmdet - INFO - Epoch(val) [13][5332]\tmAP: 0.7297\n",
            "2020-09-07 10:51:41,092 - mmdet - INFO - Epoch [14][64/5332]\tlr: 1.000e-05, eta: 21:09:58, time: 2.079, data_time: 0.037, memory: 7874, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0229, s0.acc: 99.0570, s0.loss_bbox: 0.0171, s1.loss_cls: 0.0154, s1.acc: 98.8800, s1.loss_bbox: 0.0272, s2.loss_cls: 0.0099, s2.acc: 98.4314, s2.loss_bbox: 0.0254, loss: 0.1242, grad_norm: 4.3875\n",
            "2020-09-07 10:53:54,851 - mmdet - INFO - Epoch [14][128/5332]\tlr: 1.000e-05, eta: 21:07:57, time: 2.090, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0210, s0.acc: 99.0906, s0.loss_bbox: 0.0132, s1.loss_cls: 0.0142, s1.acc: 98.8403, s1.loss_bbox: 0.0254, s2.loss_cls: 0.0087, s2.acc: 98.4711, s2.loss_bbox: 0.0239, loss: 0.1134, grad_norm: 3.9094\n",
            "2020-09-07 10:56:05,998 - mmdet - INFO - Epoch [14][192/5332]\tlr: 1.000e-05, eta: 21:05:46, time: 2.049, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0215, s0.acc: 99.2065, s0.loss_bbox: 0.0135, s1.loss_cls: 0.0137, s1.acc: 98.9075, s1.loss_bbox: 0.0245, s2.loss_cls: 0.0077, s2.acc: 98.8068, s2.loss_bbox: 0.0215, loss: 0.1098, grad_norm: 3.8510\n",
            "2020-09-07 10:58:18,099 - mmdet - INFO - Epoch [14][256/5332]\tlr: 1.000e-05, eta: 21:03:40, time: 2.064, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0213, s0.acc: 99.2279, s0.loss_bbox: 0.0141, s1.loss_cls: 0.0147, s1.acc: 98.9075, s1.loss_bbox: 0.0240, s2.loss_cls: 0.0096, s2.acc: 98.5535, s2.loss_bbox: 0.0210, loss: 0.1132, grad_norm: 4.0113\n",
            "2020-09-07 11:00:29,635 - mmdet - INFO - Epoch [14][320/5332]\tlr: 1.000e-05, eta: 21:01:31, time: 2.055, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0263, s0.acc: 98.9441, s0.loss_bbox: 0.0229, s1.loss_cls: 0.0202, s1.acc: 98.3429, s1.loss_bbox: 0.0279, s2.loss_cls: 0.0115, s2.acc: 97.9218, s2.loss_bbox: 0.0183, loss: 0.1381, grad_norm: 4.4485\n",
            "2020-09-07 11:02:41,862 - mmdet - INFO - Epoch [14][384/5332]\tlr: 1.000e-05, eta: 20:59:24, time: 2.066, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0215, s0.acc: 99.1119, s0.loss_bbox: 0.0164, s1.loss_cls: 0.0141, s1.acc: 98.9288, s1.loss_bbox: 0.0254, s2.loss_cls: 0.0088, s2.acc: 98.5992, s2.loss_bbox: 0.0210, loss: 0.1177, grad_norm: 4.1780\n",
            "2020-09-07 11:04:52,510 - mmdet - INFO - Epoch [14][448/5332]\tlr: 1.000e-05, eta: 20:57:13, time: 2.041, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0233, s0.acc: 99.0753, s0.loss_bbox: 0.0152, s1.loss_cls: 0.0129, s1.acc: 99.0631, s1.loss_bbox: 0.0249, s2.loss_cls: 0.0085, s2.acc: 98.6603, s2.loss_bbox: 0.0243, loss: 0.1176, grad_norm: 3.9627\n",
            "2020-09-07 11:07:03,174 - mmdet - INFO - Epoch [14][512/5332]\tlr: 1.000e-05, eta: 20:55:01, time: 2.042, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0268, s0.acc: 98.9594, s0.loss_bbox: 0.0185, s1.loss_cls: 0.0178, s1.acc: 98.6328, s1.loss_bbox: 0.0287, s2.loss_cls: 0.0110, s2.acc: 98.2727, s2.loss_bbox: 0.0219, loss: 0.1316, grad_norm: 4.3144\n",
            "2020-09-07 11:09:14,127 - mmdet - INFO - Epoch [14][576/5332]\tlr: 1.000e-05, eta: 20:52:50, time: 2.046, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0236, s0.acc: 99.1058, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0157, s1.acc: 98.8770, s1.loss_bbox: 0.0280, s2.loss_cls: 0.0102, s2.acc: 98.5748, s2.loss_bbox: 0.0236, loss: 0.1249, grad_norm: 4.0622\n",
            "2020-09-07 11:11:26,282 - mmdet - INFO - Epoch [14][640/5332]\tlr: 1.000e-05, eta: 20:50:43, time: 2.065, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0197, s0.acc: 99.2493, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0135, s1.acc: 98.8800, s1.loss_bbox: 0.0311, s2.loss_cls: 0.0090, s2.acc: 98.4558, s2.loss_bbox: 0.0277, loss: 0.1245, grad_norm: 4.3335\n",
            "2020-09-07 11:13:38,220 - mmdet - INFO - Epoch [14][704/5332]\tlr: 1.000e-05, eta: 20:48:35, time: 2.062, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0247, s0.acc: 98.9532, s0.loss_bbox: 0.0196, s1.loss_cls: 0.0186, s1.acc: 98.6298, s1.loss_bbox: 0.0305, s2.loss_cls: 0.0125, s2.acc: 98.2178, s2.loss_bbox: 0.0233, loss: 0.1399, grad_norm: 4.4851\n",
            "2020-09-07 11:15:50,776 - mmdet - INFO - Epoch [14][768/5332]\tlr: 1.000e-05, eta: 20:46:30, time: 2.071, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0232, s0.acc: 99.0845, s0.loss_bbox: 0.0169, s1.loss_cls: 0.0134, s1.acc: 98.9075, s1.loss_bbox: 0.0306, s2.loss_cls: 0.0083, s2.acc: 98.5931, s2.loss_bbox: 0.0246, loss: 0.1241, grad_norm: 4.7288\n",
            "2020-09-07 11:18:01,381 - mmdet - INFO - Epoch [14][832/5332]\tlr: 1.000e-05, eta: 20:44:18, time: 2.041, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0213, s0.acc: 99.0967, s0.loss_bbox: 0.0169, s1.loss_cls: 0.0133, s1.acc: 98.9136, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0088, s2.acc: 98.6603, s2.loss_bbox: 0.0278, loss: 0.1268, grad_norm: 4.5199\n",
            "2020-09-07 11:20:13,297 - mmdet - INFO - Epoch [14][896/5332]\tlr: 1.000e-05, eta: 20:42:10, time: 2.061, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0240, s0.acc: 99.0662, s0.loss_bbox: 0.0188, s1.loss_cls: 0.0156, s1.acc: 98.7335, s1.loss_bbox: 0.0302, s2.loss_cls: 0.0105, s2.acc: 98.3246, s2.loss_bbox: 0.0257, loss: 0.1333, grad_norm: 4.5028\n",
            "2020-09-07 11:22:24,889 - mmdet - INFO - Epoch [14][960/5332]\tlr: 1.000e-05, eta: 20:40:01, time: 2.056, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0230, s0.acc: 99.0631, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0159, s1.acc: 98.6816, s1.loss_bbox: 0.0326, s2.loss_cls: 0.0108, s2.acc: 98.2666, s2.loss_bbox: 0.0272, loss: 0.1346, grad_norm: 4.3555\n",
            "2020-09-07 11:24:35,727 - mmdet - INFO - Epoch [14][1024/5332]\tlr: 1.000e-05, eta: 20:37:50, time: 2.044, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0224, s0.acc: 99.1882, s0.loss_bbox: 0.0143, s1.loss_cls: 0.0133, s1.acc: 98.9563, s1.loss_bbox: 0.0245, s2.loss_cls: 0.0083, s2.acc: 98.7518, s2.loss_bbox: 0.0229, loss: 0.1152, grad_norm: 3.9390\n",
            "2020-09-07 11:26:48,855 - mmdet - INFO - Epoch [14][1088/5332]\tlr: 1.000e-05, eta: 20:35:45, time: 2.080, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0270, s0.acc: 98.8739, s0.loss_bbox: 0.0171, s1.loss_cls: 0.0186, s1.acc: 98.5229, s1.loss_bbox: 0.0257, s2.loss_cls: 0.0117, s2.acc: 98.2574, s2.loss_bbox: 0.0194, loss: 0.1294, grad_norm: 4.3997\n",
            "2020-09-07 11:29:01,073 - mmdet - INFO - Epoch [14][1152/5332]\tlr: 1.000e-05, eta: 20:33:38, time: 2.066, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0211, s0.acc: 99.0906, s0.loss_bbox: 0.0159, s1.loss_cls: 0.0133, s1.acc: 98.9594, s1.loss_bbox: 0.0226, s2.loss_cls: 0.0086, s2.acc: 98.6786, s2.loss_bbox: 0.0198, loss: 0.1093, grad_norm: 3.7824\n",
            "2020-09-07 11:31:11,894 - mmdet - INFO - Epoch [14][1216/5332]\tlr: 1.000e-05, eta: 20:31:27, time: 2.044, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0242, s0.acc: 99.0845, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0171, s1.acc: 98.6267, s1.loss_bbox: 0.0265, s2.loss_cls: 0.0108, s2.acc: 98.1995, s2.loss_bbox: 0.0219, loss: 0.1267, grad_norm: 4.3886\n",
            "2020-09-07 11:33:25,776 - mmdet - INFO - Epoch [14][1280/5332]\tlr: 1.000e-05, eta: 20:29:25, time: 2.092, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0075, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0259, s0.acc: 99.0540, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0167, s1.acc: 98.7427, s1.loss_bbox: 0.0324, s2.loss_cls: 0.0102, s2.acc: 98.2574, s2.loss_bbox: 0.0246, loss: 0.1415, grad_norm: 4.5542\n",
            "2020-09-07 11:35:37,595 - mmdet - INFO - Epoch [14][1344/5332]\tlr: 1.000e-05, eta: 20:27:16, time: 2.060, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0198, s0.acc: 99.2188, s0.loss_bbox: 0.0149, s1.loss_cls: 0.0122, s1.acc: 99.0631, s1.loss_bbox: 0.0281, s2.loss_cls: 0.0101, s2.acc: 98.4680, s2.loss_bbox: 0.0206, loss: 0.1115, grad_norm: 4.0562\n",
            "2020-09-07 11:37:49,011 - mmdet - INFO - Epoch [14][1408/5332]\tlr: 1.000e-05, eta: 20:25:07, time: 2.053, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0282, s0.acc: 98.8739, s0.loss_bbox: 0.0195, s1.loss_cls: 0.0164, s1.acc: 98.6328, s1.loss_bbox: 0.0304, s2.loss_cls: 0.0110, s2.acc: 98.1293, s2.loss_bbox: 0.0260, loss: 0.1393, grad_norm: 4.6733\n",
            "2020-09-07 11:40:01,742 - mmdet - INFO - Epoch [14][1472/5332]\tlr: 1.000e-05, eta: 20:23:01, time: 2.074, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0233, s0.acc: 99.0326, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0134, s1.acc: 98.9685, s1.loss_bbox: 0.0255, s2.loss_cls: 0.0083, s2.acc: 98.7061, s2.loss_bbox: 0.0231, loss: 0.1142, grad_norm: 4.1587\n",
            "2020-09-07 11:42:13,050 - mmdet - INFO - Epoch [14][1536/5332]\tlr: 1.000e-05, eta: 20:20:51, time: 2.052, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0247, s0.acc: 99.0387, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0174, s1.acc: 98.7823, s1.loss_bbox: 0.0291, s2.loss_cls: 0.0117, s2.acc: 98.1018, s2.loss_bbox: 0.0221, loss: 0.1313, grad_norm: 4.4304\n",
            "2020-09-07 11:44:25,046 - mmdet - INFO - Epoch [14][1600/5332]\tlr: 1.000e-05, eta: 20:18:43, time: 2.062, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0244, s0.acc: 99.0570, s0.loss_bbox: 0.0176, s1.loss_cls: 0.0151, s1.acc: 98.8678, s1.loss_bbox: 0.0302, s2.loss_cls: 0.0101, s2.acc: 98.5382, s2.loss_bbox: 0.0258, loss: 0.1299, grad_norm: 4.3472\n",
            "2020-09-07 11:46:38,981 - mmdet - INFO - Epoch [14][1664/5332]\tlr: 1.000e-05, eta: 20:16:40, time: 2.093, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0273, s0.acc: 98.8525, s0.loss_bbox: 0.0180, s1.loss_cls: 0.0169, s1.acc: 98.5382, s1.loss_bbox: 0.0300, s2.loss_cls: 0.0107, s2.acc: 98.1293, s2.loss_bbox: 0.0250, loss: 0.1370, grad_norm: 4.4370\n",
            "2020-09-07 11:48:47,966 - mmdet - INFO - Epoch [14][1728/5332]\tlr: 1.000e-05, eta: 20:14:23, time: 2.015, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0262, s0.acc: 98.9777, s0.loss_bbox: 0.0215, s1.loss_cls: 0.0168, s1.acc: 98.7427, s1.loss_bbox: 0.0338, s2.loss_cls: 0.0110, s2.acc: 98.0957, s2.loss_bbox: 0.0268, loss: 0.1460, grad_norm: 4.6396\n",
            "2020-09-07 11:50:59,150 - mmdet - INFO - Epoch [14][1792/5332]\tlr: 1.000e-05, eta: 20:12:13, time: 2.050, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0252, s0.acc: 98.9471, s0.loss_bbox: 0.0182, s1.loss_cls: 0.0172, s1.acc: 98.5016, s1.loss_bbox: 0.0317, s2.loss_cls: 0.0107, s2.acc: 98.1049, s2.loss_bbox: 0.0240, loss: 0.1343, grad_norm: 4.3527\n",
            "2020-09-07 11:53:10,729 - mmdet - INFO - Epoch [14][1856/5332]\tlr: 1.000e-05, eta: 20:10:03, time: 2.056, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0216, s0.acc: 99.1302, s0.loss_bbox: 0.0126, s1.loss_cls: 0.0130, s1.acc: 98.9044, s1.loss_bbox: 0.0265, s2.loss_cls: 0.0087, s2.acc: 98.5596, s2.loss_bbox: 0.0237, loss: 0.1141, grad_norm: 4.4903\n",
            "2020-09-07 11:55:22,640 - mmdet - INFO - Epoch [14][1920/5332]\tlr: 1.000e-05, eta: 20:07:55, time: 2.061, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0233, s0.acc: 99.0662, s0.loss_bbox: 0.0160, s1.loss_cls: 0.0157, s1.acc: 98.7244, s1.loss_bbox: 0.0273, s2.loss_cls: 0.0096, s2.acc: 98.2697, s2.loss_bbox: 0.0209, loss: 0.1224, grad_norm: 4.2438\n",
            "2020-09-07 11:57:34,617 - mmdet - INFO - Epoch [14][1984/5332]\tlr: 1.000e-05, eta: 20:05:47, time: 2.062, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0235, s0.acc: 99.0662, s0.loss_bbox: 0.0149, s1.loss_cls: 0.0149, s1.acc: 98.7366, s1.loss_bbox: 0.0256, s2.loss_cls: 0.0102, s2.acc: 98.4100, s2.loss_bbox: 0.0231, loss: 0.1190, grad_norm: 4.1046\n",
            "2020-09-07 11:59:47,762 - mmdet - INFO - Epoch [14][2048/5332]\tlr: 1.000e-05, eta: 20:03:41, time: 2.080, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0058, loss_rpn_bbox: 0.0106, s0.loss_cls: 0.0219, s0.acc: 99.0326, s0.loss_bbox: 0.0146, s1.loss_cls: 0.0162, s1.acc: 98.6420, s1.loss_bbox: 0.0249, s2.loss_cls: 0.0097, s2.acc: 98.4833, s2.loss_bbox: 0.0234, loss: 0.1270, grad_norm: 4.2297\n",
            "2020-09-07 12:02:00,345 - mmdet - INFO - Epoch [14][2112/5332]\tlr: 1.000e-05, eta: 20:01:35, time: 2.072, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0258, s0.acc: 98.9929, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0178, s1.acc: 98.5443, s1.loss_bbox: 0.0263, s2.loss_cls: 0.0103, s2.acc: 98.1323, s2.loss_bbox: 0.0203, loss: 0.1271, grad_norm: 4.6682\n",
            "2020-09-07 12:04:12,831 - mmdet - INFO - Epoch [14][2176/5332]\tlr: 1.000e-05, eta: 19:59:28, time: 2.070, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0223, s0.acc: 99.0967, s0.loss_bbox: 0.0157, s1.loss_cls: 0.0140, s1.acc: 98.7854, s1.loss_bbox: 0.0264, s2.loss_cls: 0.0087, s2.acc: 98.6664, s2.loss_bbox: 0.0250, loss: 0.1194, grad_norm: 4.5106\n",
            "2020-09-07 12:06:23,093 - mmdet - INFO - Epoch [14][2240/5332]\tlr: 1.000e-05, eta: 19:57:14, time: 2.035, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0061, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0210, s0.acc: 99.1699, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0114, s1.acc: 99.1547, s1.loss_bbox: 0.0303, s2.loss_cls: 0.0071, s2.acc: 98.9929, s2.loss_bbox: 0.0301, loss: 0.1276, grad_norm: 4.4833\n",
            "2020-09-07 12:08:36,132 - mmdet - INFO - Epoch [14][2304/5332]\tlr: 1.000e-05, eta: 19:55:09, time: 2.079, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0061, s0.loss_cls: 0.0259, s0.acc: 99.0417, s0.loss_bbox: 0.0165, s1.loss_cls: 0.0177, s1.acc: 98.6267, s1.loss_bbox: 0.0317, s2.loss_cls: 0.0116, s2.acc: 97.9706, s2.loss_bbox: 0.0273, loss: 0.1395, grad_norm: 4.1882\n",
            "2020-09-07 12:10:48,458 - mmdet - INFO - Epoch [14][2368/5332]\tlr: 1.000e-05, eta: 19:53:01, time: 2.068, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0209, s0.acc: 99.1913, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0131, s1.acc: 98.9655, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0086, s2.acc: 98.6237, s2.loss_bbox: 0.0229, loss: 0.1188, grad_norm: 4.4195\n",
            "2020-09-07 12:13:01,478 - mmdet - INFO - Epoch [14][2432/5332]\tlr: 1.000e-05, eta: 19:50:55, time: 2.078, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0023, s0.loss_cls: 0.0255, s0.acc: 98.8922, s0.loss_bbox: 0.0159, s1.loss_cls: 0.0161, s1.acc: 98.6450, s1.loss_bbox: 0.0262, s2.loss_cls: 0.0113, s2.acc: 98.0591, s2.loss_bbox: 0.0221, loss: 0.1220, grad_norm: 4.2853\n",
            "2020-09-07 12:15:14,703 - mmdet - INFO - Epoch [14][2496/5332]\tlr: 1.000e-05, eta: 19:48:50, time: 2.082, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0221, s0.acc: 99.1333, s0.loss_bbox: 0.0177, s1.loss_cls: 0.0132, s1.acc: 99.0112, s1.loss_bbox: 0.0291, s2.loss_cls: 0.0082, s2.acc: 98.7854, s2.loss_bbox: 0.0235, loss: 0.1243, grad_norm: 4.1407\n",
            "2020-09-07 12:17:26,536 - mmdet - INFO - Epoch [14][2560/5332]\tlr: 1.000e-05, eta: 19:46:41, time: 2.060, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0022, s0.loss_cls: 0.0242, s0.acc: 99.0479, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0167, s1.acc: 98.8007, s1.loss_bbox: 0.0293, s2.loss_cls: 0.0110, s2.acc: 98.2788, s2.loss_bbox: 0.0234, loss: 0.1265, grad_norm: 4.6693\n",
            "2020-09-07 12:19:37,736 - mmdet - INFO - Epoch [14][2624/5332]\tlr: 1.000e-05, eta: 19:44:30, time: 2.050, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0076, s0.loss_cls: 0.0267, s0.acc: 98.8983, s0.loss_bbox: 0.0189, s1.loss_cls: 0.0175, s1.acc: 98.6023, s1.loss_bbox: 0.0326, s2.loss_cls: 0.0107, s2.acc: 98.0499, s2.loss_bbox: 0.0280, loss: 0.1449, grad_norm: 4.7927\n",
            "2020-09-07 12:21:49,093 - mmdet - INFO - Epoch [14][2688/5332]\tlr: 1.000e-05, eta: 19:42:20, time: 2.052, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0225, s0.acc: 99.0387, s0.loss_bbox: 0.0168, s1.loss_cls: 0.0144, s1.acc: 98.8586, s1.loss_bbox: 0.0317, s2.loss_cls: 0.0100, s2.acc: 98.2819, s2.loss_bbox: 0.0220, loss: 0.1231, grad_norm: 4.1103\n",
            "2020-09-07 12:24:00,837 - mmdet - INFO - Epoch [14][2752/5332]\tlr: 1.000e-05, eta: 19:40:10, time: 2.059, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0274, s0.acc: 99.0448, s0.loss_bbox: 0.0174, s1.loss_cls: 0.0171, s1.acc: 98.7732, s1.loss_bbox: 0.0320, s2.loss_cls: 0.0110, s2.acc: 98.4436, s2.loss_bbox: 0.0279, loss: 0.1396, grad_norm: 4.8732\n",
            "2020-09-07 12:26:11,412 - mmdet - INFO - Epoch [14][2816/5332]\tlr: 1.000e-05, eta: 19:37:58, time: 2.040, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0062, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0320, s0.acc: 98.7274, s0.loss_bbox: 0.0233, s1.loss_cls: 0.0208, s1.acc: 98.2758, s1.loss_bbox: 0.0356, s2.loss_cls: 0.0135, s2.acc: 97.6898, s2.loss_bbox: 0.0267, loss: 0.1631, grad_norm: 5.3956\n",
            "2020-09-07 12:28:24,287 - mmdet - INFO - Epoch [14][2880/5332]\tlr: 1.000e-05, eta: 19:35:51, time: 2.076, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0291, s0.acc: 98.7457, s0.loss_bbox: 0.0213, s1.loss_cls: 0.0179, s1.acc: 98.5260, s1.loss_bbox: 0.0309, s2.loss_cls: 0.0112, s2.acc: 98.2758, s2.loss_bbox: 0.0257, loss: 0.1455, grad_norm: 4.7429\n",
            "2020-09-07 12:30:35,231 - mmdet - INFO - Epoch [14][2944/5332]\tlr: 1.000e-05, eta: 19:33:40, time: 2.046, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0075, s0.loss_cls: 0.0275, s0.acc: 98.9136, s0.loss_bbox: 0.0194, s1.loss_cls: 0.0162, s1.acc: 98.7183, s1.loss_bbox: 0.0310, s2.loss_cls: 0.0106, s2.acc: 98.1415, s2.loss_bbox: 0.0226, loss: 0.1380, grad_norm: 4.7628\n",
            "2020-09-07 12:32:46,028 - mmdet - INFO - Epoch [14][3008/5332]\tlr: 1.000e-05, eta: 19:31:28, time: 2.044, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0268, s0.acc: 99.0265, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0170, s1.acc: 98.6725, s1.loss_bbox: 0.0254, s2.loss_cls: 0.0103, s2.acc: 98.4039, s2.loss_bbox: 0.0197, loss: 0.1256, grad_norm: 3.8919\n",
            "2020-09-07 12:34:55,891 - mmdet - INFO - Epoch [14][3072/5332]\tlr: 1.000e-05, eta: 19:29:14, time: 2.029, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0251, s0.acc: 99.0204, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0186, s1.acc: 98.6206, s1.loss_bbox: 0.0278, s2.loss_cls: 0.0117, s2.acc: 98.0225, s2.loss_bbox: 0.0240, loss: 0.1327, grad_norm: 4.4433\n",
            "2020-09-07 12:37:06,070 - mmdet - INFO - Epoch [14][3136/5332]\tlr: 1.000e-05, eta: 19:27:01, time: 2.034, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0066, s0.loss_cls: 0.0182, s0.acc: 99.3011, s0.loss_bbox: 0.0138, s1.loss_cls: 0.0131, s1.acc: 99.0265, s1.loss_bbox: 0.0223, s2.loss_cls: 0.0084, s2.acc: 98.7091, s2.loss_bbox: 0.0179, loss: 0.1041, grad_norm: 3.7423\n",
            "2020-09-07 12:39:16,296 - mmdet - INFO - Epoch [14][3200/5332]\tlr: 1.000e-05, eta: 19:24:48, time: 2.035, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0064, s0.loss_cls: 0.0281, s0.acc: 98.8708, s0.loss_bbox: 0.0213, s1.loss_cls: 0.0184, s1.acc: 98.3948, s1.loss_bbox: 0.0343, s2.loss_cls: 0.0126, s2.acc: 97.7570, s2.loss_bbox: 0.0259, loss: 0.1524, grad_norm: 4.6878\n",
            "2020-09-07 12:41:29,325 - mmdet - INFO - Epoch [14][3264/5332]\tlr: 1.000e-05, eta: 19:22:41, time: 2.079, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0239, s0.acc: 98.9777, s0.loss_bbox: 0.0177, s1.loss_cls: 0.0175, s1.acc: 98.4833, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0103, s2.acc: 98.2178, s2.loss_bbox: 0.0247, loss: 0.1333, grad_norm: 4.2193\n",
            "2020-09-07 12:43:42,032 - mmdet - INFO - Epoch [14][3328/5332]\tlr: 1.000e-05, eta: 19:20:34, time: 2.074, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0065, s0.loss_cls: 0.0219, s0.acc: 99.0753, s0.loss_bbox: 0.0147, s1.loss_cls: 0.0140, s1.acc: 98.9502, s1.loss_bbox: 0.0242, s2.loss_cls: 0.0088, s2.acc: 98.7549, s2.loss_bbox: 0.0208, loss: 0.1146, grad_norm: 4.2065\n",
            "2020-09-07 12:45:54,314 - mmdet - INFO - Epoch [14][3392/5332]\tlr: 1.000e-05, eta: 19:18:26, time: 2.067, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0250, s0.acc: 98.9563, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0176, s1.acc: 98.5596, s1.loss_bbox: 0.0294, s2.loss_cls: 0.0107, s2.acc: 98.2361, s2.loss_bbox: 0.0251, loss: 0.1336, grad_norm: 4.5897\n",
            "2020-09-07 12:48:07,090 - mmdet - INFO - Epoch [14][3456/5332]\tlr: 1.000e-05, eta: 19:16:19, time: 2.075, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0076, s0.loss_cls: 0.0251, s0.acc: 99.0631, s0.loss_bbox: 0.0171, s1.loss_cls: 0.0161, s1.acc: 98.8342, s1.loss_bbox: 0.0276, s2.loss_cls: 0.0096, s2.acc: 98.6450, s2.loss_bbox: 0.0227, loss: 0.1302, grad_norm: 4.4208\n",
            "2020-09-07 12:50:19,094 - mmdet - INFO - Epoch [14][3520/5332]\tlr: 1.000e-05, eta: 19:14:10, time: 2.063, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0235, s0.acc: 99.0601, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0157, s1.acc: 98.7885, s1.loss_bbox: 0.0330, s2.loss_cls: 0.0099, s2.acc: 98.4039, s2.loss_bbox: 0.0297, loss: 0.1392, grad_norm: 4.6940\n",
            "2020-09-07 12:52:29,922 - mmdet - INFO - Epoch [14][3584/5332]\tlr: 1.000e-05, eta: 19:11:58, time: 2.044, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0189, s0.acc: 99.1638, s0.loss_bbox: 0.0138, s1.loss_cls: 0.0122, s1.acc: 98.9624, s1.loss_bbox: 0.0254, s2.loss_cls: 0.0083, s2.acc: 98.4650, s2.loss_bbox: 0.0230, loss: 0.1093, grad_norm: 3.9158\n",
            "2020-09-07 12:54:40,912 - mmdet - INFO - Epoch [14][3648/5332]\tlr: 1.000e-05, eta: 19:09:47, time: 2.047, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0244, s0.acc: 98.9838, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0163, s1.acc: 98.7030, s1.loss_bbox: 0.0283, s2.loss_cls: 0.0099, s2.acc: 98.3734, s2.loss_bbox: 0.0226, loss: 0.1256, grad_norm: 4.2009\n",
            "2020-09-07 12:56:53,404 - mmdet - INFO - Epoch [14][3712/5332]\tlr: 1.000e-05, eta: 19:07:39, time: 2.070, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0237, s0.acc: 98.9899, s0.loss_bbox: 0.0139, s1.loss_cls: 0.0145, s1.acc: 98.8342, s1.loss_bbox: 0.0243, s2.loss_cls: 0.0098, s2.acc: 98.5382, s2.loss_bbox: 0.0213, loss: 0.1171, grad_norm: 4.0443\n",
            "2020-09-07 12:59:05,454 - mmdet - INFO - Epoch [14][3776/5332]\tlr: 1.000e-05, eta: 19:05:30, time: 2.063, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0064, s0.loss_cls: 0.0285, s0.acc: 98.8770, s0.loss_bbox: 0.0190, s1.loss_cls: 0.0168, s1.acc: 98.6938, s1.loss_bbox: 0.0315, s2.loss_cls: 0.0107, s2.acc: 98.1934, s2.loss_bbox: 0.0268, loss: 0.1435, grad_norm: 4.7104\n",
            "2020-09-07 13:01:16,680 - mmdet - INFO - Epoch [14][3840/5332]\tlr: 1.000e-05, eta: 19:03:19, time: 2.050, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0248, s0.acc: 99.0112, s0.loss_bbox: 0.0201, s1.loss_cls: 0.0165, s1.acc: 98.6694, s1.loss_bbox: 0.0321, s2.loss_cls: 0.0107, s2.acc: 98.3765, s2.loss_bbox: 0.0284, loss: 0.1411, grad_norm: 4.3067\n",
            "2020-09-07 13:03:28,402 - mmdet - INFO - Epoch [14][3904/5332]\tlr: 1.000e-05, eta: 19:01:09, time: 2.058, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0076, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0259, s0.acc: 99.0540, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0165, s1.acc: 98.7457, s1.loss_bbox: 0.0290, s2.loss_cls: 0.0096, s2.acc: 98.6053, s2.loss_bbox: 0.0259, loss: 0.1367, grad_norm: 4.4614\n",
            "2020-09-07 13:05:40,571 - mmdet - INFO - Epoch [14][3968/5332]\tlr: 1.000e-05, eta: 18:59:01, time: 2.065, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0224, s0.acc: 99.0845, s0.loss_bbox: 0.0159, s1.loss_cls: 0.0142, s1.acc: 98.8983, s1.loss_bbox: 0.0275, s2.loss_cls: 0.0089, s2.acc: 98.5687, s2.loss_bbox: 0.0256, loss: 0.1214, grad_norm: 4.3978\n",
            "2020-09-07 13:07:51,925 - mmdet - INFO - Epoch [14][4032/5332]\tlr: 1.000e-05, eta: 18:56:50, time: 2.052, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0237, s0.acc: 99.0540, s0.loss_bbox: 0.0213, s1.loss_cls: 0.0152, s1.acc: 98.8251, s1.loss_bbox: 0.0335, s2.loss_cls: 0.0105, s2.acc: 98.3276, s2.loss_bbox: 0.0219, loss: 0.1339, grad_norm: 4.3438\n",
            "2020-09-07 13:10:05,665 - mmdet - INFO - Epoch [14][4096/5332]\tlr: 1.000e-05, eta: 18:54:45, time: 2.090, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0025, s0.loss_cls: 0.0218, s0.acc: 99.1608, s0.loss_bbox: 0.0140, s1.loss_cls: 0.0132, s1.acc: 99.0082, s1.loss_bbox: 0.0244, s2.loss_cls: 0.0083, s2.acc: 98.6084, s2.loss_bbox: 0.0218, loss: 0.1095, grad_norm: 3.8761\n",
            "2020-09-07 13:12:18,603 - mmdet - INFO - Epoch [14][4160/5332]\tlr: 1.000e-05, eta: 18:52:38, time: 2.077, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0206, s0.acc: 99.1486, s0.loss_bbox: 0.0134, s1.loss_cls: 0.0155, s1.acc: 98.7152, s1.loss_bbox: 0.0223, s2.loss_cls: 0.0103, s2.acc: 98.1262, s2.loss_bbox: 0.0183, loss: 0.1051, grad_norm: 3.7824\n",
            "2020-09-07 13:14:28,993 - mmdet - INFO - Epoch [14][4224/5332]\tlr: 1.000e-05, eta: 18:50:25, time: 2.037, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0335, s0.acc: 98.8281, s0.loss_bbox: 0.0181, s1.loss_cls: 0.0195, s1.acc: 98.5260, s1.loss_bbox: 0.0323, s2.loss_cls: 0.0127, s2.acc: 97.9034, s2.loss_bbox: 0.0238, loss: 0.1481, grad_norm: 4.7067\n",
            "2020-09-07 13:16:41,076 - mmdet - INFO - Epoch [14][4288/5332]\tlr: 1.000e-05, eta: 18:48:16, time: 2.064, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0217, s0.acc: 99.0936, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0142, s1.acc: 98.8129, s1.loss_bbox: 0.0266, s2.loss_cls: 0.0095, s2.acc: 98.3765, s2.loss_bbox: 0.0239, loss: 0.1199, grad_norm: 4.2976\n",
            "2020-09-07 13:18:51,841 - mmdet - INFO - Epoch [14][4352/5332]\tlr: 1.000e-05, eta: 18:46:04, time: 2.043, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0233, s0.acc: 99.0387, s0.loss_bbox: 0.0184, s1.loss_cls: 0.0159, s1.acc: 98.6511, s1.loss_bbox: 0.0336, s2.loss_cls: 0.0107, s2.acc: 98.2300, s2.loss_bbox: 0.0250, loss: 0.1351, grad_norm: 4.6681\n",
            "2020-09-07 13:21:04,798 - mmdet - INFO - Epoch [14][4416/5332]\tlr: 1.000e-05, eta: 18:43:56, time: 2.077, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0254, s0.acc: 99.0417, s0.loss_bbox: 0.0184, s1.loss_cls: 0.0164, s1.acc: 98.7061, s1.loss_bbox: 0.0297, s2.loss_cls: 0.0110, s2.acc: 98.2941, s2.loss_bbox: 0.0246, loss: 0.1357, grad_norm: 4.3277\n",
            "2020-09-07 13:23:17,056 - mmdet - INFO - Epoch [14][4480/5332]\tlr: 1.000e-05, eta: 18:41:48, time: 2.067, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0190, s0.acc: 99.2554, s0.loss_bbox: 0.0130, s1.loss_cls: 0.0139, s1.acc: 98.7732, s1.loss_bbox: 0.0235, s2.loss_cls: 0.0096, s2.acc: 98.4619, s2.loss_bbox: 0.0221, loss: 0.1087, grad_norm: 3.9869\n",
            "2020-09-07 13:25:29,879 - mmdet - INFO - Epoch [14][4544/5332]\tlr: 1.000e-05, eta: 18:39:40, time: 2.075, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0247, s0.acc: 98.9655, s0.loss_bbox: 0.0198, s1.loss_cls: 0.0150, s1.acc: 98.7854, s1.loss_bbox: 0.0323, s2.loss_cls: 0.0101, s2.acc: 98.2819, s2.loss_bbox: 0.0266, loss: 0.1375, grad_norm: 4.5263\n",
            "2020-09-07 13:27:42,055 - mmdet - INFO - Epoch [14][4608/5332]\tlr: 1.000e-05, eta: 18:37:31, time: 2.065, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0280, s0.acc: 98.9044, s0.loss_bbox: 0.0186, s1.loss_cls: 0.0178, s1.acc: 98.6115, s1.loss_bbox: 0.0313, s2.loss_cls: 0.0124, s2.acc: 97.9126, s2.loss_bbox: 0.0255, loss: 0.1417, grad_norm: 4.9188\n",
            "2020-09-07 13:29:55,957 - mmdet - INFO - Epoch [14][4672/5332]\tlr: 1.000e-05, eta: 18:35:26, time: 2.092, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0206, s0.acc: 99.1486, s0.loss_bbox: 0.0135, s1.loss_cls: 0.0128, s1.acc: 98.9655, s1.loss_bbox: 0.0232, s2.loss_cls: 0.0079, s2.acc: 98.8586, s2.loss_bbox: 0.0181, loss: 0.1024, grad_norm: 3.6832\n",
            "2020-09-07 13:32:07,013 - mmdet - INFO - Epoch [14][4736/5332]\tlr: 1.000e-05, eta: 18:33:14, time: 2.048, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0261, s0.acc: 99.0051, s0.loss_bbox: 0.0187, s1.loss_cls: 0.0179, s1.acc: 98.5626, s1.loss_bbox: 0.0288, s2.loss_cls: 0.0116, s2.acc: 98.0499, s2.loss_bbox: 0.0247, loss: 0.1345, grad_norm: 4.3844\n",
            "2020-09-07 13:34:18,476 - mmdet - INFO - Epoch [14][4800/5332]\tlr: 1.000e-05, eta: 18:31:04, time: 2.054, data_time: 0.005, memory: 7874, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0306, s0.acc: 98.7762, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0193, s1.acc: 98.4711, s1.loss_bbox: 0.0274, s2.loss_cls: 0.0116, s2.acc: 98.1110, s2.loss_bbox: 0.0234, loss: 0.1401, grad_norm: 4.9541\n",
            "2020-09-07 13:36:29,852 - mmdet - INFO - Epoch [14][4864/5332]\tlr: 1.000e-05, eta: 18:28:53, time: 2.053, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0245, s0.acc: 99.1058, s0.loss_bbox: 0.0142, s1.loss_cls: 0.0161, s1.acc: 98.8525, s1.loss_bbox: 0.0233, s2.loss_cls: 0.0095, s2.acc: 98.7762, s2.loss_bbox: 0.0219, loss: 0.1162, grad_norm: 3.9422\n",
            "2020-09-07 13:38:42,343 - mmdet - INFO - Epoch [14][4928/5332]\tlr: 1.000e-05, eta: 18:26:45, time: 2.070, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0251, s0.acc: 98.9716, s0.loss_bbox: 0.0181, s1.loss_cls: 0.0167, s1.acc: 98.6664, s1.loss_bbox: 0.0301, s2.loss_cls: 0.0113, s2.acc: 98.1628, s2.loss_bbox: 0.0277, loss: 0.1354, grad_norm: 5.1097\n",
            "2020-09-07 13:40:54,805 - mmdet - INFO - Epoch [14][4992/5332]\tlr: 1.000e-05, eta: 18:24:36, time: 2.070, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0202, s0.acc: 99.2279, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0142, s1.acc: 98.7732, s1.loss_bbox: 0.0302, s2.loss_cls: 0.0099, s2.acc: 98.2239, s2.loss_bbox: 0.0222, loss: 0.1204, grad_norm: 3.9682\n",
            "2020-09-07 13:43:06,659 - mmdet - INFO - Epoch [14][5056/5332]\tlr: 1.000e-05, eta: 18:22:26, time: 2.060, data_time: 0.004, memory: 7874, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0252, s0.acc: 99.1119, s0.loss_bbox: 0.0162, s1.loss_cls: 0.0161, s1.acc: 98.9532, s1.loss_bbox: 0.0284, s2.loss_cls: 0.0093, s2.acc: 98.8220, s2.loss_bbox: 0.0260, loss: 0.1292, grad_norm: 4.3364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPdm3Vuh4f_R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c371d118-23cb-4355-e70d-2d58d87f3312"
      },
      "source": [
        "!python tools/train.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py --resume-from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_13.pth"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-07 14:06:09,723 - mmdet - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.7.6 (default, Jan  8 2020, 19:59:22) [GCC 7.3.0]\n",
            "CUDA available: True\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
            "GPU 0: Tesla P100-PCIE-16GB\n",
            "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "PyTorch: 1.4.0\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CUDA Runtime 10.0\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.1\n",
            "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "TorchVision: 0.5.0\n",
            "OpenCV: 4.4.0\n",
            "MMCV: 1.1.2\n",
            "MMDetection: 2.3.0+\n",
            "MMDetection Compiler: GCC 7.5\n",
            "MMDetection CUDA Compiler: 10.1\n",
            "------------------------------------------------------------\n",
            "\n",
            "2020-09-07 14:06:10,421 - mmdet - INFO - Distributed training: False\n",
            "2020-09-07 14:06:11,126 - mmdet - INFO - Config:\n",
            "model = dict(\n",
            "    type='CascadeRCNN',\n",
            "    pretrained='open-mmlab://resnext101_32x4d',\n",
            "    backbone=dict(\n",
            "        type='DetectoRS_ResNeXt',\n",
            "        depth=101,\n",
            "        groups=32,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=True,\n",
            "        style='pytorch',\n",
            "        conv_cfg=dict(type='ConvAWS'),\n",
            "        sac=dict(type='SAC', use_deform=True),\n",
            "        stage_with_sac=(False, True, True, True),\n",
            "        output_img=True),\n",
            "    neck=dict(\n",
            "        type='RFP',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5,\n",
            "        rfp_steps=2,\n",
            "        aspp_out_channels=64,\n",
            "        aspp_dilations=(1, 3, 6, 1),\n",
            "        rfp_backbone=dict(\n",
            "            rfp_inplanes=256,\n",
            "            type='DetectoRS_ResNeXt',\n",
            "            depth=101,\n",
            "            num_stages=4,\n",
            "            out_indices=(0, 1, 2, 3),\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(type='BN', requires_grad=True),\n",
            "            norm_eval=True,\n",
            "            conv_cfg=dict(type='ConvAWS'),\n",
            "            sac=dict(type='SAC', use_deform=True),\n",
            "            stage_with_sac=(False, True, True, True),\n",
            "            pretrained='open-mmlab://resnext101_32x4d',\n",
            "            style='pytorch')),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(\n",
            "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='CascadeRoIHead',\n",
            "        num_stages=3,\n",
            "        stage_loss_weights=[1, 0.5, 0.25],\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='GenericRoIExtractor',\n",
            "            aggregation='sum',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32],\n",
            "            pre_cfg=dict(\n",
            "                type='ConvModule',\n",
            "                in_channels=256,\n",
            "                out_channels=256,\n",
            "                kernel_size=5,\n",
            "                padding=2,\n",
            "                inplace=False),\n",
            "            post_cfg=dict(\n",
            "                type='GeneralizedAttention',\n",
            "                in_channels=256,\n",
            "                spatial_range=-1,\n",
            "                num_heads=6,\n",
            "                attention_type='0100',\n",
            "                kv_stride=2)),\n",
            "        bbox_head=[\n",
            "            dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=10,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
            "                               loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=10,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
            "                               loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=10,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
            "        ]))\n",
            "train_cfg = dict(\n",
            "    rpn=dict(\n",
            "        assigner=dict(\n",
            "            type='MaxIoUAssigner',\n",
            "            pos_iou_thr=0.7,\n",
            "            neg_iou_thr=0.3,\n",
            "            min_pos_iou=0.3,\n",
            "            match_low_quality=True,\n",
            "            ignore_iof_thr=-1),\n",
            "        sampler=dict(\n",
            "            type='RandomSampler',\n",
            "            num=256,\n",
            "            pos_fraction=0.5,\n",
            "            neg_pos_ub=-1,\n",
            "            add_gt_as_proposals=False),\n",
            "        allowed_border=0,\n",
            "        pos_weight=-1,\n",
            "        debug=False),\n",
            "    rpn_proposal=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=2000,\n",
            "        nms_post=2000,\n",
            "        max_num=2000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=[\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.6,\n",
            "                neg_iou_thr=0.6,\n",
            "                min_pos_iou=0.6,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.7,\n",
            "                min_pos_iou=0.7,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)\n",
            "    ])\n",
            "test_cfg = dict(\n",
            "    rpn=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=1000,\n",
            "        nms_post=1000,\n",
            "        max_num=1000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=dict(\n",
            "        score_thr=0.05,\n",
            "        nms=dict(type='nms', iou_threshold=0.5),\n",
            "        max_per_img=100))\n",
            "dataset_type = 'CustomDataset'\n",
            "data_root = 'data/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "albu_train_transforms = [\n",
            "    dict(\n",
            "        type='ShiftScaleRotate',\n",
            "        shift_limit=0.0625,\n",
            "        scale_limit=0.0,\n",
            "        rotate_limit=0,\n",
            "        interpolation=1,\n",
            "        p=0.5),\n",
            "    dict(\n",
            "        type='RandomBrightnessContrast',\n",
            "        brightness_limit=[0.1, 0.3],\n",
            "        contrast_limit=[0.1, 0.3],\n",
            "        p=0.2),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='RGBShift',\n",
            "                r_shift_limit=10,\n",
            "                g_shift_limit=10,\n",
            "                b_shift_limit=10,\n",
            "                p=1.0),\n",
            "            dict(\n",
            "                type='HueSaturationValue',\n",
            "                hue_shift_limit=20,\n",
            "                sat_shift_limit=30,\n",
            "                val_shift_limit=20,\n",
            "                p=1.0)\n",
            "        ],\n",
            "        p=0.1),\n",
            "    dict(type='JpegCompression', quality_lower=85, quality_upper=95, p=0.2),\n",
            "    dict(type='ChannelShuffle', p=0.1),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "        ],\n",
            "        p=0.1)\n",
            "]\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "    dict(\n",
            "        type='Resize',\n",
            "        multiscale_mode='range',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        keep_ratio=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(\n",
            "        type='Albu',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='ShiftScaleRotate',\n",
            "                shift_limit=0.0625,\n",
            "                scale_limit=0.0,\n",
            "                rotate_limit=0,\n",
            "                interpolation=1,\n",
            "                p=0.5),\n",
            "            dict(\n",
            "                type='RandomBrightnessContrast',\n",
            "                brightness_limit=[0.1, 0.3],\n",
            "                contrast_limit=[0.1, 0.3],\n",
            "                p=0.2),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='RGBShift',\n",
            "                        r_shift_limit=10,\n",
            "                        g_shift_limit=10,\n",
            "                        b_shift_limit=10,\n",
            "                        p=1.0),\n",
            "                    dict(\n",
            "                        type='HueSaturationValue',\n",
            "                        hue_shift_limit=20,\n",
            "                        sat_shift_limit=30,\n",
            "                        val_shift_limit=20,\n",
            "                        p=1.0)\n",
            "                ],\n",
            "                p=0.1),\n",
            "            dict(\n",
            "                type='JpegCompression',\n",
            "                quality_lower=85,\n",
            "                quality_upper=95,\n",
            "                p=0.2),\n",
            "            dict(type='ChannelShuffle', p=0.1),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                    dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                ],\n",
            "                p=0.1)\n",
            "        ],\n",
            "        bbox_params=dict(\n",
            "            type='BboxParams',\n",
            "            format='pascal_voc',\n",
            "            label_fields=['gt_labels'],\n",
            "            min_visibility=0.0,\n",
            "            filter_lost_elements=True),\n",
            "        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "        update_pad_shape=False,\n",
            "        skip_img_without_anno=True),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(\n",
            "        type='Collect',\n",
            "        keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "        meta_keys=('filename', 'ori_shape', 'img_shape', 'img_norm_cfg',\n",
            "                   'pad_shape', 'scale_factor'))\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        transforms=[\n",
            "            dict(type='Resize', multiscale_mode='range', keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=1.0),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=1,\n",
            "    workers_per_gpu=1,\n",
            "    train=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/train_80_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                type='Resize',\n",
            "                multiscale_mode='range',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                keep_ratio=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(\n",
            "                type='Albu',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='ShiftScaleRotate',\n",
            "                        shift_limit=0.0625,\n",
            "                        scale_limit=0.0,\n",
            "                        rotate_limit=0,\n",
            "                        interpolation=1,\n",
            "                        p=0.5),\n",
            "                    dict(\n",
            "                        type='RandomBrightnessContrast',\n",
            "                        brightness_limit=[0.1, 0.3],\n",
            "                        contrast_limit=[0.1, 0.3],\n",
            "                        p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(\n",
            "                                type='RGBShift',\n",
            "                                r_shift_limit=10,\n",
            "                                g_shift_limit=10,\n",
            "                                b_shift_limit=10,\n",
            "                                p=1.0),\n",
            "                            dict(\n",
            "                                type='HueSaturationValue',\n",
            "                                hue_shift_limit=20,\n",
            "                                sat_shift_limit=30,\n",
            "                                val_shift_limit=20,\n",
            "                                p=1.0)\n",
            "                        ],\n",
            "                        p=0.1),\n",
            "                    dict(\n",
            "                        type='JpegCompression',\n",
            "                        quality_lower=75,\n",
            "                        quality_upper=95,\n",
            "                        p=0.2),\n",
            "                    dict(type='ChannelShuffle', p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                        ],\n",
            "                        p=0.1)\n",
            "                ],\n",
            "                bbox_params=dict(\n",
            "                    type='BboxParams',\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=['gt_labels'],\n",
            "                    min_visibility=0.0,\n",
            "                    filter_lost_elements=True),\n",
            "                keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "                update_pad_shape=False,\n",
            "                skip_img_without_anno=True),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(\n",
            "                type='Collect',\n",
            "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "                meta_keys=('filename', 'ori_shape', 'img_shape',\n",
            "                           'img_norm_cfg', 'pad_shape', 'scale_factor'))\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/val_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/test_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 200), (1999, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "evaluation = dict(interval=1, metric='mAP')\n",
            "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.3333333333333333,\n",
            "    step=[8, 11])\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=64, hooks=[dict(type='TextLoggerHook')])\n",
            "total_epochs = 20\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "work_dir = './work_dirs/cascade_rcnn_x101_32x4d_fpn_1x'\n",
            "load_from = None\n",
            "resume_from = 'work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_13.pth'\n",
            "workflow = [('train', 1)]\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "2020-09-07 14:06:15,005 - mmdet - INFO - load model from: open-mmlab://resnext101_32x4d\n",
            "Downloading: \"https://openmmlab.oss-accelerate.aliyuncs.com/pretrain/third_party/resnext101_32x4d-a5af3160.pth\" to /root/.cache/torch/checkpoints/resnext101_32x4d-a5af3160.pth\n",
            "100% 161M/161M [00:12<00:00, 13.3MB/s]\n",
            "2020-09-07 14:06:28,797 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "2020-09-07 14:06:29,328 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
            "size mismatch for layer1.0.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.1.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.2.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.2.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
            "size mismatch for layer2.0.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.0.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.1.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.1.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.2.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.2.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.2.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.3.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.3.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.3.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
            "size mismatch for layer3.0.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.0.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.1.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.2.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.2.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.2.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.3.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.3.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.3.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.4.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.4.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.4.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.5.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.5.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.5.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.6.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.6.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.6.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.7.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.7.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.7.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.8.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.8.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.8.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.9.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.9.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.9.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.10.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.10.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.10.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.11.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.11.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.11.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.12.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.12.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.12.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.13.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.13.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.13.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.14.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.14.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.14.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.15.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.15.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.15.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.16.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.16.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.16.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.17.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.17.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.17.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.18.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.18.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.18.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.19.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.19.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.19.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.20.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.20.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.20.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.21.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.21.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.21.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.22.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.22.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.22.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
            "size mismatch for layer4.0.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.0.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.1.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.1.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.2.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.2.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.2.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-07 14:06:38,897 - mmdet - INFO - load checkpoint from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_13.pth\n",
            "2020-09-07 14:06:51,417 - mmdet - INFO - resumed epoch 13, iter 69316\n",
            "2020-09-07 14:06:51,423 - mmdet - INFO - Start running, host: root@7673848f21ec, work_dir: /content/drive/My Drive/mmdetection-master/work_dirs/cascade_rcnn_x101_32x4d_fpn_1x\n",
            "2020-09-07 14:06:51,424 - mmdet - INFO - workflow: [('train', 1)], max: 20 epochs\n",
            "2020-09-07 14:08:56,004 - mmdet - INFO - Epoch [14][64/5332]\tlr: 1.000e-05, eta: 20:08:40, time: 1.946, data_time: 0.044, memory: 8800, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0025, s0.loss_cls: 0.0240, s0.acc: 99.0265, s0.loss_bbox: 0.0161, s1.loss_cls: 0.0160, s1.acc: 98.6938, s1.loss_bbox: 0.0275, s2.loss_cls: 0.0107, s2.acc: 98.2147, s2.loss_bbox: 0.0250, loss: 0.1261, grad_norm: 4.7760\n",
            "2020-09-07 14:10:54,900 - mmdet - INFO - Epoch [14][128/5332]\tlr: 1.000e-05, eta: 19:39:08, time: 1.858, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0076, s0.loss_cls: 0.0251, s0.acc: 98.9624, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0142, s1.acc: 98.9166, s1.loss_bbox: 0.0256, s2.loss_cls: 0.0090, s2.acc: 98.5260, s2.loss_bbox: 0.0216, loss: 0.1236, grad_norm: 4.1914\n",
            "2020-09-07 14:12:54,094 - mmdet - INFO - Epoch [14][192/5332]\tlr: 1.000e-05, eta: 19:28:56, time: 1.862, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0207, s0.acc: 99.1516, s0.loss_bbox: 0.0141, s1.loss_cls: 0.0140, s1.acc: 98.8861, s1.loss_bbox: 0.0254, s2.loss_cls: 0.0097, s2.acc: 98.4375, s2.loss_bbox: 0.0223, loss: 0.1138, grad_norm: 4.1254\n",
            "2020-09-07 14:14:53,483 - mmdet - INFO - Epoch [14][256/5332]\tlr: 1.000e-05, eta: 19:23:18, time: 1.865, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0214, s0.acc: 99.1364, s0.loss_bbox: 0.0162, s1.loss_cls: 0.0129, s1.acc: 98.9105, s1.loss_bbox: 0.0300, s2.loss_cls: 0.0085, s2.acc: 98.7122, s2.loss_bbox: 0.0269, loss: 0.1235, grad_norm: 3.9107\n",
            "2020-09-07 14:16:52,247 - mmdet - INFO - Epoch [14][320/5332]\tlr: 1.000e-05, eta: 19:17:55, time: 1.856, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0200, s0.acc: 99.1638, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0139, s1.acc: 98.9014, s1.loss_bbox: 0.0272, s2.loss_cls: 0.0086, s2.acc: 98.5138, s2.loss_bbox: 0.0226, loss: 0.1163, grad_norm: 4.0123\n",
            "2020-09-07 14:18:48,333 - mmdet - INFO - Epoch [14][384/5332]\tlr: 1.000e-05, eta: 19:09:23, time: 1.814, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0328, s0.acc: 98.6633, s0.loss_bbox: 0.0204, s1.loss_cls: 0.0213, s1.acc: 98.3063, s1.loss_bbox: 0.0303, s2.loss_cls: 0.0131, s2.acc: 97.6776, s2.loss_bbox: 0.0237, loss: 0.1530, grad_norm: 4.8609\n",
            "2020-09-07 14:20:46,856 - mmdet - INFO - Epoch [14][448/5332]\tlr: 1.000e-05, eta: 19:06:05, time: 1.852, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0233, s0.acc: 99.0723, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0153, s1.acc: 98.8403, s1.loss_bbox: 0.0269, s2.loss_cls: 0.0102, s2.acc: 98.3826, s2.loss_bbox: 0.0185, loss: 0.1200, grad_norm: 4.1384\n",
            "2020-09-07 14:22:45,084 - mmdet - INFO - Epoch [14][512/5332]\tlr: 1.000e-05, eta: 19:02:45, time: 1.847, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0231, s0.acc: 99.0906, s0.loss_bbox: 0.0157, s1.loss_cls: 0.0140, s1.acc: 98.9410, s1.loss_bbox: 0.0285, s2.loss_cls: 0.0095, s2.acc: 98.4467, s2.loss_bbox: 0.0255, loss: 0.1241, grad_norm: 4.1025\n",
            "2020-09-07 14:24:43,042 - mmdet - INFO - Epoch [14][576/5332]\tlr: 1.000e-05, eta: 18:59:26, time: 1.843, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0283, s0.acc: 98.7976, s0.loss_bbox: 0.0187, s1.loss_cls: 0.0198, s1.acc: 98.3673, s1.loss_bbox: 0.0301, s2.loss_cls: 0.0122, s2.acc: 97.9279, s2.loss_bbox: 0.0225, loss: 0.1403, grad_norm: 4.5983\n",
            "2020-09-07 14:26:42,522 - mmdet - INFO - Epoch [14][640/5332]\tlr: 1.000e-05, eta: 18:57:51, time: 1.867, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0065, s0.loss_cls: 0.0240, s0.acc: 99.0997, s0.loss_bbox: 0.0190, s1.loss_cls: 0.0174, s1.acc: 98.6237, s1.loss_bbox: 0.0323, s2.loss_cls: 0.0107, s2.acc: 98.2117, s2.loss_bbox: 0.0261, loss: 0.1405, grad_norm: 4.6753\n",
            "2020-09-07 14:28:42,257 - mmdet - INFO - Epoch [14][704/5332]\tlr: 1.000e-05, eta: 18:56:24, time: 1.871, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0217, s0.acc: 99.1333, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0151, s1.acc: 98.7274, s1.loss_bbox: 0.0271, s2.loss_cls: 0.0101, s2.acc: 98.1659, s2.loss_bbox: 0.0247, loss: 0.1223, grad_norm: 4.1352\n",
            "2020-09-07 14:30:42,269 - mmdet - INFO - Epoch [14][768/5332]\tlr: 1.000e-05, eta: 18:55:05, time: 1.875, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0208, s0.acc: 99.1028, s0.loss_bbox: 0.0149, s1.loss_cls: 0.0142, s1.acc: 98.7823, s1.loss_bbox: 0.0284, s2.loss_cls: 0.0096, s2.acc: 98.2361, s2.loss_bbox: 0.0217, loss: 0.1178, grad_norm: 3.9556\n",
            "2020-09-07 14:32:40,852 - mmdet - INFO - Epoch [14][832/5332]\tlr: 1.000e-05, eta: 18:52:37, time: 1.853, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0240, s0.acc: 98.9655, s0.loss_bbox: 0.0169, s1.loss_cls: 0.0158, s1.acc: 98.6877, s1.loss_bbox: 0.0245, s2.loss_cls: 0.0104, s2.acc: 98.1842, s2.loss_bbox: 0.0212, loss: 0.1196, grad_norm: 4.3613\n",
            "2020-09-07 14:34:39,736 - mmdet - INFO - Epoch [14][896/5332]\tlr: 1.000e-05, eta: 18:50:26, time: 1.858, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0208, s0.acc: 99.1791, s0.loss_bbox: 0.0148, s1.loss_cls: 0.0146, s1.acc: 98.8251, s1.loss_bbox: 0.0265, s2.loss_cls: 0.0092, s2.acc: 98.5748, s2.loss_bbox: 0.0239, loss: 0.1173, grad_norm: 3.8213\n",
            "2020-09-07 14:36:36,883 - mmdet - INFO - Epoch [14][960/5332]\tlr: 1.000e-05, eta: 18:47:10, time: 1.830, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0244, s0.acc: 98.9899, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0179, s1.acc: 98.4863, s1.loss_bbox: 0.0314, s2.loss_cls: 0.0109, s2.acc: 98.1232, s2.loss_bbox: 0.0254, loss: 0.1384, grad_norm: 4.3946\n",
            "2020-09-07 14:38:32,490 - mmdet - INFO - Epoch [14][1024/5332]\tlr: 1.000e-05, eta: 18:43:10, time: 1.806, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0222, s0.acc: 99.1272, s0.loss_bbox: 0.0188, s1.loss_cls: 0.0149, s1.acc: 98.8312, s1.loss_bbox: 0.0307, s2.loss_cls: 0.0089, s2.acc: 98.5931, s2.loss_bbox: 0.0237, loss: 0.1303, grad_norm: 4.4015\n",
            "2020-09-07 14:40:28,535 - mmdet - INFO - Epoch [14][1088/5332]\tlr: 1.000e-05, eta: 18:39:39, time: 1.813, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0252, s0.acc: 98.9655, s0.loss_bbox: 0.0169, s1.loss_cls: 0.0173, s1.acc: 98.7000, s1.loss_bbox: 0.0242, s2.loss_cls: 0.0101, s2.acc: 98.6420, s2.loss_bbox: 0.0220, loss: 0.1229, grad_norm: 3.8882\n",
            "2020-09-07 14:42:25,811 - mmdet - INFO - Epoch [14][1152/5332]\tlr: 1.000e-05, eta: 18:36:57, time: 1.832, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0235, s0.acc: 99.0417, s0.loss_bbox: 0.0178, s1.loss_cls: 0.0142, s1.acc: 98.8464, s1.loss_bbox: 0.0309, s2.loss_cls: 0.0085, s2.acc: 98.6664, s2.loss_bbox: 0.0237, loss: 0.1257, grad_norm: 4.0951\n",
            "2020-09-07 14:44:23,490 - mmdet - INFO - Epoch [14][1216/5332]\tlr: 1.000e-05, eta: 18:34:32, time: 1.839, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0265, s0.acc: 98.9807, s0.loss_bbox: 0.0196, s1.loss_cls: 0.0159, s1.acc: 98.7701, s1.loss_bbox: 0.0342, s2.loss_cls: 0.0102, s2.acc: 98.2849, s2.loss_bbox: 0.0247, loss: 0.1381, grad_norm: 4.4840\n",
            "2020-09-07 14:46:21,160 - mmdet - INFO - Epoch [14][1280/5332]\tlr: 1.000e-05, eta: 18:32:09, time: 1.839, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0028, s0.loss_cls: 0.0203, s0.acc: 99.2188, s0.loss_bbox: 0.0158, s1.loss_cls: 0.0147, s1.acc: 98.8190, s1.loss_bbox: 0.0236, s2.loss_cls: 0.0094, s2.acc: 98.4039, s2.loss_bbox: 0.0186, loss: 0.1077, grad_norm: 3.7540\n",
            "2020-09-07 14:48:19,594 - mmdet - INFO - Epoch [14][1344/5332]\tlr: 1.000e-05, eta: 18:30:09, time: 1.851, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0273, s0.acc: 98.9716, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0176, s1.acc: 98.7854, s1.loss_bbox: 0.0283, s2.loss_cls: 0.0116, s2.acc: 98.2758, s2.loss_bbox: 0.0226, loss: 0.1362, grad_norm: 4.6836\n",
            "2020-09-07 14:50:17,961 - mmdet - INFO - Epoch [14][1408/5332]\tlr: 1.000e-05, eta: 18:28:08, time: 1.849, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0057, loss_rpn_bbox: 0.0070, s0.loss_cls: 0.0217, s0.acc: 99.1730, s0.loss_bbox: 0.0133, s1.loss_cls: 0.0133, s1.acc: 98.9532, s1.loss_bbox: 0.0258, s2.loss_cls: 0.0085, s2.acc: 98.6816, s2.loss_bbox: 0.0230, loss: 0.1183, grad_norm: 4.1988\n",
            "2020-09-07 14:52:15,647 - mmdet - INFO - Epoch [14][1472/5332]\tlr: 1.000e-05, eta: 18:25:50, time: 1.839, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0202, s0.acc: 99.2065, s0.loss_bbox: 0.0142, s1.loss_cls: 0.0135, s1.acc: 98.9929, s1.loss_bbox: 0.0243, s2.loss_cls: 0.0092, s2.acc: 98.5260, s2.loss_bbox: 0.0242, loss: 0.1129, grad_norm: 4.1403\n",
            "2020-09-07 14:54:13,843 - mmdet - INFO - Epoch [14][1536/5332]\tlr: 1.000e-05, eta: 18:23:46, time: 1.847, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0206, s0.acc: 99.2004, s0.loss_bbox: 0.0153, s1.loss_cls: 0.0133, s1.acc: 98.9716, s1.loss_bbox: 0.0263, s2.loss_cls: 0.0085, s2.acc: 98.6908, s2.loss_bbox: 0.0223, loss: 0.1150, grad_norm: 3.8160\n",
            "2020-09-07 14:56:12,297 - mmdet - INFO - Epoch [14][1600/5332]\tlr: 1.000e-05, eta: 18:21:48, time: 1.851, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0256, s0.acc: 98.9655, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0178, s1.acc: 98.6084, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0105, s2.acc: 98.2025, s2.loss_bbox: 0.0243, loss: 0.1344, grad_norm: 4.5406\n",
            "2020-09-07 14:58:11,109 - mmdet - INFO - Epoch [14][1664/5332]\tlr: 1.000e-05, eta: 18:19:58, time: 1.856, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0225, s0.acc: 99.1455, s0.loss_bbox: 0.0148, s1.loss_cls: 0.0142, s1.acc: 98.8770, s1.loss_bbox: 0.0259, s2.loss_cls: 0.0100, s2.acc: 98.2788, s2.loss_bbox: 0.0220, loss: 0.1170, grad_norm: 4.1517\n",
            "2020-09-07 15:00:09,886 - mmdet - INFO - Epoch [14][1728/5332]\tlr: 1.000e-05, eta: 18:18:06, time: 1.856, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0315, s0.acc: 98.7732, s0.loss_bbox: 0.0230, s1.loss_cls: 0.0210, s1.acc: 98.3582, s1.loss_bbox: 0.0335, s2.loss_cls: 0.0137, s2.acc: 97.6929, s2.loss_bbox: 0.0260, loss: 0.1576, grad_norm: 5.2276\n",
            "2020-09-07 15:02:07,833 - mmdet - INFO - Epoch [14][1792/5332]\tlr: 1.000e-05, eta: 18:15:57, time: 1.843, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0079, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0206, s0.acc: 99.2126, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0130, s1.acc: 98.9990, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0088, s2.acc: 98.6664, s2.loss_bbox: 0.0275, loss: 0.1296, grad_norm: 4.7423\n",
            "2020-09-07 15:04:04,540 - mmdet - INFO - Epoch [14][1856/5332]\tlr: 1.000e-05, eta: 18:13:26, time: 1.824, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0269, s0.acc: 98.9075, s0.loss_bbox: 0.0197, s1.loss_cls: 0.0194, s1.acc: 98.4344, s1.loss_bbox: 0.0330, s2.loss_cls: 0.0123, s2.acc: 98.0682, s2.loss_bbox: 0.0270, loss: 0.1471, grad_norm: 4.6563\n",
            "2020-09-07 15:06:02,066 - mmdet - INFO - Epoch [14][1920/5332]\tlr: 1.000e-05, eta: 18:11:11, time: 1.836, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0219, s0.acc: 99.1333, s0.loss_bbox: 0.0173, s1.loss_cls: 0.0127, s1.acc: 99.0326, s1.loss_bbox: 0.0313, s2.loss_cls: 0.0087, s2.acc: 98.5596, s2.loss_bbox: 0.0260, loss: 0.1255, grad_norm: 4.0761\n",
            "2020-09-07 15:08:01,706 - mmdet - INFO - Epoch [14][1984/5332]\tlr: 1.000e-05, eta: 18:09:36, time: 1.869, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0203, s0.acc: 99.1821, s0.loss_bbox: 0.0149, s1.loss_cls: 0.0129, s1.acc: 98.9319, s1.loss_bbox: 0.0233, s2.loss_cls: 0.0079, s2.acc: 98.6664, s2.loss_bbox: 0.0199, loss: 0.1067, grad_norm: 3.9623\n",
            "2020-09-07 15:09:59,587 - mmdet - INFO - Epoch [14][2048/5332]\tlr: 1.000e-05, eta: 18:07:29, time: 1.842, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0246, s0.acc: 99.0112, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0147, s1.acc: 98.7793, s1.loss_bbox: 0.0327, s2.loss_cls: 0.0095, s2.acc: 98.3429, s2.loss_bbox: 0.0279, loss: 0.1363, grad_norm: 4.7502\n",
            "2020-09-07 15:11:59,732 - mmdet - INFO - Epoch [14][2112/5332]\tlr: 1.000e-05, eta: 18:06:00, time: 1.877, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0209, s0.acc: 99.1791, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0155, s1.acc: 98.6603, s1.loss_bbox: 0.0265, s2.loss_cls: 0.0108, s2.acc: 98.0835, s2.loss_bbox: 0.0213, loss: 0.1198, grad_norm: 3.8833\n",
            "2020-09-07 15:13:58,221 - mmdet - INFO - Epoch [14][2176/5332]\tlr: 1.000e-05, eta: 18:04:02, time: 1.851, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0234, s0.acc: 99.0936, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0151, s1.acc: 98.8342, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0090, s2.acc: 98.5931, s2.loss_bbox: 0.0250, loss: 0.1283, grad_norm: 4.3076\n",
            "2020-09-07 15:15:56,362 - mmdet - INFO - Epoch [14][2240/5332]\tlr: 1.000e-05, eta: 18:01:59, time: 1.846, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0219, s0.acc: 99.1119, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0137, s1.acc: 98.9777, s1.loss_bbox: 0.0252, s2.loss_cls: 0.0089, s2.acc: 98.5535, s2.loss_bbox: 0.0255, loss: 0.1180, grad_norm: 4.2615\n",
            "2020-09-07 15:17:53,889 - mmdet - INFO - Epoch [14][2304/5332]\tlr: 1.000e-05, eta: 17:59:47, time: 1.836, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0227, s0.acc: 99.0143, s0.loss_bbox: 0.0149, s1.loss_cls: 0.0157, s1.acc: 98.6969, s1.loss_bbox: 0.0280, s2.loss_cls: 0.0115, s2.acc: 98.0164, s2.loss_bbox: 0.0238, loss: 0.1253, grad_norm: 4.5574\n",
            "2020-09-07 15:19:50,995 - mmdet - INFO - Epoch [14][2368/5332]\tlr: 1.000e-05, eta: 17:57:30, time: 1.830, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0259, s0.acc: 98.9349, s0.loss_bbox: 0.0200, s1.loss_cls: 0.0165, s1.acc: 98.6053, s1.loss_bbox: 0.0382, s2.loss_cls: 0.0121, s2.acc: 97.8516, s2.loss_bbox: 0.0309, loss: 0.1526, grad_norm: 4.7045\n",
            "2020-09-07 15:21:46,630 - mmdet - INFO - Epoch [14][2432/5332]\tlr: 1.000e-05, eta: 17:54:52, time: 1.807, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0215, s0.acc: 99.2218, s0.loss_bbox: 0.0131, s1.loss_cls: 0.0134, s1.acc: 98.9532, s1.loss_bbox: 0.0246, s2.loss_cls: 0.0087, s2.acc: 98.5870, s2.loss_bbox: 0.0217, loss: 0.1109, grad_norm: 3.8000\n",
            "2020-09-07 15:23:45,713 - mmdet - INFO - Epoch [14][2496/5332]\tlr: 1.000e-05, eta: 17:53:05, time: 1.861, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0076, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0307, s0.acc: 98.8312, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0194, s1.acc: 98.5077, s1.loss_bbox: 0.0230, s2.loss_cls: 0.0119, s2.acc: 98.1476, s2.loss_bbox: 0.0191, loss: 0.1329, grad_norm: 4.3738\n",
            "2020-09-07 15:25:43,873 - mmdet - INFO - Epoch [14][2560/5332]\tlr: 1.000e-05, eta: 17:51:04, time: 1.846, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0260, s0.acc: 98.9288, s0.loss_bbox: 0.0208, s1.loss_cls: 0.0184, s1.acc: 98.4802, s1.loss_bbox: 0.0311, s2.loss_cls: 0.0116, s2.acc: 98.0774, s2.loss_bbox: 0.0211, loss: 0.1359, grad_norm: 4.4236\n",
            "2020-09-07 15:27:42,849 - mmdet - INFO - Epoch [14][2624/5332]\tlr: 1.000e-05, eta: 17:49:15, time: 1.859, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0253, s0.acc: 99.0387, s0.loss_bbox: 0.0161, s1.loss_cls: 0.0165, s1.acc: 98.7579, s1.loss_bbox: 0.0256, s2.loss_cls: 0.0099, s2.acc: 98.3246, s2.loss_bbox: 0.0215, loss: 0.1235, grad_norm: 4.6481\n",
            "2020-09-07 15:29:41,647 - mmdet - INFO - Epoch [14][2688/5332]\tlr: 1.000e-05, eta: 17:47:23, time: 1.856, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0217, s0.acc: 99.1119, s0.loss_bbox: 0.0157, s1.loss_cls: 0.0129, s1.acc: 99.0479, s1.loss_bbox: 0.0271, s2.loss_cls: 0.0091, s2.acc: 98.6847, s2.loss_bbox: 0.0237, loss: 0.1197, grad_norm: 4.0379\n",
            "2020-09-07 15:31:41,146 - mmdet - INFO - Epoch [14][2752/5332]\tlr: 1.000e-05, eta: 17:45:39, time: 1.867, data_time: 0.005, memory: 8800, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0065, s0.loss_cls: 0.0210, s0.acc: 99.1333, s0.loss_bbox: 0.0154, s1.loss_cls: 0.0146, s1.acc: 98.7335, s1.loss_bbox: 0.0299, s2.loss_cls: 0.0089, s2.acc: 98.5168, s2.loss_bbox: 0.0241, loss: 0.1245, grad_norm: 4.3384\n",
            "2020-09-07 15:33:39,384 - mmdet - INFO - Epoch [14][2816/5332]\tlr: 1.000e-05, eta: 17:43:39, time: 1.847, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0237, s0.acc: 99.1333, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0147, s1.acc: 98.8281, s1.loss_bbox: 0.0267, s2.loss_cls: 0.0102, s2.acc: 98.3490, s2.loss_bbox: 0.0218, loss: 0.1240, grad_norm: 4.1357\n",
            "2020-09-07 15:35:38,340 - mmdet - INFO - Epoch [14][2880/5332]\tlr: 1.000e-05, eta: 17:41:48, time: 1.859, data_time: 0.005, memory: 8800, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0068, s0.loss_cls: 0.0310, s0.acc: 98.8403, s0.loss_bbox: 0.0209, s1.loss_cls: 0.0209, s1.acc: 98.3551, s1.loss_bbox: 0.0306, s2.loss_cls: 0.0117, s2.acc: 98.0896, s2.loss_bbox: 0.0267, loss: 0.1532, grad_norm: 5.1250\n",
            "2020-09-07 15:37:36,271 - mmdet - INFO - Epoch [14][2944/5332]\tlr: 1.000e-05, eta: 17:39:44, time: 1.843, data_time: 0.005, memory: 8800, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0255, s0.acc: 98.9716, s0.loss_bbox: 0.0217, s1.loss_cls: 0.0160, s1.acc: 98.7579, s1.loss_bbox: 0.0333, s2.loss_cls: 0.0092, s2.acc: 98.4772, s2.loss_bbox: 0.0250, loss: 0.1410, grad_norm: 4.0794\n",
            "2020-09-07 15:39:36,809 - mmdet - INFO - Epoch [14][3008/5332]\tlr: 1.000e-05, eta: 17:38:10, time: 1.883, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0233, s0.acc: 99.0051, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0152, s1.acc: 98.7549, s1.loss_bbox: 0.0297, s2.loss_cls: 0.0102, s2.acc: 98.3032, s2.loss_bbox: 0.0247, loss: 0.1279, grad_norm: 4.4116\n",
            "2020-09-07 15:41:36,206 - mmdet - INFO - Epoch [14][3072/5332]\tlr: 1.000e-05, eta: 17:36:23, time: 1.866, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0062, s0.loss_cls: 0.0322, s0.acc: 98.8312, s0.loss_bbox: 0.0207, s1.loss_cls: 0.0213, s1.acc: 98.3063, s1.loss_bbox: 0.0329, s2.loss_cls: 0.0135, s2.acc: 97.6440, s2.loss_bbox: 0.0268, loss: 0.1576, grad_norm: 5.0626\n",
            "2020-09-07 15:43:35,158 - mmdet - INFO - Epoch [14][3136/5332]\tlr: 1.000e-05, eta: 17:34:30, time: 1.859, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0216, s0.acc: 99.1364, s0.loss_bbox: 0.0151, s1.loss_cls: 0.0141, s1.acc: 98.9197, s1.loss_bbox: 0.0250, s2.loss_cls: 0.0089, s2.acc: 98.5504, s2.loss_bbox: 0.0236, loss: 0.1167, grad_norm: 4.3196\n",
            "2020-09-07 15:45:36,324 - mmdet - INFO - Epoch [14][3200/5332]\tlr: 1.000e-05, eta: 17:33:01, time: 1.893, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0068, s0.loss_cls: 0.0264, s0.acc: 98.9838, s0.loss_bbox: 0.0203, s1.loss_cls: 0.0190, s1.acc: 98.4894, s1.loss_bbox: 0.0339, s2.loss_cls: 0.0128, s2.acc: 97.7600, s2.loss_bbox: 0.0254, loss: 0.1491, grad_norm: 4.7069\n",
            "2020-09-07 15:47:36,418 - mmdet - INFO - Epoch [14][3264/5332]\tlr: 1.000e-05, eta: 17:31:19, time: 1.876, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0246, s0.acc: 99.0540, s0.loss_bbox: 0.0161, s1.loss_cls: 0.0148, s1.acc: 98.8464, s1.loss_bbox: 0.0253, s2.loss_cls: 0.0093, s2.acc: 98.4802, s2.loss_bbox: 0.0198, loss: 0.1172, grad_norm: 4.0138\n",
            "2020-09-07 15:49:34,881 - mmdet - INFO - Epoch [14][3328/5332]\tlr: 1.000e-05, eta: 17:29:20, time: 1.851, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0253, s0.acc: 99.0204, s0.loss_bbox: 0.0176, s1.loss_cls: 0.0170, s1.acc: 98.5779, s1.loss_bbox: 0.0278, s2.loss_cls: 0.0100, s2.acc: 98.2849, s2.loss_bbox: 0.0223, loss: 0.1259, grad_norm: 4.4001\n",
            "2020-09-07 15:51:33,718 - mmdet - INFO - Epoch [14][3392/5332]\tlr: 1.000e-05, eta: 17:27:24, time: 1.857, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0244, s0.acc: 99.0601, s0.loss_bbox: 0.0162, s1.loss_cls: 0.0156, s1.acc: 98.7732, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0095, s2.acc: 98.3643, s2.loss_bbox: 0.0193, loss: 0.1228, grad_norm: 4.0919\n",
            "2020-09-07 15:53:32,916 - mmdet - INFO - Epoch [14][3456/5332]\tlr: 1.000e-05, eta: 17:25:32, time: 1.862, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0204, s0.acc: 99.1821, s0.loss_bbox: 0.0166, s1.loss_cls: 0.0144, s1.acc: 98.8678, s1.loss_bbox: 0.0292, s2.loss_cls: 0.0094, s2.acc: 98.3978, s2.loss_bbox: 0.0231, loss: 0.1206, grad_norm: 4.3589\n",
            "2020-09-07 15:55:32,324 - mmdet - INFO - Epoch [14][3520/5332]\tlr: 1.000e-05, eta: 17:23:42, time: 1.866, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0209, s0.acc: 99.1669, s0.loss_bbox: 0.0185, s1.loss_cls: 0.0133, s1.acc: 98.9044, s1.loss_bbox: 0.0307, s2.loss_cls: 0.0090, s2.acc: 98.3917, s2.loss_bbox: 0.0225, loss: 0.1205, grad_norm: 4.0486\n",
            "2020-09-07 15:57:32,769 - mmdet - INFO - Epoch [14][3584/5332]\tlr: 1.000e-05, eta: 17:22:01, time: 1.882, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0274, s0.acc: 98.8770, s0.loss_bbox: 0.0197, s1.loss_cls: 0.0169, s1.acc: 98.6115, s1.loss_bbox: 0.0295, s2.loss_cls: 0.0117, s2.acc: 98.0774, s2.loss_bbox: 0.0234, loss: 0.1372, grad_norm: 4.9543\n",
            "2020-09-07 15:59:32,566 - mmdet - INFO - Epoch [14][3648/5332]\tlr: 1.000e-05, eta: 17:20:14, time: 1.872, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0348, s0.acc: 98.6786, s0.loss_bbox: 0.0192, s1.loss_cls: 0.0240, s1.acc: 98.2239, s1.loss_bbox: 0.0321, s2.loss_cls: 0.0157, s2.acc: 97.6013, s2.loss_bbox: 0.0213, loss: 0.1558, grad_norm: 5.0197\n",
            "2020-09-07 16:01:31,802 - mmdet - INFO - Epoch [14][3712/5332]\tlr: 1.000e-05, eta: 17:18:21, time: 1.863, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0309, s0.acc: 98.7823, s0.loss_bbox: 0.0214, s1.loss_cls: 0.0188, s1.acc: 98.5413, s1.loss_bbox: 0.0325, s2.loss_cls: 0.0118, s2.acc: 98.1293, s2.loss_bbox: 0.0265, loss: 0.1519, grad_norm: 5.0630\n",
            "2020-09-07 16:03:30,487 - mmdet - INFO - Epoch [14][3776/5332]\tlr: 1.000e-05, eta: 17:16:23, time: 1.854, data_time: 0.005, memory: 8800, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0272, s0.acc: 98.9136, s0.loss_bbox: 0.0187, s1.loss_cls: 0.0176, s1.acc: 98.6206, s1.loss_bbox: 0.0293, s2.loss_cls: 0.0114, s2.acc: 98.3582, s2.loss_bbox: 0.0242, loss: 0.1355, grad_norm: 4.4088\n",
            "2020-09-07 16:05:28,946 - mmdet - INFO - Epoch [14][3840/5332]\tlr: 1.000e-05, eta: 17:14:22, time: 1.851, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0231, s0.acc: 99.0784, s0.loss_bbox: 0.0158, s1.loss_cls: 0.0154, s1.acc: 98.7518, s1.loss_bbox: 0.0245, s2.loss_cls: 0.0099, s2.acc: 98.3093, s2.loss_bbox: 0.0202, loss: 0.1157, grad_norm: 3.8282\n",
            "2020-09-07 16:07:28,619 - mmdet - INFO - Epoch [14][3904/5332]\tlr: 1.000e-05, eta: 17:12:33, time: 1.870, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0226, s0.acc: 99.1638, s0.loss_bbox: 0.0174, s1.loss_cls: 0.0163, s1.acc: 98.7091, s1.loss_bbox: 0.0281, s2.loss_cls: 0.0095, s2.acc: 98.4802, s2.loss_bbox: 0.0249, loss: 0.1283, grad_norm: 4.4657\n",
            "2020-09-07 16:09:26,454 - mmdet - INFO - Epoch [14][3968/5332]\tlr: 1.000e-05, eta: 17:10:27, time: 1.841, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0251, s0.acc: 98.9655, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0178, s1.acc: 98.4680, s1.loss_bbox: 0.0255, s2.loss_cls: 0.0112, s2.acc: 98.1506, s2.loss_bbox: 0.0236, loss: 0.1280, grad_norm: 4.5897\n",
            "2020-09-07 16:11:26,485 - mmdet - INFO - Epoch [14][4032/5332]\tlr: 1.000e-05, eta: 17:08:40, time: 1.875, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0259, s0.acc: 98.9807, s0.loss_bbox: 0.0195, s1.loss_cls: 0.0165, s1.acc: 98.7732, s1.loss_bbox: 0.0297, s2.loss_cls: 0.0097, s2.acc: 98.5687, s2.loss_bbox: 0.0235, loss: 0.1344, grad_norm: 4.5539\n",
            "2020-09-07 16:13:25,842 - mmdet - INFO - Epoch [14][4096/5332]\tlr: 1.000e-05, eta: 17:06:47, time: 1.865, data_time: 0.012, memory: 8800, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0024, s0.loss_cls: 0.0214, s0.acc: 99.1760, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0149, s1.acc: 98.8098, s1.loss_bbox: 0.0312, s2.loss_cls: 0.0101, s2.acc: 98.3734, s2.loss_bbox: 0.0256, loss: 0.1250, grad_norm: 4.4002\n",
            "2020-09-07 16:15:25,001 - mmdet - INFO - Epoch [14][4160/5332]\tlr: 1.000e-05, eta: 17:04:53, time: 1.862, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0067, s0.loss_cls: 0.0235, s0.acc: 99.0479, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0153, s1.acc: 98.8617, s1.loss_bbox: 0.0338, s2.loss_cls: 0.0105, s2.acc: 98.3490, s2.loss_bbox: 0.0269, loss: 0.1403, grad_norm: 4.4113\n",
            "2020-09-07 16:17:23,102 - mmdet - INFO - Epoch [14][4224/5332]\tlr: 1.000e-05, eta: 17:02:50, time: 1.845, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0250, s0.acc: 99.0234, s0.loss_bbox: 0.0177, s1.loss_cls: 0.0164, s1.acc: 98.7579, s1.loss_bbox: 0.0344, s2.loss_cls: 0.0111, s2.acc: 98.2666, s2.loss_bbox: 0.0318, loss: 0.1460, grad_norm: 5.0419\n",
            "2020-09-07 16:19:21,399 - mmdet - INFO - Epoch [14][4288/5332]\tlr: 1.000e-05, eta: 17:00:48, time: 1.848, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0269, s0.acc: 98.9166, s0.loss_bbox: 0.0192, s1.loss_cls: 0.0173, s1.acc: 98.6877, s1.loss_bbox: 0.0301, s2.loss_cls: 0.0108, s2.acc: 98.3093, s2.loss_bbox: 0.0262, loss: 0.1395, grad_norm: 4.4669\n",
            "2020-09-07 16:21:21,069 - mmdet - INFO - Epoch [14][4352/5332]\tlr: 1.000e-05, eta: 16:58:57, time: 1.870, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0073, s0.loss_cls: 0.0271, s0.acc: 98.8739, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0176, s1.acc: 98.5870, s1.loss_bbox: 0.0307, s2.loss_cls: 0.0119, s2.acc: 97.9156, s2.loss_bbox: 0.0220, loss: 0.1384, grad_norm: 4.5293\n",
            "2020-09-07 16:23:18,320 - mmdet - INFO - Epoch [14][4416/5332]\tlr: 1.000e-05, eta: 16:56:48, time: 1.832, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0240, s0.acc: 99.0265, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0175, s1.acc: 98.6511, s1.loss_bbox: 0.0300, s2.loss_cls: 0.0109, s2.acc: 98.2422, s2.loss_bbox: 0.0268, loss: 0.1337, grad_norm: 4.7160\n",
            "2020-09-07 16:25:15,576 - mmdet - INFO - Epoch [14][4480/5332]\tlr: 1.000e-05, eta: 16:54:39, time: 1.832, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0225, s0.acc: 99.0814, s0.loss_bbox: 0.0162, s1.loss_cls: 0.0142, s1.acc: 98.7305, s1.loss_bbox: 0.0272, s2.loss_cls: 0.0100, s2.acc: 98.0499, s2.loss_bbox: 0.0230, loss: 0.1213, grad_norm: 4.1537\n",
            "2020-09-07 16:27:12,438 - mmdet - INFO - Epoch [14][4544/5332]\tlr: 1.000e-05, eta: 16:52:28, time: 1.826, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0197, s0.acc: 99.2798, s0.loss_bbox: 0.0133, s1.loss_cls: 0.0129, s1.acc: 98.9960, s1.loss_bbox: 0.0225, s2.loss_cls: 0.0074, s2.acc: 98.7701, s2.loss_bbox: 0.0189, loss: 0.1008, grad_norm: 3.6172\n",
            "2020-09-07 16:29:09,536 - mmdet - INFO - Epoch [14][4608/5332]\tlr: 1.000e-05, eta: 16:50:18, time: 1.830, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0243, s0.acc: 99.0021, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0164, s1.acc: 98.6603, s1.loss_bbox: 0.0287, s2.loss_cls: 0.0102, s2.acc: 98.0530, s2.loss_bbox: 0.0226, loss: 0.1265, grad_norm: 4.5211\n",
            "2020-09-07 16:31:07,416 - mmdet - INFO - Epoch [14][4672/5332]\tlr: 1.000e-05, eta: 16:48:15, time: 1.842, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0276, s0.acc: 98.8373, s0.loss_bbox: 0.0202, s1.loss_cls: 0.0173, s1.acc: 98.5046, s1.loss_bbox: 0.0331, s2.loss_cls: 0.0103, s2.acc: 98.2391, s2.loss_bbox: 0.0243, loss: 0.1408, grad_norm: 4.8934\n",
            "2020-09-07 16:33:04,144 - mmdet - INFO - Epoch [14][4736/5332]\tlr: 1.000e-05, eta: 16:46:04, time: 1.824, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0226, s0.acc: 99.0295, s0.loss_bbox: 0.0146, s1.loss_cls: 0.0145, s1.acc: 98.8129, s1.loss_bbox: 0.0257, s2.loss_cls: 0.0098, s2.acc: 98.3215, s2.loss_bbox: 0.0219, loss: 0.1170, grad_norm: 3.9989\n",
            "2020-09-07 16:35:02,018 - mmdet - INFO - Epoch [14][4800/5332]\tlr: 1.000e-05, eta: 16:44:00, time: 1.842, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0062, loss_rpn_bbox: 0.0061, s0.loss_cls: 0.0351, s0.acc: 98.7701, s0.loss_bbox: 0.0215, s1.loss_cls: 0.0215, s1.acc: 98.3917, s1.loss_bbox: 0.0360, s2.loss_cls: 0.0134, s2.acc: 98.0316, s2.loss_bbox: 0.0258, loss: 0.1656, grad_norm: 5.5236\n",
            "2020-09-07 16:36:58,842 - mmdet - INFO - Epoch [14][4864/5332]\tlr: 1.000e-05, eta: 16:41:50, time: 1.825, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0253, s0.acc: 98.9746, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0164, s1.acc: 98.5992, s1.loss_bbox: 0.0289, s2.loss_cls: 0.0116, s2.acc: 98.0072, s2.loss_bbox: 0.0239, loss: 0.1302, grad_norm: 4.1625\n",
            "2020-09-07 16:38:56,771 - mmdet - INFO - Epoch [14][4928/5332]\tlr: 1.000e-05, eta: 16:39:48, time: 1.843, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0236, s0.acc: 99.0509, s0.loss_bbox: 0.0206, s1.loss_cls: 0.0146, s1.acc: 98.7793, s1.loss_bbox: 0.0350, s2.loss_cls: 0.0093, s2.acc: 98.4924, s2.loss_bbox: 0.0272, loss: 0.1370, grad_norm: 4.8976\n",
            "2020-09-07 16:40:54,790 - mmdet - INFO - Epoch [14][4992/5332]\tlr: 1.000e-05, eta: 16:37:46, time: 1.844, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0028, s0.loss_cls: 0.0266, s0.acc: 98.9624, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0149, s1.acc: 98.9288, s1.loss_bbox: 0.0288, s2.loss_cls: 0.0093, s2.acc: 98.4894, s2.loss_bbox: 0.0234, loss: 0.1254, grad_norm: 4.2619\n",
            "2020-09-07 16:42:52,733 - mmdet - INFO - Epoch [14][5056/5332]\tlr: 1.000e-05, eta: 16:35:44, time: 1.843, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0270, s0.acc: 98.8739, s0.loss_bbox: 0.0166, s1.loss_cls: 0.0169, s1.acc: 98.6786, s1.loss_bbox: 0.0303, s2.loss_cls: 0.0122, s2.acc: 98.0377, s2.loss_bbox: 0.0233, loss: 0.1360, grad_norm: 4.6033\n",
            "2020-09-07 16:44:49,150 - mmdet - INFO - Epoch [14][5120/5332]\tlr: 1.000e-05, eta: 16:33:33, time: 1.819, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0064, s0.loss_cls: 0.0215, s0.acc: 99.0997, s0.loss_bbox: 0.0191, s1.loss_cls: 0.0142, s1.acc: 98.9105, s1.loss_bbox: 0.0325, s2.loss_cls: 0.0109, s2.acc: 98.2178, s2.loss_bbox: 0.0252, loss: 0.1339, grad_norm: 4.2270\n",
            "2020-09-07 16:46:46,886 - mmdet - INFO - Epoch [14][5184/5332]\tlr: 1.000e-05, eta: 16:31:30, time: 1.840, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0063, s0.loss_cls: 0.0283, s0.acc: 98.8281, s0.loss_bbox: 0.0176, s1.loss_cls: 0.0178, s1.acc: 98.5077, s1.loss_bbox: 0.0266, s2.loss_cls: 0.0118, s2.acc: 98.0560, s2.loss_bbox: 0.0237, loss: 0.1360, grad_norm: 4.8928\n",
            "2020-09-07 16:48:44,356 - mmdet - INFO - Epoch [14][5248/5332]\tlr: 1.000e-05, eta: 16:29:25, time: 1.835, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0240, s0.acc: 99.0570, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0154, s1.acc: 98.7030, s1.loss_bbox: 0.0278, s2.loss_cls: 0.0108, s2.acc: 98.0835, s2.loss_bbox: 0.0231, loss: 0.1251, grad_norm: 4.2932\n",
            "2020-09-07 16:50:43,763 - mmdet - INFO - Epoch [14][5312/5332]\tlr: 1.000e-05, eta: 16:27:32, time: 1.866, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0246, s0.acc: 99.1241, s0.loss_bbox: 0.0149, s1.loss_cls: 0.0153, s1.acc: 98.8770, s1.loss_bbox: 0.0263, s2.loss_cls: 0.0105, s2.acc: 98.4222, s2.loss_bbox: 0.0219, loss: 0.1216, grad_norm: 4.2351\n",
            "2020-09-07 16:51:20,186 - mmdet - INFO - Saving checkpoint at 14 epochs\n",
            "[>>] 667/667, 0.6 task/s, elapsed: 1059s, ETA:     0s2020-09-07 17:09:06,061 - mmdet - INFO - \n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 82  | 234  | 0.854  | 0.590 |\n",
            "| 3     | 22  | 98   | 0.818  | 0.710 |\n",
            "| 4     | 529 | 1173 | 0.922  | 0.829 |\n",
            "| 5     | 78  | 174  | 0.885  | 0.794 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.731 |\n",
            "+-------+-----+------+--------+-------+\n",
            "2020-09-07 17:09:06,066 - mmdet - INFO - Epoch(val) [14][5332]\tmAP: 0.7306\n",
            "2020-09-07 17:11:05,566 - mmdet - INFO - Epoch [15][64/5332]\tlr: 1.000e-05, eta: 16:21:24, time: 1.867, data_time: 0.037, memory: 8800, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0064, s0.loss_cls: 0.0232, s0.acc: 99.1333, s0.loss_bbox: 0.0144, s1.loss_cls: 0.0151, s1.acc: 98.8708, s1.loss_bbox: 0.0254, s2.loss_cls: 0.0083, s2.acc: 98.6908, s2.loss_bbox: 0.0227, loss: 0.1185, grad_norm: 4.0831\n",
            "2020-09-07 17:13:05,868 - mmdet - INFO - Epoch [15][128/5332]\tlr: 1.000e-05, eta: 16:19:39, time: 1.880, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0069, s0.loss_cls: 0.0233, s0.acc: 98.9960, s0.loss_bbox: 0.0226, s1.loss_cls: 0.0161, s1.acc: 98.6359, s1.loss_bbox: 0.0354, s2.loss_cls: 0.0106, s2.acc: 98.1720, s2.loss_bbox: 0.0242, loss: 0.1427, grad_norm: 4.3572\n",
            "2020-09-07 17:15:05,661 - mmdet - INFO - Epoch [15][192/5332]\tlr: 1.000e-05, eta: 16:17:51, time: 1.872, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0069, s0.loss_cls: 0.0244, s0.acc: 99.0051, s0.loss_bbox: 0.0186, s1.loss_cls: 0.0147, s1.acc: 98.8190, s1.loss_bbox: 0.0293, s2.loss_cls: 0.0097, s2.acc: 98.5107, s2.loss_bbox: 0.0244, loss: 0.1320, grad_norm: 4.0164\n",
            "2020-09-07 17:17:04,686 - mmdet - INFO - Epoch [15][256/5332]\tlr: 1.000e-05, eta: 16:15:58, time: 1.860, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0240, s0.acc: 99.0204, s0.loss_bbox: 0.0146, s1.loss_cls: 0.0165, s1.acc: 98.6938, s1.loss_bbox: 0.0288, s2.loss_cls: 0.0109, s2.acc: 98.2697, s2.loss_bbox: 0.0244, loss: 0.1271, grad_norm: 4.1810\n",
            "2020-09-07 17:19:02,139 - mmdet - INFO - Epoch [15][320/5332]\tlr: 1.000e-05, eta: 16:13:57, time: 1.835, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0216, s0.acc: 99.1089, s0.loss_bbox: 0.0178, s1.loss_cls: 0.0166, s1.acc: 98.5321, s1.loss_bbox: 0.0268, s2.loss_cls: 0.0094, s2.acc: 98.3765, s2.loss_bbox: 0.0206, loss: 0.1212, grad_norm: 4.3028\n",
            "2020-09-07 17:21:00,462 - mmdet - INFO - Epoch [15][384/5332]\tlr: 1.000e-05, eta: 16:12:00, time: 1.849, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0307, s0.acc: 98.7793, s0.loss_bbox: 0.0225, s1.loss_cls: 0.0212, s1.acc: 98.3765, s1.loss_bbox: 0.0361, s2.loss_cls: 0.0132, s2.acc: 97.8058, s2.loss_bbox: 0.0271, loss: 0.1607, grad_norm: 4.9151\n",
            "2020-09-07 17:22:59,466 - mmdet - INFO - Epoch [15][448/5332]\tlr: 1.000e-05, eta: 16:10:07, time: 1.859, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0279, s0.acc: 98.9594, s0.loss_bbox: 0.0192, s1.loss_cls: 0.0197, s1.acc: 98.4070, s1.loss_bbox: 0.0338, s2.loss_cls: 0.0118, s2.acc: 97.9279, s2.loss_bbox: 0.0261, loss: 0.1473, grad_norm: 4.7481\n",
            "2020-09-07 17:25:00,124 - mmdet - INFO - Epoch [15][512/5332]\tlr: 1.000e-05, eta: 16:08:22, time: 1.885, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0282, s0.acc: 98.8892, s0.loss_bbox: 0.0203, s1.loss_cls: 0.0178, s1.acc: 98.6511, s1.loss_bbox: 0.0299, s2.loss_cls: 0.0112, s2.acc: 98.3704, s2.loss_bbox: 0.0265, loss: 0.1417, grad_norm: 4.4803\n",
            "2020-09-07 17:26:59,892 - mmdet - INFO - Epoch [15][576/5332]\tlr: 1.000e-05, eta: 16:06:33, time: 1.871, data_time: 0.005, memory: 8800, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0248, s0.acc: 99.1119, s0.loss_bbox: 0.0143, s1.loss_cls: 0.0161, s1.acc: 98.7915, s1.loss_bbox: 0.0285, s2.loss_cls: 0.0105, s2.acc: 98.5016, s2.loss_bbox: 0.0276, loss: 0.1306, grad_norm: 4.5001\n",
            "2020-09-07 17:29:00,858 - mmdet - INFO - Epoch [15][640/5332]\tlr: 1.000e-05, eta: 16:04:50, time: 1.890, data_time: 0.005, memory: 8800, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0264, s0.acc: 99.0387, s0.loss_bbox: 0.0147, s1.loss_cls: 0.0157, s1.acc: 98.9380, s1.loss_bbox: 0.0217, s2.loss_cls: 0.0095, s2.acc: 98.6847, s2.loss_bbox: 0.0210, loss: 0.1181, grad_norm: 4.0276\n",
            "2020-09-07 17:30:59,561 - mmdet - INFO - Epoch [15][704/5332]\tlr: 1.000e-05, eta: 16:02:54, time: 1.855, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0113, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0213, s0.acc: 99.1821, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0138, s1.acc: 98.9258, s1.loss_bbox: 0.0288, s2.loss_cls: 0.0091, s2.acc: 98.5382, s2.loss_bbox: 0.0247, loss: 0.1296, grad_norm: 4.6180\n",
            "2020-09-07 17:32:58,719 - mmdet - INFO - Epoch [15][768/5332]\tlr: 1.000e-05, eta: 16:01:01, time: 1.862, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0255, s0.acc: 98.9685, s0.loss_bbox: 0.0174, s1.loss_cls: 0.0158, s1.acc: 98.7091, s1.loss_bbox: 0.0314, s2.loss_cls: 0.0100, s2.acc: 98.2880, s2.loss_bbox: 0.0230, loss: 0.1305, grad_norm: 4.3513\n",
            "2020-09-07 17:34:57,336 - mmdet - INFO - Epoch [15][832/5332]\tlr: 1.000e-05, eta: 15:59:05, time: 1.853, data_time: 0.005, memory: 8800, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0237, s0.acc: 99.0417, s0.loss_bbox: 0.0174, s1.loss_cls: 0.0152, s1.acc: 98.8556, s1.loss_bbox: 0.0260, s2.loss_cls: 0.0099, s2.acc: 98.4741, s2.loss_bbox: 0.0220, loss: 0.1238, grad_norm: 4.1400\n",
            "2020-09-07 17:36:55,937 - mmdet - INFO - Epoch [15][896/5332]\tlr: 1.000e-05, eta: 15:57:09, time: 1.853, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0239, s0.acc: 99.0814, s0.loss_bbox: 0.0158, s1.loss_cls: 0.0154, s1.acc: 98.8831, s1.loss_bbox: 0.0260, s2.loss_cls: 0.0093, s2.acc: 98.6511, s2.loss_bbox: 0.0217, loss: 0.1205, grad_norm: 4.3235\n",
            "2020-09-07 17:38:55,033 - mmdet - INFO - Epoch [15][960/5332]\tlr: 1.000e-05, eta: 15:55:15, time: 1.861, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0268, s0.acc: 98.9532, s0.loss_bbox: 0.0195, s1.loss_cls: 0.0196, s1.acc: 98.4100, s1.loss_bbox: 0.0301, s2.loss_cls: 0.0129, s2.acc: 97.5433, s2.loss_bbox: 0.0239, loss: 0.1408, grad_norm: 4.5877\n",
            "2020-09-07 17:40:53,481 - mmdet - INFO - Epoch [15][1024/5332]\tlr: 1.000e-05, eta: 15:53:18, time: 1.851, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0207, s0.acc: 99.1882, s0.loss_bbox: 0.0146, s1.loss_cls: 0.0136, s1.acc: 98.8678, s1.loss_bbox: 0.0229, s2.loss_cls: 0.0088, s2.acc: 98.4680, s2.loss_bbox: 0.0196, loss: 0.1080, grad_norm: 4.1444\n",
            "2020-09-07 17:42:52,576 - mmdet - INFO - Epoch [15][1088/5332]\tlr: 1.000e-05, eta: 15:51:24, time: 1.861, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0220, s0.acc: 99.0662, s0.loss_bbox: 0.0182, s1.loss_cls: 0.0155, s1.acc: 98.7732, s1.loss_bbox: 0.0297, s2.loss_cls: 0.0101, s2.acc: 98.2941, s2.loss_bbox: 0.0214, loss: 0.1263, grad_norm: 4.3934\n",
            "2020-09-07 17:44:53,826 - mmdet - INFO - Epoch [15][1152/5332]\tlr: 1.000e-05, eta: 15:49:40, time: 1.895, data_time: 0.005, memory: 8800, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0210, s0.acc: 99.2096, s0.loss_bbox: 0.0148, s1.loss_cls: 0.0143, s1.acc: 98.9624, s1.loss_bbox: 0.0261, s2.loss_cls: 0.0090, s2.acc: 98.6633, s2.loss_bbox: 0.0220, loss: 0.1147, grad_norm: 3.9950\n",
            "2020-09-07 17:46:54,203 - mmdet - INFO - Epoch [15][1216/5332]\tlr: 1.000e-05, eta: 15:47:52, time: 1.881, data_time: 0.005, memory: 8800, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0211, s0.acc: 99.1425, s0.loss_bbox: 0.0158, s1.loss_cls: 0.0162, s1.acc: 98.6633, s1.loss_bbox: 0.0260, s2.loss_cls: 0.0110, s2.acc: 98.1171, s2.loss_bbox: 0.0223, loss: 0.1217, grad_norm: 3.9548\n",
            "2020-09-07 17:48:53,136 - mmdet - INFO - Epoch [15][1280/5332]\tlr: 1.000e-05, eta: 15:45:57, time: 1.858, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0231, s0.acc: 98.9807, s0.loss_bbox: 0.0160, s1.loss_cls: 0.0142, s1.acc: 98.7915, s1.loss_bbox: 0.0273, s2.loss_cls: 0.0087, s2.acc: 98.4314, s2.loss_bbox: 0.0245, loss: 0.1210, grad_norm: 4.1825\n",
            "2020-09-07 17:50:51,901 - mmdet - INFO - Epoch [15][1344/5332]\tlr: 1.000e-05, eta: 15:44:01, time: 1.856, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0240, s0.acc: 99.1425, s0.loss_bbox: 0.0176, s1.loss_cls: 0.0156, s1.acc: 98.7946, s1.loss_bbox: 0.0288, s2.loss_cls: 0.0092, s2.acc: 98.4467, s2.loss_bbox: 0.0228, loss: 0.1272, grad_norm: 4.3059\n",
            "2020-09-07 17:52:51,745 - mmdet - INFO - Epoch [15][1408/5332]\tlr: 1.000e-05, eta: 15:42:10, time: 1.873, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0188, s0.acc: 99.2645, s0.loss_bbox: 0.0161, s1.loss_cls: 0.0130, s1.acc: 99.0204, s1.loss_bbox: 0.0262, s2.loss_cls: 0.0087, s2.acc: 98.5474, s2.loss_bbox: 0.0249, loss: 0.1137, grad_norm: 4.3942\n",
            "2020-09-07 17:54:52,187 - mmdet - INFO - Epoch [15][1472/5332]\tlr: 1.000e-05, eta: 15:40:21, time: 1.882, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0223, s0.acc: 99.1211, s0.loss_bbox: 0.0147, s1.loss_cls: 0.0137, s1.acc: 98.9075, s1.loss_bbox: 0.0264, s2.loss_cls: 0.0081, s2.acc: 98.7518, s2.loss_bbox: 0.0250, loss: 0.1176, grad_norm: 4.2663\n",
            "2020-09-07 17:56:51,161 - mmdet - INFO - Epoch [15][1536/5332]\tlr: 1.000e-05, eta: 15:38:26, time: 1.859, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0223, s0.acc: 99.1516, s0.loss_bbox: 0.0168, s1.loss_cls: 0.0163, s1.acc: 98.7701, s1.loss_bbox: 0.0305, s2.loss_cls: 0.0106, s2.acc: 98.2269, s2.loss_bbox: 0.0258, loss: 0.1315, grad_norm: 4.4490\n",
            "2020-09-07 17:58:53,219 - mmdet - INFO - Epoch [15][1600/5332]\tlr: 1.000e-05, eta: 15:36:44, time: 1.907, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0305, s0.acc: 98.7122, s0.loss_bbox: 0.0216, s1.loss_cls: 0.0203, s1.acc: 98.1995, s1.loss_bbox: 0.0317, s2.loss_cls: 0.0125, s2.acc: 97.9065, s2.loss_bbox: 0.0223, loss: 0.1491, grad_norm: 4.9345\n",
            "2020-09-07 18:00:51,570 - mmdet - INFO - Epoch [15][1664/5332]\tlr: 1.000e-05, eta: 15:34:45, time: 1.849, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0235, s0.acc: 99.0509, s0.loss_bbox: 0.0154, s1.loss_cls: 0.0152, s1.acc: 98.7701, s1.loss_bbox: 0.0257, s2.loss_cls: 0.0102, s2.acc: 98.2422, s2.loss_bbox: 0.0222, loss: 0.1198, grad_norm: 4.0648\n",
            "2020-09-07 18:02:51,168 - mmdet - INFO - Epoch [15][1728/5332]\tlr: 1.000e-05, eta: 15:32:52, time: 1.869, data_time: 0.005, memory: 8800, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0266, s0.acc: 98.9777, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0183, s1.acc: 98.6206, s1.loss_bbox: 0.0236, s2.loss_cls: 0.0106, s2.acc: 98.4558, s2.loss_bbox: 0.0206, loss: 0.1264, grad_norm: 4.2831\n",
            "2020-09-07 18:04:50,259 - mmdet - INFO - Epoch [15][1792/5332]\tlr: 1.000e-05, eta: 15:30:57, time: 1.861, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0255, s0.acc: 99.0753, s0.loss_bbox: 0.0188, s1.loss_cls: 0.0167, s1.acc: 98.8586, s1.loss_bbox: 0.0302, s2.loss_cls: 0.0098, s2.acc: 98.3612, s2.loss_bbox: 0.0243, loss: 0.1352, grad_norm: 4.1664\n",
            "2020-09-07 18:06:49,701 - mmdet - INFO - Epoch [15][1856/5332]\tlr: 1.000e-05, eta: 15:29:03, time: 1.866, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0316, s0.acc: 98.6481, s0.loss_bbox: 0.0222, s1.loss_cls: 0.0227, s1.acc: 97.9828, s1.loss_bbox: 0.0322, s2.loss_cls: 0.0137, s2.acc: 97.6532, s2.loss_bbox: 0.0233, loss: 0.1535, grad_norm: 5.2476\n",
            "2020-09-07 18:08:47,975 - mmdet - INFO - Epoch [15][1920/5332]\tlr: 1.000e-05, eta: 15:27:04, time: 1.848, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0279, s0.acc: 98.8434, s0.loss_bbox: 0.0196, s1.loss_cls: 0.0184, s1.acc: 98.3673, s1.loss_bbox: 0.0309, s2.loss_cls: 0.0120, s2.acc: 97.8851, s2.loss_bbox: 0.0234, loss: 0.1411, grad_norm: 4.8663\n",
            "2020-09-07 18:10:47,283 - mmdet - INFO - Epoch [15][1984/5332]\tlr: 1.000e-05, eta: 15:25:10, time: 1.864, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0283, s0.acc: 98.9288, s0.loss_bbox: 0.0212, s1.loss_cls: 0.0177, s1.acc: 98.5962, s1.loss_bbox: 0.0316, s2.loss_cls: 0.0116, s2.acc: 97.9919, s2.loss_bbox: 0.0228, loss: 0.1400, grad_norm: 4.3720\n",
            "2020-09-07 18:12:46,752 - mmdet - INFO - Epoch [15][2048/5332]\tlr: 1.000e-05, eta: 15:23:16, time: 1.867, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0271, s0.acc: 98.8922, s0.loss_bbox: 0.0195, s1.loss_cls: 0.0179, s1.acc: 98.5474, s1.loss_bbox: 0.0294, s2.loss_cls: 0.0117, s2.acc: 97.7936, s2.loss_bbox: 0.0256, loss: 0.1398, grad_norm: 5.1140\n",
            "2020-09-07 18:14:45,319 - mmdet - INFO - Epoch [15][2112/5332]\tlr: 1.000e-05, eta: 15:21:18, time: 1.853, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0260, s0.acc: 98.8953, s0.loss_bbox: 0.0199, s1.loss_cls: 0.0162, s1.acc: 98.6786, s1.loss_bbox: 0.0357, s2.loss_cls: 0.0107, s2.acc: 98.2178, s2.loss_bbox: 0.0291, loss: 0.1469, grad_norm: 4.3952\n",
            "2020-09-07 18:16:46,366 - mmdet - INFO - Epoch [15][2176/5332]\tlr: 1.000e-05, eta: 15:19:30, time: 1.891, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0184, s0.acc: 99.3042, s0.loss_bbox: 0.0131, s1.loss_cls: 0.0117, s1.acc: 99.1364, s1.loss_bbox: 0.0269, s2.loss_cls: 0.0080, s2.acc: 98.6664, s2.loss_bbox: 0.0238, loss: 0.1097, grad_norm: 4.2942\n",
            "2020-09-07 18:18:45,837 - mmdet - INFO - Epoch [15][2240/5332]\tlr: 1.000e-05, eta: 15:17:36, time: 1.867, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0068, s0.loss_cls: 0.0212, s0.acc: 99.1486, s0.loss_bbox: 0.0180, s1.loss_cls: 0.0144, s1.acc: 98.8434, s1.loss_bbox: 0.0303, s2.loss_cls: 0.0091, s2.acc: 98.5657, s2.loss_bbox: 0.0236, loss: 0.1274, grad_norm: 4.0418\n",
            "2020-09-07 18:20:41,732 - mmdet - INFO - Epoch [15][2304/5332]\tlr: 1.000e-05, eta: 15:15:27, time: 1.811, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0084, loss_rpn_bbox: 0.0070, s0.loss_cls: 0.0278, s0.acc: 98.8403, s0.loss_bbox: 0.0197, s1.loss_cls: 0.0193, s1.acc: 98.3490, s1.loss_bbox: 0.0352, s2.loss_cls: 0.0133, s2.acc: 97.8027, s2.loss_bbox: 0.0278, loss: 0.1585, grad_norm: 5.1327\n",
            "2020-09-07 18:22:41,202 - mmdet - INFO - Epoch [15][2368/5332]\tlr: 1.000e-05, eta: 15:13:33, time: 1.867, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0376, s0.acc: 98.5504, s0.loss_bbox: 0.0223, s1.loss_cls: 0.0235, s1.acc: 98.1537, s1.loss_bbox: 0.0261, s2.loss_cls: 0.0141, s2.acc: 97.7966, s2.loss_bbox: 0.0176, loss: 0.1495, grad_norm: 4.9709\n",
            "2020-09-07 18:24:40,041 - mmdet - INFO - Epoch [15][2432/5332]\tlr: 1.000e-05, eta: 15:11:36, time: 1.857, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0268, s0.acc: 98.9380, s0.loss_bbox: 0.0166, s1.loss_cls: 0.0180, s1.acc: 98.4863, s1.loss_bbox: 0.0309, s2.loss_cls: 0.0115, s2.acc: 98.1323, s2.loss_bbox: 0.0293, loss: 0.1431, grad_norm: 4.5354\n",
            "2020-09-07 18:26:39,712 - mmdet - INFO - Epoch [15][2496/5332]\tlr: 1.000e-05, eta: 15:09:43, time: 1.870, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0212, s0.acc: 99.2218, s0.loss_bbox: 0.0166, s1.loss_cls: 0.0129, s1.acc: 99.0265, s1.loss_bbox: 0.0312, s2.loss_cls: 0.0095, s2.acc: 98.5260, s2.loss_bbox: 0.0228, loss: 0.1237, grad_norm: 4.0835\n",
            "2020-09-07 18:28:38,656 - mmdet - INFO - Epoch [15][2560/5332]\tlr: 1.000e-05, eta: 15:07:46, time: 1.858, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0263, s0.acc: 98.9899, s0.loss_bbox: 0.0171, s1.loss_cls: 0.0167, s1.acc: 98.5657, s1.loss_bbox: 0.0283, s2.loss_cls: 0.0103, s2.acc: 98.2544, s2.loss_bbox: 0.0273, loss: 0.1346, grad_norm: 4.6806\n",
            "2020-09-07 18:30:37,239 - mmdet - INFO - Epoch [15][2624/5332]\tlr: 1.000e-05, eta: 15:05:48, time: 1.853, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0201, s0.acc: 99.1638, s0.loss_bbox: 0.0143, s1.loss_cls: 0.0130, s1.acc: 98.9227, s1.loss_bbox: 0.0257, s2.loss_cls: 0.0082, s2.acc: 98.6755, s2.loss_bbox: 0.0243, loss: 0.1115, grad_norm: 4.1286\n",
            "2020-09-07 18:32:35,524 - mmdet - INFO - Epoch [15][2688/5332]\tlr: 1.000e-05, eta: 15:03:49, time: 1.848, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0231, s0.acc: 99.0387, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0145, s1.acc: 98.8312, s1.loss_bbox: 0.0313, s2.loss_cls: 0.0099, s2.acc: 98.4680, s2.loss_bbox: 0.0273, loss: 0.1308, grad_norm: 4.5425\n",
            "2020-09-07 18:34:34,028 - mmdet - INFO - Epoch [15][2752/5332]\tlr: 1.000e-05, eta: 15:01:51, time: 1.852, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0248, s0.acc: 98.9319, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0158, s1.acc: 98.8159, s1.loss_bbox: 0.0284, s2.loss_cls: 0.0102, s2.acc: 98.2971, s2.loss_bbox: 0.0235, loss: 0.1279, grad_norm: 4.2998\n",
            "2020-09-07 18:36:32,258 - mmdet - INFO - Epoch [15][2816/5332]\tlr: 1.000e-05, eta: 14:59:52, time: 1.847, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0236, s0.acc: 99.0814, s0.loss_bbox: 0.0181, s1.loss_cls: 0.0157, s1.acc: 98.7518, s1.loss_bbox: 0.0313, s2.loss_cls: 0.0110, s2.acc: 98.2086, s2.loss_bbox: 0.0254, loss: 0.1324, grad_norm: 4.0890\n",
            "2020-09-07 18:38:30,754 - mmdet - INFO - Epoch [15][2880/5332]\tlr: 1.000e-05, eta: 14:57:54, time: 1.851, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0054, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0214, s0.acc: 99.1211, s0.loss_bbox: 0.0165, s1.loss_cls: 0.0137, s1.acc: 98.9410, s1.loss_bbox: 0.0274, s2.loss_cls: 0.0096, s2.acc: 98.3948, s2.loss_bbox: 0.0220, loss: 0.1215, grad_norm: 4.2588\n",
            "2020-09-07 18:40:29,611 - mmdet - INFO - Epoch [15][2944/5332]\tlr: 1.000e-05, eta: 14:55:57, time: 1.857, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0210, s0.acc: 99.2096, s0.loss_bbox: 0.0149, s1.loss_cls: 0.0137, s1.acc: 98.9227, s1.loss_bbox: 0.0255, s2.loss_cls: 0.0099, s2.acc: 98.3643, s2.loss_bbox: 0.0219, loss: 0.1158, grad_norm: 4.1389\n",
            "2020-09-07 18:42:30,100 - mmdet - INFO - Epoch [15][3008/5332]\tlr: 1.000e-05, eta: 14:54:05, time: 1.883, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0211, s0.acc: 99.1699, s0.loss_bbox: 0.0137, s1.loss_cls: 0.0127, s1.acc: 99.0143, s1.loss_bbox: 0.0230, s2.loss_cls: 0.0086, s2.acc: 98.7000, s2.loss_bbox: 0.0185, loss: 0.1047, grad_norm: 3.6576\n",
            "2020-09-07 18:44:29,739 - mmdet - INFO - Epoch [15][3072/5332]\tlr: 1.000e-05, eta: 14:52:11, time: 1.869, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0205, s0.acc: 99.1516, s0.loss_bbox: 0.0150, s1.loss_cls: 0.0123, s1.acc: 99.0143, s1.loss_bbox: 0.0292, s2.loss_cls: 0.0083, s2.acc: 98.6816, s2.loss_bbox: 0.0257, loss: 0.1191, grad_norm: 4.2918\n",
            "2020-09-07 18:46:27,677 - mmdet - INFO - Epoch [15][3136/5332]\tlr: 1.000e-05, eta: 14:50:11, time: 1.843, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0204, s0.acc: 99.1394, s0.loss_bbox: 0.0140, s1.loss_cls: 0.0129, s1.acc: 99.0234, s1.loss_bbox: 0.0251, s2.loss_cls: 0.0084, s2.acc: 98.6694, s2.loss_bbox: 0.0251, loss: 0.1113, grad_norm: 4.1081\n",
            "2020-09-07 18:48:25,364 - mmdet - INFO - Epoch [15][3200/5332]\tlr: 1.000e-05, eta: 14:48:10, time: 1.839, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0203, s0.acc: 99.1760, s0.loss_bbox: 0.0158, s1.loss_cls: 0.0138, s1.acc: 98.8770, s1.loss_bbox: 0.0229, s2.loss_cls: 0.0096, s2.acc: 98.3215, s2.loss_bbox: 0.0198, loss: 0.1100, grad_norm: 3.8237\n",
            "2020-09-07 18:50:25,423 - mmdet - INFO - Epoch [15][3264/5332]\tlr: 1.000e-05, eta: 14:46:16, time: 1.876, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0250, s0.acc: 99.0814, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0138, s1.acc: 98.8953, s1.loss_bbox: 0.0290, s2.loss_cls: 0.0092, s2.acc: 98.5718, s2.loss_bbox: 0.0233, loss: 0.1282, grad_norm: 4.2802\n",
            "2020-09-07 18:52:23,532 - mmdet - INFO - Epoch [15][3328/5332]\tlr: 1.000e-05, eta: 14:44:17, time: 1.845, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0213, s0.acc: 99.2645, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0137, s1.acc: 99.0509, s1.loss_bbox: 0.0268, s2.loss_cls: 0.0091, s2.acc: 98.6053, s2.loss_bbox: 0.0231, loss: 0.1169, grad_norm: 4.1772\n",
            "2020-09-07 18:54:22,140 - mmdet - INFO - Epoch [15][3392/5332]\tlr: 1.000e-05, eta: 14:42:19, time: 1.853, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0105, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0284, s0.acc: 98.9105, s0.loss_bbox: 0.0198, s1.loss_cls: 0.0188, s1.acc: 98.4192, s1.loss_bbox: 0.0272, s2.loss_cls: 0.0115, s2.acc: 97.9431, s2.loss_bbox: 0.0203, loss: 0.1422, grad_norm: 4.5022\n",
            "2020-09-07 18:56:20,330 - mmdet - INFO - Epoch [15][3456/5332]\tlr: 1.000e-05, eta: 14:40:19, time: 1.847, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0223, s0.acc: 99.0540, s0.loss_bbox: 0.0171, s1.loss_cls: 0.0150, s1.acc: 98.8251, s1.loss_bbox: 0.0253, s2.loss_cls: 0.0097, s2.acc: 98.3185, s2.loss_bbox: 0.0185, loss: 0.1166, grad_norm: 3.9349\n",
            "2020-09-07 18:58:18,137 - mmdet - INFO - Epoch [15][3520/5332]\tlr: 1.000e-05, eta: 14:38:19, time: 1.841, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0206, s0.acc: 99.1913, s0.loss_bbox: 0.0131, s1.loss_cls: 0.0132, s1.acc: 98.9624, s1.loss_bbox: 0.0239, s2.loss_cls: 0.0077, s2.acc: 98.8007, s2.loss_bbox: 0.0240, loss: 0.1076, grad_norm: 4.1276\n",
            "2020-09-07 19:00:16,102 - mmdet - INFO - Epoch [15][3584/5332]\tlr: 1.000e-05, eta: 14:36:19, time: 1.843, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0058, loss_rpn_bbox: 0.0067, s0.loss_cls: 0.0331, s0.acc: 98.7701, s0.loss_bbox: 0.0227, s1.loss_cls: 0.0202, s1.acc: 98.4192, s1.loss_bbox: 0.0337, s2.loss_cls: 0.0125, s2.acc: 97.7875, s2.loss_bbox: 0.0262, loss: 0.1607, grad_norm: 5.6532\n",
            "2020-09-07 19:02:14,525 - mmdet - INFO - Epoch [15][3648/5332]\tlr: 1.000e-05, eta: 14:34:20, time: 1.850, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0070, s0.loss_cls: 0.0271, s0.acc: 99.0021, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0203, s1.acc: 98.5138, s1.loss_bbox: 0.0288, s2.loss_cls: 0.0123, s2.acc: 98.1140, s2.loss_bbox: 0.0248, loss: 0.1402, grad_norm: 4.9804\n",
            "2020-09-07 19:04:11,639 - mmdet - INFO - Epoch [15][3712/5332]\tlr: 1.000e-05, eta: 14:32:18, time: 1.830, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0067, s0.loss_cls: 0.0224, s0.acc: 99.1699, s0.loss_bbox: 0.0153, s1.loss_cls: 0.0153, s1.acc: 98.8281, s1.loss_bbox: 0.0282, s2.loss_cls: 0.0096, s2.acc: 98.5016, s2.loss_bbox: 0.0240, loss: 0.1244, grad_norm: 4.0057\n",
            "2020-09-07 19:06:08,825 - mmdet - INFO - Epoch [15][3776/5332]\tlr: 1.000e-05, eta: 14:30:15, time: 1.831, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0198, s0.acc: 99.2340, s0.loss_bbox: 0.0146, s1.loss_cls: 0.0142, s1.acc: 98.6969, s1.loss_bbox: 0.0279, s2.loss_cls: 0.0087, s2.acc: 98.6786, s2.loss_bbox: 0.0222, loss: 0.1133, grad_norm: 3.9462\n",
            "2020-09-07 19:08:06,572 - mmdet - INFO - Epoch [15][3840/5332]\tlr: 1.000e-05, eta: 14:28:15, time: 1.840, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0208, s0.acc: 99.1333, s0.loss_bbox: 0.0145, s1.loss_cls: 0.0128, s1.acc: 98.9960, s1.loss_bbox: 0.0262, s2.loss_cls: 0.0083, s2.acc: 98.7305, s2.loss_bbox: 0.0214, loss: 0.1113, grad_norm: 3.7509\n",
            "2020-09-07 19:10:05,746 - mmdet - INFO - Epoch [15][3904/5332]\tlr: 1.000e-05, eta: 14:26:19, time: 1.862, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0219, s0.acc: 99.1119, s0.loss_bbox: 0.0134, s1.loss_cls: 0.0137, s1.acc: 98.8953, s1.loss_bbox: 0.0212, s2.loss_cls: 0.0082, s2.acc: 98.7854, s2.loss_bbox: 0.0184, loss: 0.1032, grad_norm: 4.2007\n",
            "2020-09-07 19:12:03,534 - mmdet - INFO - Epoch [15][3968/5332]\tlr: 1.000e-05, eta: 14:24:18, time: 1.840, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0100, s0.loss_cls: 0.0298, s0.acc: 98.8251, s0.loss_bbox: 0.0203, s1.loss_cls: 0.0177, s1.acc: 98.5840, s1.loss_bbox: 0.0285, s2.loss_cls: 0.0110, s2.acc: 98.3398, s2.loss_bbox: 0.0216, loss: 0.1437, grad_norm: 4.8412\n",
            "2020-09-07 19:14:02,853 - mmdet - INFO - Epoch [15][4032/5332]\tlr: 1.000e-05, eta: 14:22:22, time: 1.864, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0209, s0.acc: 99.1943, s0.loss_bbox: 0.0154, s1.loss_cls: 0.0134, s1.acc: 98.9349, s1.loss_bbox: 0.0259, s2.loss_cls: 0.0095, s2.acc: 98.4131, s2.loss_bbox: 0.0223, loss: 0.1155, grad_norm: 3.8177\n",
            "2020-09-07 19:16:01,030 - mmdet - INFO - Epoch [15][4096/5332]\tlr: 1.000e-05, eta: 14:20:23, time: 1.847, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0231, s0.acc: 99.0875, s0.loss_bbox: 0.0180, s1.loss_cls: 0.0147, s1.acc: 98.8800, s1.loss_bbox: 0.0253, s2.loss_cls: 0.0091, s2.acc: 98.6023, s2.loss_bbox: 0.0228, loss: 0.1206, grad_norm: 4.5567\n",
            "2020-09-07 19:17:59,817 - mmdet - INFO - Epoch [15][4160/5332]\tlr: 1.000e-05, eta: 14:18:26, time: 1.856, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0215, s0.acc: 99.0936, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0144, s1.acc: 98.7457, s1.loss_bbox: 0.0278, s2.loss_cls: 0.0105, s2.acc: 98.1720, s2.loss_bbox: 0.0228, loss: 0.1187, grad_norm: 4.5402\n",
            "2020-09-07 19:19:58,242 - mmdet - INFO - Epoch [15][4224/5332]\tlr: 1.000e-05, eta: 14:16:27, time: 1.850, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0268, s0.acc: 99.0082, s0.loss_bbox: 0.0153, s1.loss_cls: 0.0186, s1.acc: 98.6481, s1.loss_bbox: 0.0326, s2.loss_cls: 0.0127, s2.acc: 97.9614, s2.loss_bbox: 0.0289, loss: 0.1441, grad_norm: 4.8434\n",
            "2020-09-07 19:21:56,858 - mmdet - INFO - Epoch [15][4288/5332]\tlr: 1.000e-05, eta: 14:14:29, time: 1.853, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0250, s0.acc: 98.9624, s0.loss_bbox: 0.0187, s1.loss_cls: 0.0170, s1.acc: 98.7152, s1.loss_bbox: 0.0333, s2.loss_cls: 0.0116, s2.acc: 98.0469, s2.loss_bbox: 0.0263, loss: 0.1389, grad_norm: 4.5363\n",
            "2020-09-07 19:23:55,183 - mmdet - INFO - Epoch [15][4352/5332]\tlr: 1.000e-05, eta: 14:12:31, time: 1.849, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0218, s0.acc: 99.1119, s0.loss_bbox: 0.0187, s1.loss_cls: 0.0147, s1.acc: 98.8373, s1.loss_bbox: 0.0292, s2.loss_cls: 0.0097, s2.acc: 98.4497, s2.loss_bbox: 0.0221, loss: 0.1251, grad_norm: 4.2727\n",
            "2020-09-07 19:25:54,532 - mmdet - INFO - Epoch [15][4416/5332]\tlr: 1.000e-05, eta: 14:10:35, time: 1.865, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0253, s0.acc: 99.0417, s0.loss_bbox: 0.0166, s1.loss_cls: 0.0169, s1.acc: 98.6511, s1.loss_bbox: 0.0306, s2.loss_cls: 0.0100, s2.acc: 98.4100, s2.loss_bbox: 0.0224, loss: 0.1313, grad_norm: 4.7221\n",
            "2020-09-07 19:27:52,559 - mmdet - INFO - Epoch [15][4480/5332]\tlr: 1.000e-05, eta: 14:08:35, time: 1.844, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0314, s0.acc: 98.8983, s0.loss_bbox: 0.0199, s1.loss_cls: 0.0200, s1.acc: 98.6176, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0104, s2.acc: 98.4344, s2.loss_bbox: 0.0224, loss: 0.1425, grad_norm: 4.7656\n",
            "2020-09-07 19:29:50,454 - mmdet - INFO - Epoch [15][4544/5332]\tlr: 1.000e-05, eta: 14:06:35, time: 1.842, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0192, s0.acc: 99.2706, s0.loss_bbox: 0.0151, s1.loss_cls: 0.0131, s1.acc: 98.9624, s1.loss_bbox: 0.0258, s2.loss_cls: 0.0080, s2.acc: 98.7885, s2.loss_bbox: 0.0233, loss: 0.1132, grad_norm: 3.9481\n",
            "2020-09-07 19:31:48,341 - mmdet - INFO - Epoch [15][4608/5332]\tlr: 1.000e-05, eta: 14:04:35, time: 1.842, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0065, s0.loss_cls: 0.0320, s0.acc: 98.8678, s0.loss_bbox: 0.0198, s1.loss_cls: 0.0192, s1.acc: 98.6053, s1.loss_bbox: 0.0253, s2.loss_cls: 0.0117, s2.acc: 98.0927, s2.loss_bbox: 0.0187, loss: 0.1398, grad_norm: 4.4656\n",
            "2020-09-07 19:33:47,638 - mmdet - INFO - Epoch [15][4672/5332]\tlr: 1.000e-05, eta: 14:02:39, time: 1.864, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0214, s0.acc: 99.1608, s0.loss_bbox: 0.0135, s1.loss_cls: 0.0150, s1.acc: 98.8678, s1.loss_bbox: 0.0248, s2.loss_cls: 0.0100, s2.acc: 98.3246, s2.loss_bbox: 0.0243, loss: 0.1148, grad_norm: 4.2502\n",
            "2020-09-07 19:35:46,933 - mmdet - INFO - Epoch [15][4736/5332]\tlr: 1.000e-05, eta: 14:00:43, time: 1.864, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0272, s0.acc: 98.9075, s0.loss_bbox: 0.0154, s1.loss_cls: 0.0203, s1.acc: 98.4161, s1.loss_bbox: 0.0272, s2.loss_cls: 0.0129, s2.acc: 97.9004, s2.loss_bbox: 0.0222, loss: 0.1324, grad_norm: 4.7162\n",
            "2020-09-07 19:37:45,390 - mmdet - INFO - Epoch [15][4800/5332]\tlr: 1.000e-05, eta: 13:58:44, time: 1.851, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0211, s0.acc: 99.1516, s0.loss_bbox: 0.0160, s1.loss_cls: 0.0135, s1.acc: 98.8983, s1.loss_bbox: 0.0243, s2.loss_cls: 0.0088, s2.acc: 98.6603, s2.loss_bbox: 0.0230, loss: 0.1130, grad_norm: 4.1692\n",
            "2020-09-07 19:39:43,529 - mmdet - INFO - Epoch [15][4864/5332]\tlr: 1.000e-05, eta: 13:56:45, time: 1.846, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0261, s0.acc: 99.0479, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0168, s1.acc: 98.7152, s1.loss_bbox: 0.0300, s2.loss_cls: 0.0113, s2.acc: 98.2849, s2.loss_bbox: 0.0259, loss: 0.1362, grad_norm: 4.3155\n",
            "2020-09-07 19:41:42,311 - mmdet - INFO - Epoch [15][4928/5332]\tlr: 1.000e-05, eta: 13:54:48, time: 1.856, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0240, s0.acc: 99.0326, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0160, s1.acc: 98.7244, s1.loss_bbox: 0.0301, s2.loss_cls: 0.0091, s2.acc: 98.6206, s2.loss_bbox: 0.0253, loss: 0.1312, grad_norm: 4.9963\n",
            "2020-09-07 19:43:40,146 - mmdet - INFO - Epoch [15][4992/5332]\tlr: 1.000e-05, eta: 13:52:48, time: 1.841, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0254, s0.acc: 99.0234, s0.loss_bbox: 0.0180, s1.loss_cls: 0.0163, s1.acc: 98.8861, s1.loss_bbox: 0.0291, s2.loss_cls: 0.0109, s2.acc: 98.2941, s2.loss_bbox: 0.0260, loss: 0.1318, grad_norm: 4.1970\n",
            "2020-09-07 19:45:37,784 - mmdet - INFO - Epoch [15][5056/5332]\tlr: 1.000e-05, eta: 13:50:47, time: 1.838, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0227, s0.acc: 99.0326, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0138, s1.acc: 98.8312, s1.loss_bbox: 0.0290, s2.loss_cls: 0.0093, s2.acc: 98.4192, s2.loss_bbox: 0.0241, loss: 0.1239, grad_norm: 4.6328\n",
            "2020-09-07 19:47:36,585 - mmdet - INFO - Epoch [15][5120/5332]\tlr: 1.000e-05, eta: 13:48:50, time: 1.856, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0022, s0.loss_cls: 0.0195, s0.acc: 99.1974, s0.loss_bbox: 0.0147, s1.loss_cls: 0.0126, s1.acc: 99.0417, s1.loss_bbox: 0.0267, s2.loss_cls: 0.0082, s2.acc: 98.8678, s2.loss_bbox: 0.0214, loss: 0.1082, grad_norm: 4.2855\n",
            "2020-09-07 19:49:35,916 - mmdet - INFO - Epoch [15][5184/5332]\tlr: 1.000e-05, eta: 13:46:53, time: 1.865, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0248, s0.acc: 98.9685, s0.loss_bbox: 0.0174, s1.loss_cls: 0.0169, s1.acc: 98.6267, s1.loss_bbox: 0.0310, s2.loss_cls: 0.0125, s2.acc: 97.7997, s2.loss_bbox: 0.0254, loss: 0.1357, grad_norm: 4.3234\n",
            "2020-09-07 19:51:33,601 - mmdet - INFO - Epoch [15][5248/5332]\tlr: 1.000e-05, eta: 13:44:53, time: 1.839, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0249, s0.acc: 99.0356, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0165, s1.acc: 98.7183, s1.loss_bbox: 0.0291, s2.loss_cls: 0.0097, s2.acc: 98.4283, s2.loss_bbox: 0.0225, loss: 0.1292, grad_norm: 4.4839\n",
            "2020-09-07 19:53:30,683 - mmdet - INFO - Epoch [15][5312/5332]\tlr: 1.000e-05, eta: 13:42:51, time: 1.829, data_time: 0.004, memory: 8800, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0259, s0.acc: 98.9868, s0.loss_bbox: 0.0168, s1.loss_cls: 0.0172, s1.acc: 98.6542, s1.loss_bbox: 0.0280, s2.loss_cls: 0.0107, s2.acc: 98.3185, s2.loss_bbox: 0.0219, loss: 0.1309, grad_norm: 4.4352\n",
            "2020-09-07 19:54:07,260 - mmdet - INFO - Saving checkpoint at 15 epochs\n",
            "[>>] 667/667, 0.6 task/s, elapsed: 1068s, ETA:     0s2020-09-07 20:12:03,109 - mmdet - INFO - \n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 82  | 226  | 0.854  | 0.587 |\n",
            "| 3     | 22  | 97   | 0.773  | 0.646 |\n",
            "| 4     | 529 | 1155 | 0.921  | 0.827 |\n",
            "| 5     | 78  | 168  | 0.885  | 0.791 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.713 |\n",
            "+-------+-----+------+--------+-------+\n",
            "2020-09-07 20:12:03,113 - mmdet - INFO - Epoch(val) [15][5332]\tmAP: 0.7128\n",
            "Process Process-13:\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d6f08c0e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/local/lib/python3.7/threading.py\", line 1044, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/local/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y758raUv5JiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80c621d1-3518-42a0-85a6-590efa1e56a6"
      },
      "source": [
        "!python tools/train.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py --resume-from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_15.pth"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-08 04:08:08,742 - mmdet - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.7.6 (default, Jan  8 2020, 19:59:22) [GCC 7.3.0]\n",
            "CUDA available: True\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
            "GPU 0: Tesla T4\n",
            "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "PyTorch: 1.4.0\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CUDA Runtime 10.0\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.1\n",
            "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "TorchVision: 0.5.0\n",
            "OpenCV: 4.4.0\n",
            "MMCV: 1.1.2\n",
            "MMDetection: 2.3.0+\n",
            "MMDetection Compiler: GCC 7.5\n",
            "MMDetection CUDA Compiler: 10.1\n",
            "------------------------------------------------------------\n",
            "\n",
            "2020-09-08 04:08:09,432 - mmdet - INFO - Distributed training: False\n",
            "2020-09-08 04:08:10,134 - mmdet - INFO - Config:\n",
            "model = dict(\n",
            "    type='CascadeRCNN',\n",
            "    pretrained='open-mmlab://resnext101_32x4d',\n",
            "    backbone=dict(\n",
            "        type='DetectoRS_ResNeXt',\n",
            "        depth=101,\n",
            "        groups=32,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=True,\n",
            "        style='pytorch',\n",
            "        conv_cfg=dict(type='ConvAWS'),\n",
            "        sac=dict(type='SAC', use_deform=True),\n",
            "        stage_with_sac=(False, True, True, True),\n",
            "        output_img=True),\n",
            "    neck=dict(\n",
            "        type='RFP',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5,\n",
            "        rfp_steps=2,\n",
            "        aspp_out_channels=64,\n",
            "        aspp_dilations=(1, 3, 6, 1),\n",
            "        rfp_backbone=dict(\n",
            "            rfp_inplanes=256,\n",
            "            type='DetectoRS_ResNeXt',\n",
            "            depth=101,\n",
            "            num_stages=4,\n",
            "            out_indices=(0, 1, 2, 3),\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(type='BN', requires_grad=True),\n",
            "            norm_eval=True,\n",
            "            conv_cfg=dict(type='ConvAWS'),\n",
            "            sac=dict(type='SAC', use_deform=True),\n",
            "            stage_with_sac=(False, True, True, True),\n",
            "            pretrained='open-mmlab://resnext101_32x4d',\n",
            "            style='pytorch')),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(\n",
            "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='CascadeRoIHead',\n",
            "        num_stages=3,\n",
            "        stage_loss_weights=[1, 0.5, 0.25],\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='GenericRoIExtractor',\n",
            "            aggregation='sum',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32],\n",
            "            pre_cfg=dict(\n",
            "                type='ConvModule',\n",
            "                in_channels=256,\n",
            "                out_channels=256,\n",
            "                kernel_size=5,\n",
            "                padding=2,\n",
            "                inplace=False),\n",
            "            post_cfg=dict(\n",
            "                type='GeneralizedAttention',\n",
            "                in_channels=256,\n",
            "                spatial_range=-1,\n",
            "                num_heads=6,\n",
            "                attention_type='0100',\n",
            "                kv_stride=2)),\n",
            "        bbox_head=[\n",
            "            dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=10,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
            "                               loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=10,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
            "                               loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=10,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
            "        ]))\n",
            "train_cfg = dict(\n",
            "    rpn=dict(\n",
            "        assigner=dict(\n",
            "            type='MaxIoUAssigner',\n",
            "            pos_iou_thr=0.7,\n",
            "            neg_iou_thr=0.3,\n",
            "            min_pos_iou=0.3,\n",
            "            match_low_quality=True,\n",
            "            ignore_iof_thr=-1),\n",
            "        sampler=dict(\n",
            "            type='RandomSampler',\n",
            "            num=256,\n",
            "            pos_fraction=0.5,\n",
            "            neg_pos_ub=-1,\n",
            "            add_gt_as_proposals=False),\n",
            "        allowed_border=0,\n",
            "        pos_weight=-1,\n",
            "        debug=False),\n",
            "    rpn_proposal=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=2000,\n",
            "        nms_post=2000,\n",
            "        max_num=2000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=[\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.6,\n",
            "                neg_iou_thr=0.6,\n",
            "                min_pos_iou=0.6,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.7,\n",
            "                min_pos_iou=0.7,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)\n",
            "    ])\n",
            "test_cfg = dict(\n",
            "    rpn=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=1000,\n",
            "        nms_post=1000,\n",
            "        max_num=1000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=dict(\n",
            "        score_thr=0.05,\n",
            "        nms=dict(type='nms', iou_threshold=0.5),\n",
            "        max_per_img=100))\n",
            "dataset_type = 'CustomDataset'\n",
            "data_root = 'data/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "albu_train_transforms = [\n",
            "    dict(\n",
            "        type='ShiftScaleRotate',\n",
            "        shift_limit=0.0625,\n",
            "        scale_limit=0.0,\n",
            "        rotate_limit=0,\n",
            "        interpolation=1,\n",
            "        p=0.5),\n",
            "    dict(\n",
            "        type='RandomBrightnessContrast',\n",
            "        brightness_limit=[0.1, 0.3],\n",
            "        contrast_limit=[0.1, 0.3],\n",
            "        p=0.2),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='RGBShift',\n",
            "                r_shift_limit=10,\n",
            "                g_shift_limit=10,\n",
            "                b_shift_limit=10,\n",
            "                p=1.0),\n",
            "            dict(\n",
            "                type='HueSaturationValue',\n",
            "                hue_shift_limit=20,\n",
            "                sat_shift_limit=30,\n",
            "                val_shift_limit=20,\n",
            "                p=1.0)\n",
            "        ],\n",
            "        p=0.1),\n",
            "    dict(type='JpegCompression', quality_lower=85, quality_upper=95, p=0.2),\n",
            "    dict(type='ChannelShuffle', p=0.1),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "        ],\n",
            "        p=0.1)\n",
            "]\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "    dict(\n",
            "        type='Resize',\n",
            "        multiscale_mode='range',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        keep_ratio=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(\n",
            "        type='Albu',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='ShiftScaleRotate',\n",
            "                shift_limit=0.0625,\n",
            "                scale_limit=0.0,\n",
            "                rotate_limit=0,\n",
            "                interpolation=1,\n",
            "                p=0.5),\n",
            "            dict(\n",
            "                type='RandomBrightnessContrast',\n",
            "                brightness_limit=[0.1, 0.3],\n",
            "                contrast_limit=[0.1, 0.3],\n",
            "                p=0.2),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='RGBShift',\n",
            "                        r_shift_limit=10,\n",
            "                        g_shift_limit=10,\n",
            "                        b_shift_limit=10,\n",
            "                        p=1.0),\n",
            "                    dict(\n",
            "                        type='HueSaturationValue',\n",
            "                        hue_shift_limit=20,\n",
            "                        sat_shift_limit=30,\n",
            "                        val_shift_limit=20,\n",
            "                        p=1.0)\n",
            "                ],\n",
            "                p=0.1),\n",
            "            dict(\n",
            "                type='JpegCompression',\n",
            "                quality_lower=85,\n",
            "                quality_upper=95,\n",
            "                p=0.2),\n",
            "            dict(type='ChannelShuffle', p=0.1),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                    dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                ],\n",
            "                p=0.1)\n",
            "        ],\n",
            "        bbox_params=dict(\n",
            "            type='BboxParams',\n",
            "            format='pascal_voc',\n",
            "            label_fields=['gt_labels'],\n",
            "            min_visibility=0.0,\n",
            "            filter_lost_elements=True),\n",
            "        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "        update_pad_shape=False,\n",
            "        skip_img_without_anno=True),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(\n",
            "        type='Collect',\n",
            "        keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "        meta_keys=('filename', 'ori_shape', 'img_shape', 'img_norm_cfg',\n",
            "                   'pad_shape', 'scale_factor'))\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        transforms=[\n",
            "            dict(type='Resize', multiscale_mode='range', keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=1.0),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=1,\n",
            "    workers_per_gpu=1,\n",
            "    train=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/train_80_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                type='Resize',\n",
            "                multiscale_mode='range',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                keep_ratio=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(\n",
            "                type='Albu',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='ShiftScaleRotate',\n",
            "                        shift_limit=0.0625,\n",
            "                        scale_limit=0.0,\n",
            "                        rotate_limit=0,\n",
            "                        interpolation=1,\n",
            "                        p=0.5),\n",
            "                    dict(\n",
            "                        type='RandomBrightnessContrast',\n",
            "                        brightness_limit=[0.1, 0.3],\n",
            "                        contrast_limit=[0.1, 0.3],\n",
            "                        p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(\n",
            "                                type='RGBShift',\n",
            "                                r_shift_limit=10,\n",
            "                                g_shift_limit=10,\n",
            "                                b_shift_limit=10,\n",
            "                                p=1.0),\n",
            "                            dict(\n",
            "                                type='HueSaturationValue',\n",
            "                                hue_shift_limit=20,\n",
            "                                sat_shift_limit=30,\n",
            "                                val_shift_limit=20,\n",
            "                                p=1.0)\n",
            "                        ],\n",
            "                        p=0.1),\n",
            "                    dict(\n",
            "                        type='JpegCompression',\n",
            "                        quality_lower=75,\n",
            "                        quality_upper=95,\n",
            "                        p=0.2),\n",
            "                    dict(type='ChannelShuffle', p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                        ],\n",
            "                        p=0.1)\n",
            "                ],\n",
            "                bbox_params=dict(\n",
            "                    type='BboxParams',\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=['gt_labels'],\n",
            "                    min_visibility=0.0,\n",
            "                    filter_lost_elements=True),\n",
            "                keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "                update_pad_shape=False,\n",
            "                skip_img_without_anno=True),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(\n",
            "                type='Collect',\n",
            "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "                meta_keys=('filename', 'ori_shape', 'img_shape',\n",
            "                           'img_norm_cfg', 'pad_shape', 'scale_factor'))\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/val_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/test_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 200), (1999, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "evaluation = dict(interval=1, metric='mAP')\n",
            "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.3333333333333333,\n",
            "    step=[8, 11])\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=64, hooks=[dict(type='TextLoggerHook')])\n",
            "total_epochs = 20\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "work_dir = './work_dirs/cascade_rcnn_x101_32x4d_fpn_1x'\n",
            "load_from = None\n",
            "resume_from = 'work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_15.pth'\n",
            "workflow = [('train', 1)]\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "2020-09-08 04:08:14,022 - mmdet - INFO - load model from: open-mmlab://resnext101_32x4d\n",
            "Downloading: \"https://openmmlab.oss-accelerate.aliyuncs.com/pretrain/third_party/resnext101_32x4d-a5af3160.pth\" to /root/.cache/torch/checkpoints/resnext101_32x4d-a5af3160.pth\n",
            "100% 161M/161M [00:12<00:00, 13.5MB/s]\n",
            "2020-09-08 04:08:27,736 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "2020-09-08 04:08:28,274 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
            "size mismatch for layer1.0.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.1.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.2.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.2.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
            "size mismatch for layer2.0.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.0.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.1.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.1.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.2.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.2.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.2.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.3.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.3.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.3.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
            "size mismatch for layer3.0.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.0.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.1.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.2.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.2.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.2.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.3.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.3.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.3.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.4.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.4.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.4.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.5.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.5.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.5.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.6.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.6.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.6.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.7.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.7.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.7.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.8.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.8.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.8.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.9.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.9.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.9.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.10.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.10.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.10.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.11.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.11.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.11.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.12.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.12.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.12.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.13.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.13.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.13.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.14.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.14.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.14.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.15.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.15.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.15.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.16.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.16.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.16.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.17.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.17.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.17.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.18.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.18.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.18.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.19.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.19.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.19.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.20.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.20.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.20.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.21.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.21.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.21.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.22.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.22.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.22.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
            "size mismatch for layer4.0.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.0.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.1.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.1.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.2.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.2.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.2.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-08 04:08:35,355 - mmdet - INFO - load checkpoint from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_15.pth\n",
            "2020-09-08 04:08:47,797 - mmdet - INFO - resumed epoch 15, iter 79980\n",
            "2020-09-08 04:08:47,805 - mmdet - INFO - Start running, host: root@d03a4ec79aa6, work_dir: /content/drive/My Drive/mmdetection-master/work_dirs/cascade_rcnn_x101_32x4d_fpn_1x\n",
            "2020-09-08 04:08:47,806 - mmdet - INFO - workflow: [('train', 1)], max: 20 epochs\n",
            "2020-09-08 04:11:01,362 - mmdet - INFO - Epoch [16][64/5332]\tlr: 1.000e-05, eta: 15:24:51, time: 2.086, data_time: 0.070, memory: 7809, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0268, s0.acc: 98.9807, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0186, s1.acc: 98.7488, s1.loss_bbox: 0.0289, s2.loss_cls: 0.0120, s2.acc: 98.2147, s2.loss_bbox: 0.0243, loss: 0.1368, grad_norm: 4.3264\n",
            "2020-09-08 04:13:13,148 - mmdet - INFO - Epoch [16][128/5332]\tlr: 1.000e-05, eta: 15:16:36, time: 2.059, data_time: 0.005, memory: 7809, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0228, s0.acc: 99.0265, s0.loss_bbox: 0.0159, s1.loss_cls: 0.0130, s1.acc: 98.9624, s1.loss_bbox: 0.0264, s2.loss_cls: 0.0081, s2.acc: 98.8617, s2.loss_bbox: 0.0219, loss: 0.1162, grad_norm: 3.9294\n",
            "2020-09-08 04:15:24,829 - mmdet - INFO - Epoch [16][192/5332]\tlr: 1.000e-05, eta: 15:12:08, time: 2.058, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0263, s0.acc: 98.9014, s0.loss_bbox: 0.0187, s1.loss_cls: 0.0183, s1.acc: 98.5321, s1.loss_bbox: 0.0280, s2.loss_cls: 0.0109, s2.acc: 98.0896, s2.loss_bbox: 0.0225, loss: 0.1334, grad_norm: 4.6996\n",
            "2020-09-08 04:17:38,097 - mmdet - INFO - Epoch [16][256/5332]\tlr: 1.000e-05, eta: 15:11:32, time: 2.082, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0251, s0.acc: 98.9807, s0.loss_bbox: 0.0174, s1.loss_cls: 0.0168, s1.acc: 98.5260, s1.loss_bbox: 0.0258, s2.loss_cls: 0.0108, s2.acc: 98.1720, s2.loss_bbox: 0.0209, loss: 0.1245, grad_norm: 4.1795\n",
            "2020-09-08 04:19:51,901 - mmdet - INFO - Epoch [16][320/5332]\tlr: 1.000e-05, eta: 15:11:01, time: 2.091, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0028, s0.loss_cls: 0.0212, s0.acc: 99.1455, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0123, s1.acc: 99.0143, s1.loss_bbox: 0.0296, s2.loss_cls: 0.0078, s2.acc: 98.7335, s2.loss_bbox: 0.0277, loss: 0.1215, grad_norm: 4.1735\n",
            "2020-09-08 04:22:05,843 - mmdet - INFO - Epoch [16][384/5332]\tlr: 1.000e-05, eta: 15:10:05, time: 2.093, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0222, s0.acc: 99.1272, s0.loss_bbox: 0.0148, s1.loss_cls: 0.0152, s1.acc: 98.7640, s1.loss_bbox: 0.0267, s2.loss_cls: 0.0105, s2.acc: 98.3490, s2.loss_bbox: 0.0233, loss: 0.1190, grad_norm: 4.3674\n",
            "2020-09-08 04:24:17,092 - mmdet - INFO - Epoch [16][448/5332]\tlr: 1.000e-05, eta: 15:06:10, time: 2.051, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0231, s0.acc: 99.0814, s0.loss_bbox: 0.0197, s1.loss_cls: 0.0158, s1.acc: 98.7152, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0110, s2.acc: 98.1323, s2.loss_bbox: 0.0213, loss: 0.1290, grad_norm: 4.1518\n",
            "2020-09-08 04:26:29,463 - mmdet - INFO - Epoch [16][512/5332]\tlr: 1.000e-05, eta: 15:03:37, time: 2.068, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0286, s0.acc: 98.9960, s0.loss_bbox: 0.0202, s1.loss_cls: 0.0182, s1.acc: 98.7274, s1.loss_bbox: 0.0377, s2.loss_cls: 0.0133, s2.acc: 98.1506, s2.loss_bbox: 0.0310, loss: 0.1573, grad_norm: 5.0228\n",
            "2020-09-08 04:28:43,331 - mmdet - INFO - Epoch [16][576/5332]\tlr: 1.000e-05, eta: 15:02:17, time: 2.092, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0074, s0.loss_cls: 0.0215, s0.acc: 99.1180, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0145, s1.acc: 98.8403, s1.loss_bbox: 0.0336, s2.loss_cls: 0.0115, s2.acc: 98.0835, s2.loss_bbox: 0.0213, loss: 0.1304, grad_norm: 4.4928\n",
            "2020-09-08 04:30:54,455 - mmdet - INFO - Epoch [16][640/5332]\tlr: 1.000e-05, eta: 14:58:55, time: 2.049, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0241, s0.acc: 99.0692, s0.loss_bbox: 0.0171, s1.loss_cls: 0.0154, s1.acc: 98.7885, s1.loss_bbox: 0.0257, s2.loss_cls: 0.0094, s2.acc: 98.6389, s2.loss_bbox: 0.0194, loss: 0.1168, grad_norm: 4.1235\n",
            "2020-09-08 04:33:05,862 - mmdet - INFO - Epoch [16][704/5332]\tlr: 1.000e-05, eta: 14:55:56, time: 2.053, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0210, s0.acc: 99.2249, s0.loss_bbox: 0.0121, s1.loss_cls: 0.0149, s1.acc: 98.8464, s1.loss_bbox: 0.0192, s2.loss_cls: 0.0105, s2.acc: 98.4467, s2.loss_bbox: 0.0178, loss: 0.1021, grad_norm: 3.8068\n",
            "2020-09-08 04:35:17,060 - mmdet - INFO - Epoch [16][768/5332]\tlr: 1.000e-05, eta: 14:52:58, time: 2.050, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0268, s0.acc: 98.8678, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0166, s1.acc: 98.6511, s1.loss_bbox: 0.0318, s2.loss_cls: 0.0099, s2.acc: 98.2208, s2.loss_bbox: 0.0255, loss: 0.1358, grad_norm: 4.4044\n",
            "2020-09-08 04:37:27,361 - mmdet - INFO - Epoch [16][832/5332]\tlr: 1.000e-05, eta: 14:49:39, time: 2.036, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0224, s0.acc: 99.0631, s0.loss_bbox: 0.0152, s1.loss_cls: 0.0159, s1.acc: 98.7183, s1.loss_bbox: 0.0267, s2.loss_cls: 0.0099, s2.acc: 98.5596, s2.loss_bbox: 0.0215, loss: 0.1195, grad_norm: 4.2889\n",
            "2020-09-08 04:39:38,518 - mmdet - INFO - Epoch [16][896/5332]\tlr: 1.000e-05, eta: 14:46:55, time: 2.049, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0247, s0.acc: 98.9716, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0163, s1.acc: 98.6328, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0100, s2.acc: 98.3398, s2.loss_bbox: 0.0250, loss: 0.1307, grad_norm: 5.0395\n",
            "2020-09-08 04:41:51,053 - mmdet - INFO - Epoch [16][960/5332]\tlr: 1.000e-05, eta: 14:44:52, time: 2.071, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0249, s0.acc: 98.9777, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0163, s1.acc: 98.7030, s1.loss_bbox: 0.0279, s2.loss_cls: 0.0102, s2.acc: 98.4772, s2.loss_bbox: 0.0223, loss: 0.1270, grad_norm: 4.9406\n",
            "2020-09-08 04:44:03,060 - mmdet - INFO - Epoch [16][1024/5332]\tlr: 1.000e-05, eta: 14:42:35, time: 2.063, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0021, s0.loss_cls: 0.0165, s0.acc: 99.4141, s0.loss_bbox: 0.0117, s1.loss_cls: 0.0116, s1.acc: 99.1058, s1.loss_bbox: 0.0200, s2.loss_cls: 0.0079, s2.acc: 98.7610, s2.loss_bbox: 0.0176, loss: 0.0901, grad_norm: 3.3392\n",
            "2020-09-08 04:46:17,688 - mmdet - INFO - Epoch [16][1088/5332]\tlr: 1.000e-05, eta: 14:41:19, time: 2.104, data_time: 0.036, memory: 7880, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0209, s0.acc: 99.1516, s0.loss_bbox: 0.0141, s1.loss_cls: 0.0142, s1.acc: 98.9594, s1.loss_bbox: 0.0234, s2.loss_cls: 0.0091, s2.acc: 98.5779, s2.loss_bbox: 0.0218, loss: 0.1094, grad_norm: 4.0897\n",
            "2020-09-08 04:48:29,636 - mmdet - INFO - Epoch [16][1152/5332]\tlr: 1.000e-05, eta: 14:38:58, time: 2.062, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0285, s0.acc: 98.7976, s0.loss_bbox: 0.0216, s1.loss_cls: 0.0179, s1.acc: 98.4375, s1.loss_bbox: 0.0303, s2.loss_cls: 0.0106, s2.acc: 98.3215, s2.loss_bbox: 0.0228, loss: 0.1389, grad_norm: 4.6541\n",
            "2020-09-08 04:50:41,547 - mmdet - INFO - Epoch [16][1216/5332]\tlr: 1.000e-05, eta: 14:36:37, time: 2.061, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0246, s0.acc: 99.0204, s0.loss_bbox: 0.0206, s1.loss_cls: 0.0160, s1.acc: 98.7274, s1.loss_bbox: 0.0331, s2.loss_cls: 0.0105, s2.acc: 98.0225, s2.loss_bbox: 0.0276, loss: 0.1406, grad_norm: 5.0338\n",
            "2020-09-08 04:52:55,485 - mmdet - INFO - Epoch [16][1280/5332]\tlr: 1.000e-05, eta: 14:34:58, time: 2.093, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0279, s0.acc: 98.8495, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0197, s1.acc: 98.4314, s1.loss_bbox: 0.0333, s2.loss_cls: 0.0119, s2.acc: 98.1873, s2.loss_bbox: 0.0318, loss: 0.1513, grad_norm: 5.3940\n",
            "2020-09-08 04:55:06,822 - mmdet - INFO - Epoch [16][1344/5332]\tlr: 1.000e-05, eta: 14:32:25, time: 2.052, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0065, s0.loss_cls: 0.0245, s0.acc: 99.0112, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0147, s1.acc: 98.8159, s1.loss_bbox: 0.0289, s2.loss_cls: 0.0098, s2.acc: 98.3154, s2.loss_bbox: 0.0232, loss: 0.1314, grad_norm: 4.6551\n",
            "2020-09-08 04:57:17,680 - mmdet - INFO - Epoch [16][1408/5332]\tlr: 1.000e-05, eta: 14:29:47, time: 2.045, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0173, s0.acc: 99.3347, s0.loss_bbox: 0.0132, s1.loss_cls: 0.0105, s1.acc: 99.1302, s1.loss_bbox: 0.0255, s2.loss_cls: 0.0071, s2.acc: 98.8678, s2.loss_bbox: 0.0230, loss: 0.1037, grad_norm: 3.5173\n",
            "2020-09-08 04:59:29,829 - mmdet - INFO - Epoch [16][1472/5332]\tlr: 1.000e-05, eta: 14:27:32, time: 2.065, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0026, s0.loss_cls: 0.0236, s0.acc: 99.0692, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0154, s1.acc: 98.7488, s1.loss_bbox: 0.0296, s2.loss_cls: 0.0102, s2.acc: 98.4924, s2.loss_bbox: 0.0268, loss: 0.1299, grad_norm: 4.6257\n",
            "2020-09-08 05:01:40,594 - mmdet - INFO - Epoch [16][1536/5332]\tlr: 1.000e-05, eta: 14:24:56, time: 2.043, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0063, s0.loss_cls: 0.0244, s0.acc: 99.1119, s0.loss_bbox: 0.0192, s1.loss_cls: 0.0165, s1.acc: 98.7457, s1.loss_bbox: 0.0352, s2.loss_cls: 0.0111, s2.acc: 98.2117, s2.loss_bbox: 0.0322, loss: 0.1481, grad_norm: 4.7586\n",
            "2020-09-08 05:03:52,286 - mmdet - INFO - Epoch [16][1600/5332]\tlr: 1.000e-05, eta: 14:22:35, time: 2.058, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0068, s0.loss_cls: 0.0255, s0.acc: 99.0662, s0.loss_bbox: 0.0193, s1.loss_cls: 0.0149, s1.acc: 98.8129, s1.loss_bbox: 0.0261, s2.loss_cls: 0.0088, s2.acc: 98.5962, s2.loss_bbox: 0.0203, loss: 0.1250, grad_norm: 4.2126\n",
            "2020-09-08 05:06:03,961 - mmdet - INFO - Epoch [16][1664/5332]\tlr: 1.000e-05, eta: 14:20:16, time: 2.057, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0022, s0.loss_cls: 0.0205, s0.acc: 99.2706, s0.loss_bbox: 0.0144, s1.loss_cls: 0.0132, s1.acc: 99.0479, s1.loss_bbox: 0.0195, s2.loss_cls: 0.0084, s2.acc: 98.8068, s2.loss_bbox: 0.0188, loss: 0.0997, grad_norm: 3.9597\n",
            "2020-09-08 05:08:14,454 - mmdet - INFO - Epoch [16][1728/5332]\tlr: 1.000e-05, eta: 14:17:40, time: 2.039, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0081, s0.loss_cls: 0.0266, s0.acc: 98.9014, s0.loss_bbox: 0.0190, s1.loss_cls: 0.0185, s1.acc: 98.4009, s1.loss_bbox: 0.0322, s2.loss_cls: 0.0117, s2.acc: 97.8149, s2.loss_bbox: 0.0267, loss: 0.1473, grad_norm: 4.8660\n",
            "2020-09-08 05:10:25,908 - mmdet - INFO - Epoch [16][1792/5332]\tlr: 1.000e-05, eta: 14:15:18, time: 2.054, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0226, s0.acc: 99.1425, s0.loss_bbox: 0.0149, s1.loss_cls: 0.0153, s1.acc: 98.7762, s1.loss_bbox: 0.0239, s2.loss_cls: 0.0093, s2.acc: 98.4528, s2.loss_bbox: 0.0186, loss: 0.1138, grad_norm: 4.2076\n",
            "2020-09-08 05:12:38,912 - mmdet - INFO - Epoch [16][1856/5332]\tlr: 1.000e-05, eta: 14:13:19, time: 2.078, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0263, s0.acc: 99.0356, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0181, s1.acc: 98.5992, s1.loss_bbox: 0.0307, s2.loss_cls: 0.0133, s2.acc: 97.8851, s2.loss_bbox: 0.0234, loss: 0.1351, grad_norm: 4.3005\n",
            "2020-09-08 05:14:51,124 - mmdet - INFO - Epoch [16][1920/5332]\tlr: 1.000e-05, eta: 14:11:08, time: 2.066, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0265, s0.acc: 98.9929, s0.loss_bbox: 0.0194, s1.loss_cls: 0.0177, s1.acc: 98.5962, s1.loss_bbox: 0.0301, s2.loss_cls: 0.0119, s2.acc: 97.8760, s2.loss_bbox: 0.0241, loss: 0.1383, grad_norm: 4.6289\n",
            "2020-09-08 05:17:04,206 - mmdet - INFO - Epoch [16][1984/5332]\tlr: 1.000e-05, eta: 14:09:08, time: 2.079, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0253, s0.acc: 98.9136, s0.loss_bbox: 0.0165, s1.loss_cls: 0.0177, s1.acc: 98.6053, s1.loss_bbox: 0.0250, s2.loss_cls: 0.0112, s2.acc: 98.1903, s2.loss_bbox: 0.0204, loss: 0.1249, grad_norm: 4.2357\n",
            "2020-09-08 05:19:14,343 - mmdet - INFO - Epoch [16][2048/5332]\tlr: 1.000e-05, eta: 14:06:32, time: 2.033, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0068, s0.loss_cls: 0.0235, s0.acc: 99.0479, s0.loss_bbox: 0.0151, s1.loss_cls: 0.0148, s1.acc: 98.7427, s1.loss_bbox: 0.0283, s2.loss_cls: 0.0101, s2.acc: 98.3734, s2.loss_bbox: 0.0231, loss: 0.1251, grad_norm: 4.3207\n",
            "2020-09-08 05:21:26,632 - mmdet - INFO - Epoch [16][2112/5332]\tlr: 1.000e-05, eta: 14:04:22, time: 2.067, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0241, s0.acc: 99.0051, s0.loss_bbox: 0.0195, s1.loss_cls: 0.0146, s1.acc: 98.8617, s1.loss_bbox: 0.0299, s2.loss_cls: 0.0098, s2.acc: 98.4344, s2.loss_bbox: 0.0214, loss: 0.1252, grad_norm: 4.1553\n",
            "2020-09-08 05:23:37,954 - mmdet - INFO - Epoch [16][2176/5332]\tlr: 1.000e-05, eta: 14:02:02, time: 2.052, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0244, s0.acc: 99.0112, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0140, s1.acc: 98.8983, s1.loss_bbox: 0.0270, s2.loss_cls: 0.0084, s2.acc: 98.5107, s2.loss_bbox: 0.0207, loss: 0.1183, grad_norm: 3.9759\n",
            "2020-09-08 05:25:47,525 - mmdet - INFO - Epoch [16][2240/5332]\tlr: 1.000e-05, eta: 13:59:22, time: 2.025, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0246, s0.acc: 99.0601, s0.loss_bbox: 0.0185, s1.loss_cls: 0.0152, s1.acc: 98.7823, s1.loss_bbox: 0.0292, s2.loss_cls: 0.0095, s2.acc: 98.4802, s2.loss_bbox: 0.0273, loss: 0.1330, grad_norm: 4.4078\n",
            "2020-09-08 05:27:58,495 - mmdet - INFO - Epoch [16][2304/5332]\tlr: 1.000e-05, eta: 13:57:00, time: 2.046, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0250, s0.acc: 98.9716, s0.loss_bbox: 0.0190, s1.loss_cls: 0.0186, s1.acc: 98.5504, s1.loss_bbox: 0.0285, s2.loss_cls: 0.0115, s2.acc: 98.0957, s2.loss_bbox: 0.0206, loss: 0.1341, grad_norm: 4.5171\n",
            "2020-09-08 05:30:09,612 - mmdet - INFO - Epoch [16][2368/5332]\tlr: 1.000e-05, eta: 13:54:39, time: 2.049, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0229, s0.acc: 99.0784, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0159, s1.acc: 98.8068, s1.loss_bbox: 0.0276, s2.loss_cls: 0.0104, s2.acc: 98.3582, s2.loss_bbox: 0.0226, loss: 0.1222, grad_norm: 4.2581\n",
            "2020-09-08 05:32:22,423 - mmdet - INFO - Epoch [16][2432/5332]\tlr: 1.000e-05, eta: 13:52:36, time: 2.075, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0215, s0.acc: 99.1974, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0130, s1.acc: 99.0723, s1.loss_bbox: 0.0287, s2.loss_cls: 0.0070, s2.acc: 99.1150, s2.loss_bbox: 0.0236, loss: 0.1200, grad_norm: 4.3194\n",
            "2020-09-08 05:34:33,711 - mmdet - INFO - Epoch [16][2496/5332]\tlr: 1.000e-05, eta: 13:50:17, time: 2.051, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0215, s0.acc: 99.1241, s0.loss_bbox: 0.0154, s1.loss_cls: 0.0129, s1.acc: 98.9899, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0084, s2.acc: 98.6755, s2.loss_bbox: 0.0263, loss: 0.1212, grad_norm: 4.5039\n",
            "2020-09-08 05:36:46,210 - mmdet - INFO - Epoch [16][2560/5332]\tlr: 1.000e-05, eta: 13:48:10, time: 2.070, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0061, s0.loss_cls: 0.0244, s0.acc: 98.9655, s0.loss_bbox: 0.0215, s1.loss_cls: 0.0142, s1.acc: 98.8800, s1.loss_bbox: 0.0359, s2.loss_cls: 0.0095, s2.acc: 98.4985, s2.loss_bbox: 0.0262, loss: 0.1420, grad_norm: 4.4906\n",
            "2020-09-08 05:38:56,669 - mmdet - INFO - Epoch [16][2624/5332]\tlr: 1.000e-05, eta: 13:45:45, time: 2.038, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0250, s0.acc: 99.0784, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0169, s1.acc: 98.7061, s1.loss_bbox: 0.0297, s2.loss_cls: 0.0098, s2.acc: 98.2849, s2.loss_bbox: 0.0257, loss: 0.1331, grad_norm: 4.9728\n",
            "2020-09-08 05:41:10,083 - mmdet - INFO - Epoch [16][2688/5332]\tlr: 1.000e-05, eta: 13:43:46, time: 2.085, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0125, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0253, s0.acc: 98.9685, s0.loss_bbox: 0.0174, s1.loss_cls: 0.0148, s1.acc: 98.9014, s1.loss_bbox: 0.0284, s2.loss_cls: 0.0096, s2.acc: 98.4741, s2.loss_bbox: 0.0248, loss: 0.1370, grad_norm: 4.4305\n",
            "2020-09-08 05:43:20,534 - mmdet - INFO - Epoch [16][2752/5332]\tlr: 1.000e-05, eta: 13:41:21, time: 2.038, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0257, s0.acc: 98.9227, s0.loss_bbox: 0.0182, s1.loss_cls: 0.0162, s1.acc: 98.6389, s1.loss_bbox: 0.0313, s2.loss_cls: 0.0111, s2.acc: 98.2666, s2.loss_bbox: 0.0221, loss: 0.1335, grad_norm: 4.6342\n",
            "2020-09-08 05:45:34,534 - mmdet - INFO - Epoch [16][2816/5332]\tlr: 1.000e-05, eta: 13:39:27, time: 2.094, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0228, s0.acc: 99.1058, s0.loss_bbox: 0.0153, s1.loss_cls: 0.0149, s1.acc: 98.8037, s1.loss_bbox: 0.0231, s2.loss_cls: 0.0103, s2.acc: 98.2697, s2.loss_bbox: 0.0194, loss: 0.1141, grad_norm: 3.9040\n",
            "2020-09-08 05:47:44,468 - mmdet - INFO - Epoch [16][2880/5332]\tlr: 1.000e-05, eta: 13:36:58, time: 2.030, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0231, s0.acc: 99.1119, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0155, s1.acc: 98.7732, s1.loss_bbox: 0.0273, s2.loss_cls: 0.0101, s2.acc: 98.3948, s2.loss_bbox: 0.0250, loss: 0.1260, grad_norm: 4.5296\n",
            "2020-09-08 05:49:55,045 - mmdet - INFO - Epoch [16][2944/5332]\tlr: 1.000e-05, eta: 13:34:35, time: 2.040, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0241, s0.acc: 98.9838, s0.loss_bbox: 0.0171, s1.loss_cls: 0.0163, s1.acc: 98.5931, s1.loss_bbox: 0.0304, s2.loss_cls: 0.0116, s2.acc: 97.9553, s2.loss_bbox: 0.0246, loss: 0.1317, grad_norm: 4.7104\n",
            "2020-09-08 05:52:07,323 - mmdet - INFO - Epoch [16][3008/5332]\tlr: 1.000e-05, eta: 13:32:26, time: 2.067, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0213, s0.acc: 99.0814, s0.loss_bbox: 0.0148, s1.loss_cls: 0.0139, s1.acc: 98.9258, s1.loss_bbox: 0.0289, s2.loss_cls: 0.0087, s2.acc: 98.6237, s2.loss_bbox: 0.0284, loss: 0.1232, grad_norm: 4.4530\n",
            "2020-09-08 05:54:19,131 - mmdet - INFO - Epoch [16][3072/5332]\tlr: 1.000e-05, eta: 13:30:14, time: 2.060, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0219, s0.acc: 99.1699, s0.loss_bbox: 0.0166, s1.loss_cls: 0.0134, s1.acc: 98.9807, s1.loss_bbox: 0.0277, s2.loss_cls: 0.0091, s2.acc: 98.5321, s2.loss_bbox: 0.0222, loss: 0.1211, grad_norm: 3.8809\n",
            "2020-09-08 05:56:31,215 - mmdet - INFO - Epoch [16][3136/5332]\tlr: 1.000e-05, eta: 13:28:03, time: 2.064, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0257, s0.acc: 98.9044, s0.loss_bbox: 0.0173, s1.loss_cls: 0.0163, s1.acc: 98.4985, s1.loss_bbox: 0.0331, s2.loss_cls: 0.0107, s2.acc: 97.8912, s2.loss_bbox: 0.0262, loss: 0.1352, grad_norm: 4.6446\n",
            "2020-09-08 05:58:43,099 - mmdet - INFO - Epoch [16][3200/5332]\tlr: 1.000e-05, eta: 13:25:51, time: 2.061, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0247, s0.acc: 99.0753, s0.loss_bbox: 0.0188, s1.loss_cls: 0.0160, s1.acc: 98.7366, s1.loss_bbox: 0.0348, s2.loss_cls: 0.0112, s2.acc: 97.9919, s2.loss_bbox: 0.0294, loss: 0.1446, grad_norm: 4.8876\n",
            "2020-09-08 06:00:52,817 - mmdet - INFO - Epoch [16][3264/5332]\tlr: 1.000e-05, eta: 13:23:23, time: 2.027, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0073, s0.loss_cls: 0.0213, s0.acc: 99.1455, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0149, s1.acc: 98.8434, s1.loss_bbox: 0.0225, s2.loss_cls: 0.0090, s2.acc: 98.5870, s2.loss_bbox: 0.0203, loss: 0.1159, grad_norm: 4.1833\n",
            "2020-09-08 06:03:04,125 - mmdet - INFO - Epoch [16][3328/5332]\tlr: 1.000e-05, eta: 13:21:08, time: 2.052, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0241, s0.acc: 99.0204, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0165, s1.acc: 98.6023, s1.loss_bbox: 0.0305, s2.loss_cls: 0.0099, s2.acc: 98.2574, s2.loss_bbox: 0.0258, loss: 0.1295, grad_norm: 4.2845\n",
            "2020-09-08 06:05:14,647 - mmdet - INFO - Epoch [16][3392/5332]\tlr: 1.000e-05, eta: 13:18:47, time: 2.039, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0021, s0.loss_cls: 0.0177, s0.acc: 99.3622, s0.loss_bbox: 0.0117, s1.loss_cls: 0.0118, s1.acc: 99.1058, s1.loss_bbox: 0.0218, s2.loss_cls: 0.0069, s2.acc: 98.9105, s2.loss_bbox: 0.0186, loss: 0.0934, grad_norm: 3.8829\n",
            "2020-09-08 06:07:24,652 - mmdet - INFO - Epoch [16][3456/5332]\tlr: 1.000e-05, eta: 13:16:23, time: 2.031, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0254, s0.acc: 98.9349, s0.loss_bbox: 0.0181, s1.loss_cls: 0.0167, s1.acc: 98.6664, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0110, s2.acc: 98.0591, s2.loss_bbox: 0.0225, loss: 0.1309, grad_norm: 4.5617\n",
            "2020-09-08 06:09:36,565 - mmdet - INFO - Epoch [16][3520/5332]\tlr: 1.000e-05, eta: 13:14:12, time: 2.061, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0258, s0.acc: 98.9960, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0193, s1.acc: 98.3551, s1.loss_bbox: 0.0318, s2.loss_cls: 0.0124, s2.acc: 97.6746, s2.loss_bbox: 0.0277, loss: 0.1455, grad_norm: 4.8243\n",
            "2020-09-08 06:11:45,930 - mmdet - INFO - Epoch [16][3584/5332]\tlr: 1.000e-05, eta: 13:11:44, time: 2.021, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0246, s0.acc: 99.0479, s0.loss_bbox: 0.0165, s1.loss_cls: 0.0162, s1.acc: 98.7091, s1.loss_bbox: 0.0308, s2.loss_cls: 0.0118, s2.acc: 98.2361, s2.loss_bbox: 0.0253, loss: 0.1323, grad_norm: 4.9008\n",
            "2020-09-08 06:13:56,618 - mmdet - INFO - Epoch [16][3648/5332]\tlr: 1.000e-05, eta: 13:09:26, time: 2.042, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0273, s0.acc: 98.8617, s0.loss_bbox: 0.0201, s1.loss_cls: 0.0159, s1.acc: 98.7427, s1.loss_bbox: 0.0344, s2.loss_cls: 0.0102, s2.acc: 98.2941, s2.loss_bbox: 0.0268, loss: 0.1419, grad_norm: 4.6160\n",
            "2020-09-08 06:16:08,407 - mmdet - INFO - Epoch [16][3712/5332]\tlr: 1.000e-05, eta: 13:07:14, time: 2.059, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0061, s0.loss_cls: 0.0266, s0.acc: 98.8708, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0176, s1.acc: 98.5626, s1.loss_bbox: 0.0294, s2.loss_cls: 0.0105, s2.acc: 98.1049, s2.loss_bbox: 0.0268, loss: 0.1374, grad_norm: 4.6118\n",
            "2020-09-08 06:18:18,626 - mmdet - INFO - Epoch [16][3776/5332]\tlr: 1.000e-05, eta: 13:04:53, time: 2.035, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0233, s0.acc: 99.0845, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0143, s1.acc: 98.8678, s1.loss_bbox: 0.0305, s2.loss_cls: 0.0092, s2.acc: 98.5382, s2.loss_bbox: 0.0270, loss: 0.1309, grad_norm: 4.2715\n",
            "2020-09-08 06:20:30,943 - mmdet - INFO - Epoch [16][3840/5332]\tlr: 1.000e-05, eta: 13:02:45, time: 2.067, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0256, s0.acc: 98.9594, s0.loss_bbox: 0.0210, s1.loss_cls: 0.0184, s1.acc: 98.6267, s1.loss_bbox: 0.0301, s2.loss_cls: 0.0121, s2.acc: 98.0347, s2.loss_bbox: 0.0233, loss: 0.1379, grad_norm: 4.6488\n",
            "2020-09-08 06:22:42,548 - mmdet - INFO - Epoch [16][3904/5332]\tlr: 1.000e-05, eta: 13:00:33, time: 2.056, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0214, s0.acc: 99.1211, s0.loss_bbox: 0.0153, s1.loss_cls: 0.0135, s1.acc: 98.8770, s1.loss_bbox: 0.0317, s2.loss_cls: 0.0102, s2.acc: 98.3368, s2.loss_bbox: 0.0272, loss: 0.1259, grad_norm: 4.3910\n",
            "2020-09-08 06:24:54,245 - mmdet - INFO - Epoch [16][3968/5332]\tlr: 1.000e-05, eta: 12:58:21, time: 2.058, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0221, s0.acc: 99.1608, s0.loss_bbox: 0.0134, s1.loss_cls: 0.0153, s1.acc: 98.8068, s1.loss_bbox: 0.0254, s2.loss_cls: 0.0098, s2.acc: 98.3276, s2.loss_bbox: 0.0196, loss: 0.1148, grad_norm: 4.1148\n",
            "2020-09-08 06:27:04,821 - mmdet - INFO - Epoch [16][4032/5332]\tlr: 1.000e-05, eta: 12:56:03, time: 2.040, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0070, s0.loss_cls: 0.0223, s0.acc: 99.0692, s0.loss_bbox: 0.0180, s1.loss_cls: 0.0144, s1.acc: 98.8831, s1.loss_bbox: 0.0305, s2.loss_cls: 0.0092, s2.acc: 98.5657, s2.loss_bbox: 0.0261, loss: 0.1308, grad_norm: 4.5424\n",
            "2020-09-08 06:29:18,302 - mmdet - INFO - Epoch [16][4096/5332]\tlr: 1.000e-05, eta: 12:54:01, time: 2.086, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0201, s0.acc: 99.1852, s0.loss_bbox: 0.0138, s1.loss_cls: 0.0133, s1.acc: 98.9899, s1.loss_bbox: 0.0245, s2.loss_cls: 0.0087, s2.acc: 98.6816, s2.loss_bbox: 0.0233, loss: 0.1106, grad_norm: 4.3471\n",
            "2020-09-08 06:31:28,518 - mmdet - INFO - Epoch [16][4160/5332]\tlr: 1.000e-05, eta: 12:51:41, time: 2.035, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0235, s0.acc: 99.0417, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0159, s1.acc: 98.6725, s1.loss_bbox: 0.0275, s2.loss_cls: 0.0101, s2.acc: 98.2544, s2.loss_bbox: 0.0234, loss: 0.1216, grad_norm: 4.2485\n",
            "2020-09-08 06:33:38,490 - mmdet - INFO - Epoch [16][4224/5332]\tlr: 1.000e-05, eta: 12:49:20, time: 2.031, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0242, s0.acc: 99.0723, s0.loss_bbox: 0.0176, s1.loss_cls: 0.0154, s1.acc: 98.8190, s1.loss_bbox: 0.0278, s2.loss_cls: 0.0103, s2.acc: 98.1506, s2.loss_bbox: 0.0234, loss: 0.1259, grad_norm: 4.2798\n",
            "2020-09-08 06:35:48,397 - mmdet - INFO - Epoch [16][4288/5332]\tlr: 1.000e-05, eta: 12:46:59, time: 2.030, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0026, s0.loss_cls: 0.0262, s0.acc: 99.0570, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0173, s1.acc: 98.7122, s1.loss_bbox: 0.0250, s2.loss_cls: 0.0098, s2.acc: 98.4039, s2.loss_bbox: 0.0195, loss: 0.1196, grad_norm: 3.9064\n",
            "2020-09-08 06:37:59,297 - mmdet - INFO - Epoch [16][4352/5332]\tlr: 1.000e-05, eta: 12:44:44, time: 2.045, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0256, s0.acc: 98.9410, s0.loss_bbox: 0.0184, s1.loss_cls: 0.0170, s1.acc: 98.5931, s1.loss_bbox: 0.0305, s2.loss_cls: 0.0102, s2.acc: 98.2086, s2.loss_bbox: 0.0210, loss: 0.1328, grad_norm: 4.3789\n",
            "2020-09-08 06:40:11,211 - mmdet - INFO - Epoch [16][4416/5332]\tlr: 1.000e-05, eta: 12:42:34, time: 2.061, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0223, s0.acc: 99.1211, s0.loss_bbox: 0.0160, s1.loss_cls: 0.0149, s1.acc: 98.7579, s1.loss_bbox: 0.0281, s2.loss_cls: 0.0099, s2.acc: 98.2117, s2.loss_bbox: 0.0224, loss: 0.1235, grad_norm: 4.1213\n",
            "2020-09-08 06:42:20,061 - mmdet - INFO - Epoch [16][4480/5332]\tlr: 1.000e-05, eta: 12:40:08, time: 2.013, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0064, s0.loss_cls: 0.0288, s0.acc: 98.8617, s0.loss_bbox: 0.0201, s1.loss_cls: 0.0185, s1.acc: 98.6115, s1.loss_bbox: 0.0321, s2.loss_cls: 0.0118, s2.acc: 98.0377, s2.loss_bbox: 0.0230, loss: 0.1436, grad_norm: 4.8013\n",
            "2020-09-08 06:44:29,242 - mmdet - INFO - Epoch [16][4544/5332]\tlr: 1.000e-05, eta: 12:37:45, time: 2.018, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0179, s0.acc: 99.2889, s0.loss_bbox: 0.0133, s1.loss_cls: 0.0116, s1.acc: 99.1486, s1.loss_bbox: 0.0231, s2.loss_cls: 0.0076, s2.acc: 98.9105, s2.loss_bbox: 0.0203, loss: 0.1012, grad_norm: 3.8486\n",
            "2020-09-08 06:46:41,966 - mmdet - INFO - Epoch [16][4608/5332]\tlr: 1.000e-05, eta: 12:35:39, time: 2.074, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0250, s0.acc: 98.9502, s0.loss_bbox: 0.0193, s1.loss_cls: 0.0156, s1.acc: 98.6572, s1.loss_bbox: 0.0275, s2.loss_cls: 0.0105, s2.acc: 98.2544, s2.loss_bbox: 0.0233, loss: 0.1301, grad_norm: 4.5923\n",
            "2020-09-08 06:48:52,732 - mmdet - INFO - Epoch [16][4672/5332]\tlr: 1.000e-05, eta: 12:33:23, time: 2.043, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0259, s0.acc: 98.9838, s0.loss_bbox: 0.0199, s1.loss_cls: 0.0185, s1.acc: 98.5016, s1.loss_bbox: 0.0330, s2.loss_cls: 0.0119, s2.acc: 97.9156, s2.loss_bbox: 0.0275, loss: 0.1444, grad_norm: 4.8199\n",
            "2020-09-08 06:51:04,759 - mmdet - INFO - Epoch [16][4736/5332]\tlr: 1.000e-05, eta: 12:31:14, time: 2.063, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0267, s0.acc: 98.9166, s0.loss_bbox: 0.0176, s1.loss_cls: 0.0185, s1.acc: 98.5413, s1.loss_bbox: 0.0292, s2.loss_cls: 0.0117, s2.acc: 98.1079, s2.loss_bbox: 0.0242, loss: 0.1354, grad_norm: 4.8585\n",
            "2020-09-08 06:53:16,501 - mmdet - INFO - Epoch [16][4800/5332]\tlr: 1.000e-05, eta: 12:29:03, time: 2.058, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0286, s0.acc: 98.8770, s0.loss_bbox: 0.0196, s1.loss_cls: 0.0196, s1.acc: 98.3490, s1.loss_bbox: 0.0300, s2.loss_cls: 0.0124, s2.acc: 97.9645, s2.loss_bbox: 0.0214, loss: 0.1421, grad_norm: 4.4134\n",
            "2020-09-08 06:55:27,486 - mmdet - INFO - Epoch [16][4864/5332]\tlr: 1.000e-05, eta: 12:26:49, time: 2.047, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0257, s0.acc: 98.9227, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0168, s1.acc: 98.5687, s1.loss_bbox: 0.0268, s2.loss_cls: 0.0116, s2.acc: 97.6227, s2.loss_bbox: 0.0241, loss: 0.1286, grad_norm: 5.1382\n",
            "2020-09-08 06:57:38,467 - mmdet - INFO - Epoch [16][4928/5332]\tlr: 1.000e-05, eta: 12:24:35, time: 2.047, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0248, s0.acc: 98.9929, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0171, s1.acc: 98.6145, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0117, s2.acc: 97.9614, s2.loss_bbox: 0.0246, loss: 0.1311, grad_norm: 4.6425\n",
            "2020-09-08 06:59:50,722 - mmdet - INFO - Epoch [16][4992/5332]\tlr: 1.000e-05, eta: 12:22:26, time: 2.066, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0267, s0.acc: 98.9319, s0.loss_bbox: 0.0187, s1.loss_cls: 0.0185, s1.acc: 98.5504, s1.loss_bbox: 0.0281, s2.loss_cls: 0.0109, s2.acc: 98.1659, s2.loss_bbox: 0.0202, loss: 0.1311, grad_norm: 4.4562\n",
            "2020-09-08 07:02:02,006 - mmdet - INFO - Epoch [16][5056/5332]\tlr: 1.000e-05, eta: 12:20:13, time: 2.051, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0266, s0.acc: 98.8892, s0.loss_bbox: 0.0178, s1.loss_cls: 0.0173, s1.acc: 98.4680, s1.loss_bbox: 0.0279, s2.loss_cls: 0.0103, s2.acc: 98.1812, s2.loss_bbox: 0.0220, loss: 0.1282, grad_norm: 4.4374\n",
            "2020-09-08 07:04:14,176 - mmdet - INFO - Epoch [16][5120/5332]\tlr: 1.000e-05, eta: 12:18:04, time: 2.065, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0219, s0.acc: 99.1577, s0.loss_bbox: 0.0152, s1.loss_cls: 0.0144, s1.acc: 98.8525, s1.loss_bbox: 0.0275, s2.loss_cls: 0.0090, s2.acc: 98.5596, s2.loss_bbox: 0.0228, loss: 0.1191, grad_norm: 4.1211\n",
            "2020-09-08 07:06:25,629 - mmdet - INFO - Epoch [16][5184/5332]\tlr: 1.000e-05, eta: 12:15:52, time: 2.054, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0070, loss_rpn_bbox: 0.0063, s0.loss_cls: 0.0278, s0.acc: 98.9044, s0.loss_bbox: 0.0198, s1.loss_cls: 0.0181, s1.acc: 98.4497, s1.loss_bbox: 0.0274, s2.loss_cls: 0.0107, s2.acc: 98.2605, s2.loss_bbox: 0.0219, loss: 0.1390, grad_norm: 4.3900\n",
            "2020-09-08 07:08:36,537 - mmdet - INFO - Epoch [16][5248/5332]\tlr: 1.000e-05, eta: 12:13:38, time: 2.045, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0071, s0.loss_cls: 0.0281, s0.acc: 99.0387, s0.loss_bbox: 0.0169, s1.loss_cls: 0.0171, s1.acc: 98.7946, s1.loss_bbox: 0.0258, s2.loss_cls: 0.0104, s2.acc: 98.3948, s2.loss_bbox: 0.0214, loss: 0.1317, grad_norm: 4.6665\n",
            "2020-09-08 07:10:45,824 - mmdet - INFO - Epoch [16][5312/5332]\tlr: 1.000e-05, eta: 12:11:17, time: 2.020, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0208, s0.acc: 99.1760, s0.loss_bbox: 0.0131, s1.loss_cls: 0.0123, s1.acc: 99.0417, s1.loss_bbox: 0.0243, s2.loss_cls: 0.0087, s2.acc: 98.5809, s2.loss_bbox: 0.0228, loss: 0.1091, grad_norm: 3.7920\n",
            "2020-09-08 07:11:27,023 - mmdet - INFO - Saving checkpoint at 16 epochs\n",
            "[>>] 667/667, 0.6 task/s, elapsed: 1176s, ETA:     0s2020-09-08 07:31:17,078 - mmdet - INFO - \n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 82  | 226  | 0.854  | 0.594 |\n",
            "| 3     | 22  | 101  | 0.773  | 0.646 |\n",
            "| 4     | 529 | 1157 | 0.922  | 0.829 |\n",
            "| 5     | 78  | 172  | 0.897  | 0.797 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.717 |\n",
            "+-------+-----+------+--------+-------+\n",
            "2020-09-08 07:31:17,081 - mmdet - INFO - Epoch(val) [16][5332]\tmAP: 0.7167\n",
            "2020-09-08 07:33:32,045 - mmdet - INFO - Epoch [17][64/5332]\tlr: 1.000e-05, eta: 12:05:56, time: 2.108, data_time: 0.037, memory: 7880, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0257, s0.acc: 99.0112, s0.loss_bbox: 0.0191, s1.loss_cls: 0.0168, s1.acc: 98.5870, s1.loss_bbox: 0.0300, s2.loss_cls: 0.0104, s2.acc: 98.3337, s2.loss_bbox: 0.0260, loss: 0.1355, grad_norm: 4.4682\n",
            "2020-09-08 07:35:43,860 - mmdet - INFO - Epoch [17][128/5332]\tlr: 1.000e-05, eta: 12:03:47, time: 2.060, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0260, s0.acc: 98.9624, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0177, s1.acc: 98.4955, s1.loss_bbox: 0.0243, s2.loss_cls: 0.0111, s2.acc: 98.1140, s2.loss_bbox: 0.0222, loss: 0.1298, grad_norm: 4.7708\n",
            "2020-09-08 07:37:57,629 - mmdet - INFO - Epoch [17][192/5332]\tlr: 1.000e-05, eta: 12:01:46, time: 2.090, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0226, s0.acc: 99.1058, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0154, s1.acc: 98.7762, s1.loss_bbox: 0.0319, s2.loss_cls: 0.0100, s2.acc: 98.1293, s2.loss_bbox: 0.0249, loss: 0.1298, grad_norm: 4.5895\n",
            "2020-09-08 07:40:09,827 - mmdet - INFO - Epoch [17][256/5332]\tlr: 1.000e-05, eta: 11:59:39, time: 2.066, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0259, s0.acc: 98.9655, s0.loss_bbox: 0.0189, s1.loss_cls: 0.0168, s1.acc: 98.6603, s1.loss_bbox: 0.0333, s2.loss_cls: 0.0103, s2.acc: 98.1812, s2.loss_bbox: 0.0284, loss: 0.1404, grad_norm: 4.8432\n",
            "2020-09-08 07:42:23,072 - mmdet - INFO - Epoch [17][320/5332]\tlr: 1.000e-05, eta: 11:57:36, time: 2.082, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0064, s0.loss_cls: 0.0259, s0.acc: 99.0479, s0.loss_bbox: 0.0190, s1.loss_cls: 0.0197, s1.acc: 98.5809, s1.loss_bbox: 0.0309, s2.loss_cls: 0.0133, s2.acc: 97.8943, s2.loss_bbox: 0.0226, loss: 0.1421, grad_norm: 4.1367\n",
            "2020-09-08 07:44:35,080 - mmdet - INFO - Epoch [17][384/5332]\tlr: 1.000e-05, eta: 11:55:28, time: 2.063, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0243, s0.acc: 99.0326, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0151, s1.acc: 98.7701, s1.loss_bbox: 0.0339, s2.loss_cls: 0.0110, s2.acc: 98.1689, s2.loss_bbox: 0.0285, loss: 0.1377, grad_norm: 4.7433\n",
            "2020-09-08 07:46:47,099 - mmdet - INFO - Epoch [17][448/5332]\tlr: 1.000e-05, eta: 11:53:20, time: 2.063, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0300, s0.acc: 98.8373, s0.loss_bbox: 0.0223, s1.loss_cls: 0.0203, s1.acc: 98.3276, s1.loss_bbox: 0.0323, s2.loss_cls: 0.0120, s2.acc: 97.8699, s2.loss_bbox: 0.0244, loss: 0.1524, grad_norm: 5.0345\n",
            "2020-09-08 07:48:56,741 - mmdet - INFO - Epoch [17][512/5332]\tlr: 1.000e-05, eta: 11:51:03, time: 2.026, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0217, s0.acc: 99.1425, s0.loss_bbox: 0.0160, s1.loss_cls: 0.0144, s1.acc: 98.8770, s1.loss_bbox: 0.0295, s2.loss_cls: 0.0083, s2.acc: 98.6328, s2.loss_bbox: 0.0242, loss: 0.1245, grad_norm: 4.4306\n",
            "2020-09-08 07:51:08,625 - mmdet - INFO - Epoch [17][576/5332]\tlr: 1.000e-05, eta: 11:48:54, time: 2.061, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0239, s0.acc: 98.9655, s0.loss_bbox: 0.0186, s1.loss_cls: 0.0146, s1.acc: 98.9166, s1.loss_bbox: 0.0362, s2.loss_cls: 0.0105, s2.acc: 98.2483, s2.loss_bbox: 0.0245, loss: 0.1357, grad_norm: 4.9541\n",
            "2020-09-08 07:53:20,847 - mmdet - INFO - Epoch [17][640/5332]\tlr: 1.000e-05, eta: 11:46:47, time: 2.066, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0105, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0254, s0.acc: 99.0326, s0.loss_bbox: 0.0164, s1.loss_cls: 0.0167, s1.acc: 98.7122, s1.loss_bbox: 0.0284, s2.loss_cls: 0.0106, s2.acc: 98.1689, s2.loss_bbox: 0.0258, loss: 0.1382, grad_norm: 4.7450\n",
            "2020-09-08 07:55:32,193 - mmdet - INFO - Epoch [17][704/5332]\tlr: 1.000e-05, eta: 11:44:36, time: 2.052, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0254, s0.acc: 99.0204, s0.loss_bbox: 0.0174, s1.loss_cls: 0.0181, s1.acc: 98.6725, s1.loss_bbox: 0.0303, s2.loss_cls: 0.0125, s2.acc: 97.9980, s2.loss_bbox: 0.0253, loss: 0.1352, grad_norm: 4.9246\n",
            "2020-09-08 07:57:44,288 - mmdet - INFO - Epoch [17][768/5332]\tlr: 1.000e-05, eta: 11:42:28, time: 2.064, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0213, s0.acc: 99.0936, s0.loss_bbox: 0.0143, s1.loss_cls: 0.0145, s1.acc: 98.7122, s1.loss_bbox: 0.0255, s2.loss_cls: 0.0092, s2.acc: 98.4985, s2.loss_bbox: 0.0237, loss: 0.1147, grad_norm: 4.5603\n",
            "2020-09-08 07:59:55,788 - mmdet - INFO - Epoch [17][832/5332]\tlr: 1.000e-05, eta: 11:40:18, time: 2.055, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0111, loss_rpn_bbox: 0.0078, s0.loss_cls: 0.0256, s0.acc: 98.9716, s0.loss_bbox: 0.0174, s1.loss_cls: 0.0166, s1.acc: 98.5382, s1.loss_bbox: 0.0283, s2.loss_cls: 0.0105, s2.acc: 98.0591, s2.loss_bbox: 0.0227, loss: 0.1399, grad_norm: 4.7368\n",
            "2020-09-08 08:02:07,293 - mmdet - INFO - Epoch [17][896/5332]\tlr: 1.000e-05, eta: 11:38:08, time: 2.055, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0227, s0.acc: 99.0479, s0.loss_bbox: 0.0146, s1.loss_cls: 0.0148, s1.acc: 98.8129, s1.loss_bbox: 0.0231, s2.loss_cls: 0.0093, s2.acc: 98.3795, s2.loss_bbox: 0.0204, loss: 0.1128, grad_norm: 4.3373\n",
            "2020-09-08 08:04:18,576 - mmdet - INFO - Epoch [17][960/5332]\tlr: 1.000e-05, eta: 11:35:57, time: 2.051, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0237, s0.acc: 99.0753, s0.loss_bbox: 0.0165, s1.loss_cls: 0.0156, s1.acc: 98.8190, s1.loss_bbox: 0.0261, s2.loss_cls: 0.0095, s2.acc: 98.4375, s2.loss_bbox: 0.0214, loss: 0.1211, grad_norm: 4.2011\n",
            "2020-09-08 08:06:29,963 - mmdet - INFO - Epoch [17][1024/5332]\tlr: 1.000e-05, eta: 11:33:46, time: 2.053, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0284, s0.acc: 98.8708, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0194, s1.acc: 98.4497, s1.loss_bbox: 0.0349, s2.loss_cls: 0.0117, s2.acc: 98.0927, s2.loss_bbox: 0.0270, loss: 0.1499, grad_norm: 4.5658\n",
            "2020-09-08 08:08:42,143 - mmdet - INFO - Epoch [17][1088/5332]\tlr: 1.000e-05, eta: 11:31:38, time: 2.065, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0230, s0.acc: 98.9960, s0.loss_bbox: 0.0195, s1.loss_cls: 0.0153, s1.acc: 98.7152, s1.loss_bbox: 0.0302, s2.loss_cls: 0.0102, s2.acc: 98.2605, s2.loss_bbox: 0.0249, loss: 0.1316, grad_norm: 4.5211\n",
            "2020-09-08 08:10:54,728 - mmdet - INFO - Epoch [17][1152/5332]\tlr: 1.000e-05, eta: 11:29:31, time: 2.072, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0278, s0.acc: 98.9227, s0.loss_bbox: 0.0213, s1.loss_cls: 0.0203, s1.acc: 98.4955, s1.loss_bbox: 0.0332, s2.loss_cls: 0.0134, s2.acc: 97.8607, s2.loss_bbox: 0.0258, loss: 0.1497, grad_norm: 4.6839\n",
            "2020-09-08 08:13:06,446 - mmdet - INFO - Epoch [17][1216/5332]\tlr: 1.000e-05, eta: 11:27:21, time: 2.058, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0211, s0.acc: 99.1058, s0.loss_bbox: 0.0142, s1.loss_cls: 0.0136, s1.acc: 98.8190, s1.loss_bbox: 0.0265, s2.loss_cls: 0.0085, s2.acc: 98.6176, s2.loss_bbox: 0.0238, loss: 0.1157, grad_norm: 4.0678\n",
            "2020-09-08 08:15:16,874 - mmdet - INFO - Epoch [17][1280/5332]\tlr: 1.000e-05, eta: 11:25:07, time: 2.038, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0026, s0.loss_cls: 0.0219, s0.acc: 99.0997, s0.loss_bbox: 0.0152, s1.loss_cls: 0.0134, s1.acc: 98.8953, s1.loss_bbox: 0.0258, s2.loss_cls: 0.0093, s2.acc: 98.3154, s2.loss_bbox: 0.0226, loss: 0.1131, grad_norm: 4.3187\n",
            "2020-09-08 08:17:29,394 - mmdet - INFO - Epoch [17][1344/5332]\tlr: 1.000e-05, eta: 11:23:00, time: 2.071, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0201, s0.acc: 99.2584, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0132, s1.acc: 98.9990, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0089, s2.acc: 98.6267, s2.loss_bbox: 0.0257, loss: 0.1233, grad_norm: 4.3336\n",
            "2020-09-08 08:19:40,720 - mmdet - INFO - Epoch [17][1408/5332]\tlr: 1.000e-05, eta: 11:20:49, time: 2.052, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0225, s0.acc: 99.0662, s0.loss_bbox: 0.0165, s1.loss_cls: 0.0136, s1.acc: 98.9136, s1.loss_bbox: 0.0226, s2.loss_cls: 0.0080, s2.acc: 98.7213, s2.loss_bbox: 0.0174, loss: 0.1065, grad_norm: 3.8752\n",
            "2020-09-08 08:21:52,582 - mmdet - INFO - Epoch [17][1472/5332]\tlr: 1.000e-05, eta: 11:18:40, time: 2.060, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0222, s0.acc: 99.0051, s0.loss_bbox: 0.0151, s1.loss_cls: 0.0152, s1.acc: 98.7640, s1.loss_bbox: 0.0265, s2.loss_cls: 0.0096, s2.acc: 98.3826, s2.loss_bbox: 0.0241, loss: 0.1189, grad_norm: 4.1623\n",
            "2020-09-08 08:24:05,295 - mmdet - INFO - Epoch [17][1536/5332]\tlr: 1.000e-05, eta: 11:16:33, time: 2.074, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0281, s0.acc: 98.9075, s0.loss_bbox: 0.0160, s1.loss_cls: 0.0183, s1.acc: 98.5687, s1.loss_bbox: 0.0288, s2.loss_cls: 0.0117, s2.acc: 97.9980, s2.loss_bbox: 0.0246, loss: 0.1351, grad_norm: 5.1110\n",
            "2020-09-08 08:26:16,153 - mmdet - INFO - Epoch [17][1600/5332]\tlr: 1.000e-05, eta: 11:14:20, time: 2.045, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0271, s0.acc: 98.9441, s0.loss_bbox: 0.0191, s1.loss_cls: 0.0178, s1.acc: 98.5718, s1.loss_bbox: 0.0293, s2.loss_cls: 0.0101, s2.acc: 98.3521, s2.loss_bbox: 0.0240, loss: 0.1364, grad_norm: 4.5576\n",
            "2020-09-08 08:28:28,646 - mmdet - INFO - Epoch [17][1664/5332]\tlr: 1.000e-05, eta: 11:12:12, time: 2.070, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0065, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0255, s0.acc: 99.0173, s0.loss_bbox: 0.0173, s1.loss_cls: 0.0153, s1.acc: 98.6969, s1.loss_bbox: 0.0273, s2.loss_cls: 0.0089, s2.acc: 98.5992, s2.loss_bbox: 0.0203, loss: 0.1263, grad_norm: 4.7506\n",
            "2020-09-08 08:30:40,487 - mmdet - INFO - Epoch [17][1728/5332]\tlr: 1.000e-05, eta: 11:10:03, time: 2.060, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0248, s0.acc: 98.9807, s0.loss_bbox: 0.0189, s1.loss_cls: 0.0158, s1.acc: 98.7122, s1.loss_bbox: 0.0330, s2.loss_cls: 0.0097, s2.acc: 98.4863, s2.loss_bbox: 0.0292, loss: 0.1385, grad_norm: 4.9907\n",
            "2020-09-08 08:32:53,389 - mmdet - INFO - Epoch [17][1792/5332]\tlr: 1.000e-05, eta: 11:07:56, time: 2.077, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0225, s0.acc: 99.1455, s0.loss_bbox: 0.0154, s1.loss_cls: 0.0149, s1.acc: 98.7427, s1.loss_bbox: 0.0253, s2.loss_cls: 0.0097, s2.acc: 98.2697, s2.loss_bbox: 0.0217, loss: 0.1177, grad_norm: 4.3785\n",
            "2020-09-08 08:35:03,769 - mmdet - INFO - Epoch [17][1856/5332]\tlr: 1.000e-05, eta: 11:05:42, time: 2.037, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0217, s0.acc: 99.2371, s0.loss_bbox: 0.0148, s1.loss_cls: 0.0130, s1.acc: 98.9563, s1.loss_bbox: 0.0240, s2.loss_cls: 0.0080, s2.acc: 98.8037, s2.loss_bbox: 0.0214, loss: 0.1117, grad_norm: 4.2716\n",
            "2020-09-08 08:37:16,472 - mmdet - INFO - Epoch [17][1920/5332]\tlr: 1.000e-05, eta: 11:03:35, time: 2.073, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0245, s0.acc: 99.2889, s0.loss_bbox: 0.0165, s1.loss_cls: 0.0150, s1.acc: 98.9075, s1.loss_bbox: 0.0285, s2.loss_cls: 0.0086, s2.acc: 98.7427, s2.loss_bbox: 0.0249, loss: 0.1255, grad_norm: 4.6474\n",
            "2020-09-08 08:39:30,039 - mmdet - INFO - Epoch [17][1984/5332]\tlr: 1.000e-05, eta: 11:01:29, time: 2.087, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0234, s0.acc: 99.0875, s0.loss_bbox: 0.0201, s1.loss_cls: 0.0162, s1.acc: 98.7640, s1.loss_bbox: 0.0339, s2.loss_cls: 0.0106, s2.acc: 98.2941, s2.loss_bbox: 0.0270, loss: 0.1377, grad_norm: 4.5005\n",
            "2020-09-08 08:41:42,626 - mmdet - INFO - Epoch [17][2048/5332]\tlr: 1.000e-05, eta: 10:59:21, time: 2.072, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0071, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0266, s0.acc: 99.0112, s0.loss_bbox: 0.0177, s1.loss_cls: 0.0164, s1.acc: 98.7488, s1.loss_bbox: 0.0306, s2.loss_cls: 0.0100, s2.acc: 98.4589, s2.loss_bbox: 0.0296, loss: 0.1428, grad_norm: 5.3545\n",
            "2020-09-08 08:43:54,563 - mmdet - INFO - Epoch [17][2112/5332]\tlr: 1.000e-05, eta: 10:57:12, time: 2.061, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0228, s0.acc: 99.1333, s0.loss_bbox: 0.0169, s1.loss_cls: 0.0143, s1.acc: 98.8770, s1.loss_bbox: 0.0288, s2.loss_cls: 0.0085, s2.acc: 98.7915, s2.loss_bbox: 0.0273, loss: 0.1275, grad_norm: 4.4562\n",
            "2020-09-08 08:46:06,362 - mmdet - INFO - Epoch [17][2176/5332]\tlr: 1.000e-05, eta: 10:55:01, time: 2.059, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0256, s0.acc: 98.9929, s0.loss_bbox: 0.0136, s1.loss_cls: 0.0161, s1.acc: 98.7762, s1.loss_bbox: 0.0266, s2.loss_cls: 0.0094, s2.acc: 98.6328, s2.loss_bbox: 0.0237, loss: 0.1232, grad_norm: 4.4238\n",
            "2020-09-08 08:48:17,477 - mmdet - INFO - Epoch [17][2240/5332]\tlr: 1.000e-05, eta: 10:52:50, time: 2.049, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0242, s0.acc: 99.0143, s0.loss_bbox: 0.0157, s1.loss_cls: 0.0156, s1.acc: 98.7732, s1.loss_bbox: 0.0244, s2.loss_cls: 0.0095, s2.acc: 98.5168, s2.loss_bbox: 0.0222, loss: 0.1195, grad_norm: 4.1528\n",
            "2020-09-08 08:50:29,688 - mmdet - INFO - Epoch [17][2304/5332]\tlr: 1.000e-05, eta: 10:50:40, time: 2.066, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0225, s0.acc: 99.0417, s0.loss_bbox: 0.0153, s1.loss_cls: 0.0145, s1.acc: 98.7122, s1.loss_bbox: 0.0305, s2.loss_cls: 0.0095, s2.acc: 98.3337, s2.loss_bbox: 0.0258, loss: 0.1256, grad_norm: 4.7837\n",
            "2020-09-08 08:52:41,685 - mmdet - INFO - Epoch [17][2368/5332]\tlr: 1.000e-05, eta: 10:48:31, time: 2.062, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0209, s0.acc: 99.2249, s0.loss_bbox: 0.0130, s1.loss_cls: 0.0141, s1.acc: 99.0082, s1.loss_bbox: 0.0222, s2.loss_cls: 0.0088, s2.acc: 98.7427, s2.loss_bbox: 0.0207, loss: 0.1071, grad_norm: 3.9649\n",
            "2020-09-08 08:54:55,052 - mmdet - INFO - Epoch [17][2432/5332]\tlr: 1.000e-05, eta: 10:46:24, time: 2.084, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0245, s0.acc: 99.0265, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0153, s1.acc: 98.7610, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0104, s2.acc: 98.3154, s2.loss_bbox: 0.0242, loss: 0.1294, grad_norm: 4.3938\n",
            "2020-09-08 08:57:06,549 - mmdet - INFO - Epoch [17][2496/5332]\tlr: 1.000e-05, eta: 10:44:13, time: 2.055, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0251, s0.acc: 99.0295, s0.loss_bbox: 0.0180, s1.loss_cls: 0.0170, s1.acc: 98.7671, s1.loss_bbox: 0.0320, s2.loss_cls: 0.0112, s2.acc: 97.9462, s2.loss_bbox: 0.0236, loss: 0.1361, grad_norm: 5.0199\n",
            "2020-09-08 08:59:19,271 - mmdet - INFO - Epoch [17][2560/5332]\tlr: 1.000e-05, eta: 10:42:05, time: 2.074, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0237, s0.acc: 99.0387, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0142, s1.acc: 98.9136, s1.loss_bbox: 0.0280, s2.loss_cls: 0.0093, s2.acc: 98.5413, s2.loss_bbox: 0.0224, loss: 0.1216, grad_norm: 3.9714\n",
            "2020-09-08 09:01:31,718 - mmdet - INFO - Epoch [17][2624/5332]\tlr: 1.000e-05, eta: 10:39:56, time: 2.069, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0213, s0.acc: 99.1058, s0.loss_bbox: 0.0148, s1.loss_cls: 0.0163, s1.acc: 98.6542, s1.loss_bbox: 0.0256, s2.loss_cls: 0.0107, s2.acc: 98.1903, s2.loss_bbox: 0.0217, loss: 0.1193, grad_norm: 4.4804\n",
            "2020-09-08 09:03:43,193 - mmdet - INFO - Epoch [17][2688/5332]\tlr: 1.000e-05, eta: 10:37:45, time: 2.054, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0204, s0.acc: 99.2340, s0.loss_bbox: 0.0176, s1.loss_cls: 0.0123, s1.acc: 99.0723, s1.loss_bbox: 0.0324, s2.loss_cls: 0.0082, s2.acc: 98.6267, s2.loss_bbox: 0.0234, loss: 0.1236, grad_norm: 4.2085\n",
            "2020-09-08 09:05:56,206 - mmdet - INFO - Epoch [17][2752/5332]\tlr: 1.000e-05, eta: 10:35:37, time: 2.078, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0263, s0.acc: 99.0173, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0161, s1.acc: 98.8770, s1.loss_bbox: 0.0281, s2.loss_cls: 0.0112, s2.acc: 98.3337, s2.loss_bbox: 0.0243, loss: 0.1318, grad_norm: 4.5410\n",
            "2020-09-08 09:08:09,074 - mmdet - INFO - Epoch [17][2816/5332]\tlr: 1.000e-05, eta: 10:33:29, time: 2.076, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0196, s0.acc: 99.2615, s0.loss_bbox: 0.0178, s1.loss_cls: 0.0130, s1.acc: 98.9685, s1.loss_bbox: 0.0268, s2.loss_cls: 0.0082, s2.acc: 98.8129, s2.loss_bbox: 0.0201, loss: 0.1141, grad_norm: 4.0698\n",
            "2020-09-08 09:10:21,088 - mmdet - INFO - Epoch [17][2880/5332]\tlr: 1.000e-05, eta: 10:31:19, time: 2.063, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0248, s0.acc: 98.9990, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0158, s1.acc: 98.7854, s1.loss_bbox: 0.0270, s2.loss_cls: 0.0098, s2.acc: 98.2544, s2.loss_bbox: 0.0255, loss: 0.1278, grad_norm: 4.4039\n",
            "2020-09-08 09:12:33,818 - mmdet - INFO - Epoch [17][2944/5332]\tlr: 1.000e-05, eta: 10:29:11, time: 2.074, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0206, s0.acc: 99.2096, s0.loss_bbox: 0.0153, s1.loss_cls: 0.0145, s1.acc: 98.8281, s1.loss_bbox: 0.0251, s2.loss_cls: 0.0089, s2.acc: 98.5107, s2.loss_bbox: 0.0214, loss: 0.1129, grad_norm: 3.8564\n",
            "2020-09-08 09:14:44,514 - mmdet - INFO - Epoch [17][3008/5332]\tlr: 1.000e-05, eta: 10:26:58, time: 2.042, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0070, s0.loss_cls: 0.0266, s0.acc: 98.9899, s0.loss_bbox: 0.0209, s1.loss_cls: 0.0153, s1.acc: 98.8586, s1.loss_bbox: 0.0291, s2.loss_cls: 0.0089, s2.acc: 98.7671, s2.loss_bbox: 0.0239, loss: 0.1354, grad_norm: 4.3008\n",
            "2020-09-08 09:16:57,447 - mmdet - INFO - Epoch [17][3072/5332]\tlr: 1.000e-05, eta: 10:24:50, time: 2.077, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0247, s0.acc: 99.0265, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0162, s1.acc: 98.7122, s1.loss_bbox: 0.0287, s2.loss_cls: 0.0098, s2.acc: 98.4589, s2.loss_bbox: 0.0264, loss: 0.1321, grad_norm: 4.6497\n",
            "2020-09-08 09:19:07,444 - mmdet - INFO - Epoch [17][3136/5332]\tlr: 1.000e-05, eta: 10:22:35, time: 2.031, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0200, s0.acc: 99.2218, s0.loss_bbox: 0.0150, s1.loss_cls: 0.0146, s1.acc: 98.7610, s1.loss_bbox: 0.0241, s2.loss_cls: 0.0090, s2.acc: 98.4253, s2.loss_bbox: 0.0206, loss: 0.1111, grad_norm: 4.2606\n",
            "2020-09-08 09:21:19,305 - mmdet - INFO - Epoch [17][3200/5332]\tlr: 1.000e-05, eta: 10:20:25, time: 2.060, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0274, s0.acc: 98.9471, s0.loss_bbox: 0.0201, s1.loss_cls: 0.0183, s1.acc: 98.5870, s1.loss_bbox: 0.0305, s2.loss_cls: 0.0123, s2.acc: 97.8729, s2.loss_bbox: 0.0205, loss: 0.1391, grad_norm: 4.1797\n",
            "2020-09-08 09:23:32,648 - mmdet - INFO - Epoch [17][3264/5332]\tlr: 1.000e-05, eta: 10:18:17, time: 2.083, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0065, s0.loss_cls: 0.0231, s0.acc: 99.1394, s0.loss_bbox: 0.0176, s1.loss_cls: 0.0142, s1.acc: 98.8678, s1.loss_bbox: 0.0273, s2.loss_cls: 0.0099, s2.acc: 98.3276, s2.loss_bbox: 0.0212, loss: 0.1252, grad_norm: 4.5986\n",
            "2020-09-08 09:25:45,572 - mmdet - INFO - Epoch [17][3328/5332]\tlr: 1.000e-05, eta: 10:16:09, time: 2.077, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0191, s0.acc: 99.2340, s0.loss_bbox: 0.0140, s1.loss_cls: 0.0126, s1.acc: 99.0326, s1.loss_bbox: 0.0272, s2.loss_cls: 0.0087, s2.acc: 98.6328, s2.loss_bbox: 0.0286, loss: 0.1159, grad_norm: 4.4489\n",
            "2020-09-08 09:27:57,363 - mmdet - INFO - Epoch [17][3392/5332]\tlr: 1.000e-05, eta: 10:13:58, time: 2.059, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0236, s0.acc: 99.0417, s0.loss_bbox: 0.0164, s1.loss_cls: 0.0155, s1.acc: 98.6847, s1.loss_bbox: 0.0273, s2.loss_cls: 0.0103, s2.acc: 98.1598, s2.loss_bbox: 0.0215, loss: 0.1222, grad_norm: 4.5638\n",
            "2020-09-08 09:30:08,778 - mmdet - INFO - Epoch [17][3456/5332]\tlr: 1.000e-05, eta: 10:11:47, time: 2.053, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0226, s0.acc: 99.1272, s0.loss_bbox: 0.0196, s1.loss_cls: 0.0141, s1.acc: 98.8464, s1.loss_bbox: 0.0296, s2.loss_cls: 0.0095, s2.acc: 98.2910, s2.loss_bbox: 0.0256, loss: 0.1288, grad_norm: 4.5270\n",
            "2020-09-08 09:32:20,296 - mmdet - INFO - Epoch [17][3520/5332]\tlr: 1.000e-05, eta: 10:09:35, time: 2.055, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0258, s0.acc: 98.9746, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0161, s1.acc: 98.7457, s1.loss_bbox: 0.0270, s2.loss_cls: 0.0103, s2.acc: 98.3582, s2.loss_bbox: 0.0233, loss: 0.1284, grad_norm: 4.6000\n",
            "2020-09-08 09:34:31,553 - mmdet - INFO - Epoch [17][3584/5332]\tlr: 1.000e-05, eta: 10:07:24, time: 2.051, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0261, s0.acc: 98.9655, s0.loss_bbox: 0.0187, s1.loss_cls: 0.0170, s1.acc: 98.6572, s1.loss_bbox: 0.0367, s2.loss_cls: 0.0116, s2.acc: 98.1171, s2.loss_bbox: 0.0271, loss: 0.1477, grad_norm: 4.7716\n",
            "2020-09-08 09:36:44,170 - mmdet - INFO - Epoch [17][3648/5332]\tlr: 1.000e-05, eta: 10:05:14, time: 2.072, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0215, s0.acc: 99.1791, s0.loss_bbox: 0.0140, s1.loss_cls: 0.0152, s1.acc: 98.7152, s1.loss_bbox: 0.0244, s2.loss_cls: 0.0099, s2.acc: 98.0377, s2.loss_bbox: 0.0233, loss: 0.1172, grad_norm: 4.2577\n",
            "2020-09-08 09:38:55,076 - mmdet - INFO - Epoch [17][3712/5332]\tlr: 1.000e-05, eta: 10:03:02, time: 2.045, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0227, s0.acc: 99.0692, s0.loss_bbox: 0.0191, s1.loss_cls: 0.0150, s1.acc: 98.8770, s1.loss_bbox: 0.0292, s2.loss_cls: 0.0090, s2.acc: 98.6755, s2.loss_bbox: 0.0253, loss: 0.1296, grad_norm: 4.4164\n",
            "2020-09-08 09:41:07,352 - mmdet - INFO - Epoch [17][3776/5332]\tlr: 1.000e-05, eta: 10:00:52, time: 2.067, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0285, s0.acc: 98.8373, s0.loss_bbox: 0.0191, s1.loss_cls: 0.0192, s1.acc: 98.5168, s1.loss_bbox: 0.0335, s2.loss_cls: 0.0121, s2.acc: 98.1079, s2.loss_bbox: 0.0264, loss: 0.1492, grad_norm: 5.1006\n",
            "2020-09-08 09:43:18,287 - mmdet - INFO - Epoch [17][3840/5332]\tlr: 1.000e-05, eta: 9:58:40, time: 2.046, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0256, s0.acc: 98.9532, s0.loss_bbox: 0.0162, s1.loss_cls: 0.0189, s1.acc: 98.3276, s1.loss_bbox: 0.0244, s2.loss_cls: 0.0113, s2.acc: 98.0591, s2.loss_bbox: 0.0209, loss: 0.1260, grad_norm: 4.2497\n",
            "2020-09-08 09:45:31,497 - mmdet - INFO - Epoch [17][3904/5332]\tlr: 1.000e-05, eta: 9:56:31, time: 2.081, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0200, s0.acc: 99.2004, s0.loss_bbox: 0.0142, s1.loss_cls: 0.0126, s1.acc: 98.9624, s1.loss_bbox: 0.0263, s2.loss_cls: 0.0084, s2.acc: 98.6359, s2.loss_bbox: 0.0238, loss: 0.1116, grad_norm: 3.9941\n",
            "2020-09-08 09:47:43,939 - mmdet - INFO - Epoch [17][3968/5332]\tlr: 1.000e-05, eta: 9:54:22, time: 2.069, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0275, s0.acc: 98.8312, s0.loss_bbox: 0.0197, s1.loss_cls: 0.0190, s1.acc: 98.3795, s1.loss_bbox: 0.0319, s2.loss_cls: 0.0117, s2.acc: 98.0438, s2.loss_bbox: 0.0244, loss: 0.1426, grad_norm: 4.6107\n",
            "2020-09-08 09:49:57,129 - mmdet - INFO - Epoch [17][4032/5332]\tlr: 1.000e-05, eta: 9:52:13, time: 2.081, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0067, s0.loss_cls: 0.0224, s0.acc: 99.0967, s0.loss_bbox: 0.0166, s1.loss_cls: 0.0139, s1.acc: 98.8098, s1.loss_bbox: 0.0285, s2.loss_cls: 0.0089, s2.acc: 98.6511, s2.loss_bbox: 0.0224, loss: 0.1224, grad_norm: 4.3066\n",
            "2020-09-08 09:52:08,787 - mmdet - INFO - Epoch [17][4096/5332]\tlr: 1.000e-05, eta: 9:50:02, time: 2.057, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0245, s0.acc: 99.0356, s0.loss_bbox: 0.0165, s1.loss_cls: 0.0170, s1.acc: 98.6725, s1.loss_bbox: 0.0256, s2.loss_cls: 0.0110, s2.acc: 98.1415, s2.loss_bbox: 0.0201, loss: 0.1239, grad_norm: 4.8401\n",
            "2020-09-08 09:54:20,294 - mmdet - INFO - Epoch [17][4160/5332]\tlr: 1.000e-05, eta: 9:47:51, time: 2.055, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0085, s0.loss_cls: 0.0287, s0.acc: 98.8129, s0.loss_bbox: 0.0201, s1.loss_cls: 0.0185, s1.acc: 98.4192, s1.loss_bbox: 0.0316, s2.loss_cls: 0.0127, s2.acc: 97.7936, s2.loss_bbox: 0.0246, loss: 0.1492, grad_norm: 4.5876\n",
            "2020-09-08 09:56:31,188 - mmdet - INFO - Epoch [17][4224/5332]\tlr: 1.000e-05, eta: 9:45:38, time: 2.045, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0237, s0.acc: 98.9532, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0135, s1.acc: 98.8739, s1.loss_bbox: 0.0253, s2.loss_cls: 0.0086, s2.acc: 98.7061, s2.loss_bbox: 0.0228, loss: 0.1169, grad_norm: 4.1669\n",
            "2020-09-08 09:58:40,979 - mmdet - INFO - Epoch [17][4288/5332]\tlr: 1.000e-05, eta: 9:43:24, time: 2.028, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0285, s0.acc: 98.9532, s0.loss_bbox: 0.0210, s1.loss_cls: 0.0167, s1.acc: 98.7244, s1.loss_bbox: 0.0317, s2.loss_cls: 0.0104, s2.acc: 98.3521, s2.loss_bbox: 0.0257, loss: 0.1436, grad_norm: 4.9781\n",
            "2020-09-08 10:00:52,340 - mmdet - INFO - Epoch [17][4352/5332]\tlr: 1.000e-05, eta: 9:41:12, time: 2.052, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0245, s0.acc: 98.9655, s0.loss_bbox: 0.0213, s1.loss_cls: 0.0175, s1.acc: 98.5748, s1.loss_bbox: 0.0370, s2.loss_cls: 0.0118, s2.acc: 97.7997, s2.loss_bbox: 0.0266, loss: 0.1477, grad_norm: 4.9962\n",
            "2020-09-08 10:03:04,988 - mmdet - INFO - Epoch [17][4416/5332]\tlr: 1.000e-05, eta: 9:39:03, time: 2.073, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0236, s0.acc: 99.1425, s0.loss_bbox: 0.0141, s1.loss_cls: 0.0147, s1.acc: 98.7885, s1.loss_bbox: 0.0268, s2.loss_cls: 0.0095, s2.acc: 98.4680, s2.loss_bbox: 0.0244, loss: 0.1208, grad_norm: 4.6927\n",
            "2020-09-08 10:05:17,432 - mmdet - INFO - Epoch [17][4480/5332]\tlr: 1.000e-05, eta: 9:36:53, time: 2.069, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0203, s0.acc: 99.1974, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0154, s1.acc: 98.7427, s1.loss_bbox: 0.0264, s2.loss_cls: 0.0102, s2.acc: 98.4406, s2.loss_bbox: 0.0195, loss: 0.1144, grad_norm: 4.0577\n",
            "2020-09-08 10:07:28,223 - mmdet - INFO - Epoch [17][4544/5332]\tlr: 1.000e-05, eta: 9:34:40, time: 2.044, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0225, s0.acc: 99.1364, s0.loss_bbox: 0.0139, s1.loss_cls: 0.0167, s1.acc: 98.5962, s1.loss_bbox: 0.0272, s2.loss_cls: 0.0113, s2.acc: 98.0865, s2.loss_bbox: 0.0243, loss: 0.1232, grad_norm: 4.4594\n",
            "2020-09-08 10:09:41,621 - mmdet - INFO - Epoch [17][4608/5332]\tlr: 1.000e-05, eta: 9:32:32, time: 2.084, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0267, s0.acc: 99.0173, s0.loss_bbox: 0.0189, s1.loss_cls: 0.0194, s1.acc: 98.5504, s1.loss_bbox: 0.0282, s2.loss_cls: 0.0125, s2.acc: 97.8943, s2.loss_bbox: 0.0198, loss: 0.1351, grad_norm: 4.0301\n",
            "2020-09-08 10:11:52,783 - mmdet - INFO - Epoch [17][4672/5332]\tlr: 1.000e-05, eta: 9:30:20, time: 2.049, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0214, s0.acc: 99.2340, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0136, s1.acc: 98.9838, s1.loss_bbox: 0.0253, s2.loss_cls: 0.0084, s2.acc: 98.7671, s2.loss_bbox: 0.0224, loss: 0.1171, grad_norm: 4.0685\n",
            "2020-09-08 10:14:05,102 - mmdet - INFO - Epoch [17][4736/5332]\tlr: 1.000e-05, eta: 9:28:10, time: 2.067, data_time: 0.005, memory: 7880, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0227, s0.acc: 99.0570, s0.loss_bbox: 0.0165, s1.loss_cls: 0.0131, s1.acc: 99.0112, s1.loss_bbox: 0.0284, s2.loss_cls: 0.0087, s2.acc: 98.6267, s2.loss_bbox: 0.0252, loss: 0.1226, grad_norm: 4.3015\n",
            "2020-09-08 10:16:18,295 - mmdet - INFO - Epoch [17][4800/5332]\tlr: 1.000e-05, eta: 9:26:01, time: 2.081, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0283, s0.acc: 98.9166, s0.loss_bbox: 0.0219, s1.loss_cls: 0.0180, s1.acc: 98.6237, s1.loss_bbox: 0.0367, s2.loss_cls: 0.0114, s2.acc: 98.1628, s2.loss_bbox: 0.0299, loss: 0.1539, grad_norm: 5.1705\n",
            "2020-09-08 10:18:29,970 - mmdet - INFO - Epoch [17][4864/5332]\tlr: 1.000e-05, eta: 9:23:50, time: 2.057, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0223, s0.acc: 99.1028, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0155, s1.acc: 98.8953, s1.loss_bbox: 0.0267, s2.loss_cls: 0.0097, s2.acc: 98.2910, s2.loss_bbox: 0.0238, loss: 0.1202, grad_norm: 4.2130\n",
            "2020-09-08 10:20:41,907 - mmdet - INFO - Epoch [17][4928/5332]\tlr: 1.000e-05, eta: 9:21:39, time: 2.062, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0261, s0.acc: 99.0082, s0.loss_bbox: 0.0194, s1.loss_cls: 0.0168, s1.acc: 98.5931, s1.loss_bbox: 0.0285, s2.loss_cls: 0.0114, s2.acc: 98.0011, s2.loss_bbox: 0.0230, loss: 0.1357, grad_norm: 4.5226\n",
            "2020-09-08 10:22:51,621 - mmdet - INFO - Epoch [17][4992/5332]\tlr: 1.000e-05, eta: 9:19:25, time: 2.027, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0268, s0.acc: 98.9563, s0.loss_bbox: 0.0168, s1.loss_cls: 0.0182, s1.acc: 98.5809, s1.loss_bbox: 0.0276, s2.loss_cls: 0.0117, s2.acc: 97.9828, s2.loss_bbox: 0.0215, loss: 0.1302, grad_norm: 4.6400\n",
            "2020-09-08 10:25:04,161 - mmdet - INFO - Epoch [17][5056/5332]\tlr: 1.000e-05, eta: 9:17:15, time: 2.071, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0077, s0.loss_cls: 0.0299, s0.acc: 98.8464, s0.loss_bbox: 0.0223, s1.loss_cls: 0.0197, s1.acc: 98.4650, s1.loss_bbox: 0.0364, s2.loss_cls: 0.0116, s2.acc: 97.9706, s2.loss_bbox: 0.0249, loss: 0.1560, grad_norm: 4.8265\n",
            "2020-09-08 10:27:16,582 - mmdet - INFO - Epoch [17][5120/5332]\tlr: 1.000e-05, eta: 9:15:05, time: 2.069, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0265, s0.acc: 98.9563, s0.loss_bbox: 0.0154, s1.loss_cls: 0.0187, s1.acc: 98.4772, s1.loss_bbox: 0.0266, s2.loss_cls: 0.0106, s2.acc: 98.2391, s2.loss_bbox: 0.0186, loss: 0.1243, grad_norm: 4.3303\n",
            "2020-09-08 10:29:27,737 - mmdet - INFO - Epoch [17][5184/5332]\tlr: 1.000e-05, eta: 9:12:53, time: 2.049, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0028, s0.loss_cls: 0.0203, s0.acc: 99.2767, s0.loss_bbox: 0.0115, s1.loss_cls: 0.0133, s1.acc: 99.0326, s1.loss_bbox: 0.0213, s2.loss_cls: 0.0079, s2.acc: 98.8190, s2.loss_bbox: 0.0212, loss: 0.1017, grad_norm: 3.9165\n",
            "2020-09-08 10:31:39,557 - mmdet - INFO - Epoch [17][5248/5332]\tlr: 1.000e-05, eta: 9:10:42, time: 2.060, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0068, s0.loss_cls: 0.0246, s0.acc: 99.0997, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0180, s1.acc: 98.6908, s1.loss_bbox: 0.0275, s2.loss_cls: 0.0115, s2.acc: 98.2025, s2.loss_bbox: 0.0239, loss: 0.1322, grad_norm: 4.4389\n",
            "2020-09-08 10:33:50,342 - mmdet - INFO - Epoch [17][5312/5332]\tlr: 1.000e-05, eta: 9:08:29, time: 2.044, data_time: 0.004, memory: 7880, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0234, s0.acc: 99.1058, s0.loss_bbox: 0.0136, s1.loss_cls: 0.0147, s1.acc: 98.8373, s1.loss_bbox: 0.0241, s2.loss_cls: 0.0099, s2.acc: 98.5626, s2.loss_bbox: 0.0190, loss: 0.1105, grad_norm: 4.0915\n",
            "2020-09-08 10:34:31,071 - mmdet - INFO - Saving checkpoint at 17 epochs\n",
            "[>>] 667/667, 0.6 task/s, elapsed: 1185s, ETA:     0s2020-09-08 10:54:23,703 - mmdet - INFO - \n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 82  | 224  | 0.841  | 0.588 |\n",
            "| 3     | 22  | 95   | 0.773  | 0.641 |\n",
            "| 4     | 529 | 1160 | 0.928  | 0.832 |\n",
            "| 5     | 78  | 167  | 0.885  | 0.794 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.714 |\n",
            "+-------+-----+------+--------+-------+\n",
            "2020-09-08 10:54:23,707 - mmdet - INFO - Epoch(val) [17][5332]\tmAP: 0.7138\n",
            "Process Process-13:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/local/lib/python3.7/threading.py\", line 1044, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/local/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjxQ5WUIcUFA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b80b19be-c47b-458a-8df1-8af8db290c7c"
      },
      "source": [
        "!python tools/train.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py --resume-from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_17.pth"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-08 15:31:53,346 - mmdet - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.7.6 (default, Jan  8 2020, 19:59:22) [GCC 7.3.0]\n",
            "CUDA available: True\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
            "GPU 0: Tesla T4\n",
            "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "PyTorch: 1.4.0\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CUDA Runtime 10.0\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.1\n",
            "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "TorchVision: 0.5.0\n",
            "OpenCV: 4.4.0\n",
            "MMCV: 1.1.2\n",
            "MMDetection: 2.3.0+\n",
            "MMDetection Compiler: GCC 7.5\n",
            "MMDetection CUDA Compiler: 10.1\n",
            "------------------------------------------------------------\n",
            "\n",
            "2020-09-08 15:31:54,076 - mmdet - INFO - Distributed training: False\n",
            "2020-09-08 15:31:54,783 - mmdet - INFO - Config:\n",
            "model = dict(\n",
            "    type='CascadeRCNN',\n",
            "    pretrained='open-mmlab://resnext101_32x4d',\n",
            "    backbone=dict(\n",
            "        type='DetectoRS_ResNeXt',\n",
            "        depth=101,\n",
            "        groups=32,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=True,\n",
            "        style='pytorch',\n",
            "        conv_cfg=dict(type='ConvAWS'),\n",
            "        sac=dict(type='SAC', use_deform=True),\n",
            "        stage_with_sac=(False, True, True, True),\n",
            "        output_img=True),\n",
            "    neck=dict(\n",
            "        type='RFP',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5,\n",
            "        rfp_steps=2,\n",
            "        aspp_out_channels=64,\n",
            "        aspp_dilations=(1, 3, 6, 1),\n",
            "        rfp_backbone=dict(\n",
            "            rfp_inplanes=256,\n",
            "            type='DetectoRS_ResNeXt',\n",
            "            depth=101,\n",
            "            num_stages=4,\n",
            "            out_indices=(0, 1, 2, 3),\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(type='BN', requires_grad=True),\n",
            "            norm_eval=True,\n",
            "            conv_cfg=dict(type='ConvAWS'),\n",
            "            sac=dict(type='SAC', use_deform=True),\n",
            "            stage_with_sac=(False, True, True, True),\n",
            "            pretrained='open-mmlab://resnext101_32x4d',\n",
            "            style='pytorch')),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(\n",
            "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='CascadeRoIHead',\n",
            "        num_stages=3,\n",
            "        stage_loss_weights=[1, 0.5, 0.25],\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='GenericRoIExtractor',\n",
            "            aggregation='sum',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32],\n",
            "            pre_cfg=dict(\n",
            "                type='ConvModule',\n",
            "                in_channels=256,\n",
            "                out_channels=256,\n",
            "                kernel_size=5,\n",
            "                padding=2,\n",
            "                inplace=False),\n",
            "            post_cfg=dict(\n",
            "                type='GeneralizedAttention',\n",
            "                in_channels=256,\n",
            "                spatial_range=-1,\n",
            "                num_heads=6,\n",
            "                attention_type='0100',\n",
            "                kv_stride=2)),\n",
            "        bbox_head=[\n",
            "            dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=10,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
            "                               loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=10,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
            "                               loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=10,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
            "        ]))\n",
            "train_cfg = dict(\n",
            "    rpn=dict(\n",
            "        assigner=dict(\n",
            "            type='MaxIoUAssigner',\n",
            "            pos_iou_thr=0.7,\n",
            "            neg_iou_thr=0.3,\n",
            "            min_pos_iou=0.3,\n",
            "            match_low_quality=True,\n",
            "            ignore_iof_thr=-1),\n",
            "        sampler=dict(\n",
            "            type='RandomSampler',\n",
            "            num=256,\n",
            "            pos_fraction=0.5,\n",
            "            neg_pos_ub=-1,\n",
            "            add_gt_as_proposals=False),\n",
            "        allowed_border=0,\n",
            "        pos_weight=-1,\n",
            "        debug=False),\n",
            "    rpn_proposal=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=2000,\n",
            "        nms_post=2000,\n",
            "        max_num=2000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=[\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.6,\n",
            "                neg_iou_thr=0.6,\n",
            "                min_pos_iou=0.6,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.7,\n",
            "                min_pos_iou=0.7,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)\n",
            "    ])\n",
            "test_cfg = dict(\n",
            "    rpn=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=1000,\n",
            "        nms_post=1000,\n",
            "        max_num=1000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=dict(\n",
            "        score_thr=0.05,\n",
            "        nms=dict(type='nms', iou_threshold=0.5),\n",
            "        max_per_img=100))\n",
            "dataset_type = 'CustomDataset'\n",
            "data_root = 'data/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "albu_train_transforms = [\n",
            "    dict(\n",
            "        type='ShiftScaleRotate',\n",
            "        shift_limit=0.0625,\n",
            "        scale_limit=0.0,\n",
            "        rotate_limit=0,\n",
            "        interpolation=1,\n",
            "        p=0.5),\n",
            "    dict(\n",
            "        type='RandomBrightnessContrast',\n",
            "        brightness_limit=[0.1, 0.3],\n",
            "        contrast_limit=[0.1, 0.3],\n",
            "        p=0.2),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='RGBShift',\n",
            "                r_shift_limit=10,\n",
            "                g_shift_limit=10,\n",
            "                b_shift_limit=10,\n",
            "                p=1.0),\n",
            "            dict(\n",
            "                type='HueSaturationValue',\n",
            "                hue_shift_limit=20,\n",
            "                sat_shift_limit=30,\n",
            "                val_shift_limit=20,\n",
            "                p=1.0)\n",
            "        ],\n",
            "        p=0.1),\n",
            "    dict(type='JpegCompression', quality_lower=85, quality_upper=95, p=0.2),\n",
            "    dict(type='ChannelShuffle', p=0.1),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "        ],\n",
            "        p=0.1)\n",
            "]\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "    dict(\n",
            "        type='Resize',\n",
            "        multiscale_mode='range',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        keep_ratio=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(\n",
            "        type='Albu',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='ShiftScaleRotate',\n",
            "                shift_limit=0.0625,\n",
            "                scale_limit=0.0,\n",
            "                rotate_limit=0,\n",
            "                interpolation=1,\n",
            "                p=0.5),\n",
            "            dict(\n",
            "                type='RandomBrightnessContrast',\n",
            "                brightness_limit=[0.1, 0.3],\n",
            "                contrast_limit=[0.1, 0.3],\n",
            "                p=0.2),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='RGBShift',\n",
            "                        r_shift_limit=10,\n",
            "                        g_shift_limit=10,\n",
            "                        b_shift_limit=10,\n",
            "                        p=1.0),\n",
            "                    dict(\n",
            "                        type='HueSaturationValue',\n",
            "                        hue_shift_limit=20,\n",
            "                        sat_shift_limit=30,\n",
            "                        val_shift_limit=20,\n",
            "                        p=1.0)\n",
            "                ],\n",
            "                p=0.1),\n",
            "            dict(\n",
            "                type='JpegCompression',\n",
            "                quality_lower=85,\n",
            "                quality_upper=95,\n",
            "                p=0.2),\n",
            "            dict(type='ChannelShuffle', p=0.1),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                    dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                ],\n",
            "                p=0.1)\n",
            "        ],\n",
            "        bbox_params=dict(\n",
            "            type='BboxParams',\n",
            "            format='pascal_voc',\n",
            "            label_fields=['gt_labels'],\n",
            "            min_visibility=0.0,\n",
            "            filter_lost_elements=True),\n",
            "        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "        update_pad_shape=False,\n",
            "        skip_img_without_anno=True),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(\n",
            "        type='Collect',\n",
            "        keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "        meta_keys=('filename', 'ori_shape', 'img_shape', 'img_norm_cfg',\n",
            "                   'pad_shape', 'scale_factor'))\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        transforms=[\n",
            "            dict(type='Resize', multiscale_mode='range', keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=1.0),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=1,\n",
            "    workers_per_gpu=1,\n",
            "    train=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/train_80_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                type='Resize',\n",
            "                multiscale_mode='range',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                keep_ratio=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(\n",
            "                type='Albu',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='ShiftScaleRotate',\n",
            "                        shift_limit=0.0625,\n",
            "                        scale_limit=0.0,\n",
            "                        rotate_limit=0,\n",
            "                        interpolation=1,\n",
            "                        p=0.5),\n",
            "                    dict(\n",
            "                        type='RandomBrightnessContrast',\n",
            "                        brightness_limit=[0.1, 0.3],\n",
            "                        contrast_limit=[0.1, 0.3],\n",
            "                        p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(\n",
            "                                type='RGBShift',\n",
            "                                r_shift_limit=10,\n",
            "                                g_shift_limit=10,\n",
            "                                b_shift_limit=10,\n",
            "                                p=1.0),\n",
            "                            dict(\n",
            "                                type='HueSaturationValue',\n",
            "                                hue_shift_limit=20,\n",
            "                                sat_shift_limit=30,\n",
            "                                val_shift_limit=20,\n",
            "                                p=1.0)\n",
            "                        ],\n",
            "                        p=0.1),\n",
            "                    dict(\n",
            "                        type='JpegCompression',\n",
            "                        quality_lower=75,\n",
            "                        quality_upper=95,\n",
            "                        p=0.2),\n",
            "                    dict(type='ChannelShuffle', p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                        ],\n",
            "                        p=0.1)\n",
            "                ],\n",
            "                bbox_params=dict(\n",
            "                    type='BboxParams',\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=['gt_labels'],\n",
            "                    min_visibility=0.0,\n",
            "                    filter_lost_elements=True),\n",
            "                keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "                update_pad_shape=False,\n",
            "                skip_img_without_anno=True),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(\n",
            "                type='Collect',\n",
            "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "                meta_keys=('filename', 'ori_shape', 'img_shape',\n",
            "                           'img_norm_cfg', 'pad_shape', 'scale_factor'))\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/val_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/test_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 200), (1999, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "evaluation = dict(interval=1, metric='mAP')\n",
            "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.3333333333333333,\n",
            "    step=[8, 11])\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=64, hooks=[dict(type='TextLoggerHook')])\n",
            "total_epochs = 20\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "work_dir = './work_dirs/cascade_rcnn_x101_32x4d_fpn_1x'\n",
            "load_from = None\n",
            "resume_from = 'work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_17.pth'\n",
            "workflow = [('train', 1)]\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "2020-09-08 15:31:58,319 - mmdet - INFO - load model from: open-mmlab://resnext101_32x4d\n",
            "2020-09-08 15:31:58,853 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "2020-09-08 15:31:59,392 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
            "size mismatch for layer1.0.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.1.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.2.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.2.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
            "size mismatch for layer2.0.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.0.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.1.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.1.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.2.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.2.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.2.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.3.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.3.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.3.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
            "size mismatch for layer3.0.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.0.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.1.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.2.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.2.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.2.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.3.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.3.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.3.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.4.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.4.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.4.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.5.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.5.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.5.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.6.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.6.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.6.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.7.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.7.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.7.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.8.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.8.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.8.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.9.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.9.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.9.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.10.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.10.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.10.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.11.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.11.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.11.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.12.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.12.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.12.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.13.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.13.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.13.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.14.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.14.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.14.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.15.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.15.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.15.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.16.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.16.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.16.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.17.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.17.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.17.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.18.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.18.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.18.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.19.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.19.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.19.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.20.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.20.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.20.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.21.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.21.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.21.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.22.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.22.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.22.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
            "size mismatch for layer4.0.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.0.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.1.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.1.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.2.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.2.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.2.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-08 15:32:03,076 - mmdet - INFO - load checkpoint from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_17.pth\n",
            "2020-09-08 15:32:06,519 - mmdet - INFO - resumed epoch 17, iter 90644\n",
            "2020-09-08 15:32:06,525 - mmdet - INFO - Start running, host: root@956a6950658a, work_dir: /content/drive/My Drive/mmdetection-master/work_dirs/cascade_rcnn_x101_32x4d_fpn_1x\n",
            "2020-09-08 15:32:06,526 - mmdet - INFO - workflow: [('train', 1)], max: 20 epochs\n",
            "2020-09-08 15:34:21,033 - mmdet - INFO - Epoch [18][64/5332]\tlr: 1.000e-05, eta: 9:17:59, time: 2.101, data_time: 0.044, memory: 7868, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0229, s0.acc: 99.1791, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0138, s1.acc: 99.0112, s1.loss_bbox: 0.0223, s2.loss_cls: 0.0085, s2.acc: 98.7793, s2.loss_bbox: 0.0197, loss: 0.1104, grad_norm: 3.7373\n",
            "2020-09-08 15:36:34,173 - mmdet - INFO - Epoch [18][128/5332]\tlr: 1.000e-05, eta: 9:12:57, time: 2.080, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0213, s0.acc: 99.1272, s0.loss_bbox: 0.0150, s1.loss_cls: 0.0158, s1.acc: 98.7152, s1.loss_bbox: 0.0259, s2.loss_cls: 0.0102, s2.acc: 98.2361, s2.loss_bbox: 0.0215, loss: 0.1162, grad_norm: 4.1432\n",
            "2020-09-08 15:38:47,364 - mmdet - INFO - Epoch [18][192/5332]\tlr: 1.000e-05, eta: 9:09:52, time: 2.081, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0222, s0.acc: 99.0906, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0154, s1.acc: 98.8251, s1.loss_bbox: 0.0279, s2.loss_cls: 0.0107, s2.acc: 98.2788, s2.loss_bbox: 0.0194, loss: 0.1204, grad_norm: 4.3391\n",
            "2020-09-08 15:41:03,444 - mmdet - INFO - Epoch [18][256/5332]\tlr: 1.000e-05, eta: 9:10:10, time: 2.126, data_time: 0.005, memory: 7868, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0022, s0.loss_cls: 0.0242, s0.acc: 99.0631, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0182, s1.acc: 98.4680, s1.loss_bbox: 0.0222, s2.loss_cls: 0.0117, s2.acc: 97.9614, s2.loss_bbox: 0.0206, loss: 0.1181, grad_norm: 4.3317\n",
            "2020-09-08 15:43:16,536 - mmdet - INFO - Epoch [18][320/5332]\tlr: 1.000e-05, eta: 9:07:01, time: 2.080, data_time: 0.005, memory: 7868, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0240, s0.acc: 99.1608, s0.loss_bbox: 0.0161, s1.loss_cls: 0.0133, s1.acc: 98.9868, s1.loss_bbox: 0.0223, s2.loss_cls: 0.0075, s2.acc: 98.9594, s2.loss_bbox: 0.0184, loss: 0.1118, grad_norm: 4.0786\n",
            "2020-09-08 15:45:30,362 - mmdet - INFO - Epoch [18][384/5332]\tlr: 1.000e-05, eta: 9:04:40, time: 2.091, data_time: 0.005, memory: 7868, loss_rpn_cls: 0.0175, loss_rpn_bbox: 0.0061, s0.loss_cls: 0.0242, s0.acc: 99.0570, s0.loss_bbox: 0.0182, s1.loss_cls: 0.0154, s1.acc: 98.7793, s1.loss_bbox: 0.0321, s2.loss_cls: 0.0096, s2.acc: 98.4497, s2.loss_bbox: 0.0241, loss: 0.1472, grad_norm: 4.8602\n",
            "2020-09-08 15:47:44,990 - mmdet - INFO - Epoch [18][448/5332]\tlr: 1.000e-05, eta: 9:02:49, time: 2.104, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0253, s0.acc: 99.0814, s0.loss_bbox: 0.0195, s1.loss_cls: 0.0191, s1.acc: 98.7091, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0127, s2.acc: 97.9736, s2.loss_bbox: 0.0245, loss: 0.1404, grad_norm: 4.5441\n",
            "2020-09-08 15:49:58,786 - mmdet - INFO - Epoch [18][512/5332]\tlr: 1.000e-05, eta: 9:00:26, time: 2.091, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0242, s0.acc: 99.0326, s0.loss_bbox: 0.0177, s1.loss_cls: 0.0179, s1.acc: 98.4833, s1.loss_bbox: 0.0293, s2.loss_cls: 0.0114, s2.acc: 98.0652, s2.loss_bbox: 0.0235, loss: 0.1326, grad_norm: 4.8090\n",
            "2020-09-08 15:52:13,520 - mmdet - INFO - Epoch [18][576/5332]\tlr: 1.000e-05, eta: 8:58:31, time: 2.105, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0227, s0.acc: 99.1852, s0.loss_bbox: 0.0136, s1.loss_cls: 0.0136, s1.acc: 99.0479, s1.loss_bbox: 0.0204, s2.loss_cls: 0.0085, s2.acc: 98.8495, s2.loss_bbox: 0.0181, loss: 0.1050, grad_norm: 4.1558\n",
            "2020-09-08 15:54:29,655 - mmdet - INFO - Epoch [18][640/5332]\tlr: 1.000e-05, eta: 8:57:06, time: 2.127, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0031, s0.loss_cls: 0.0220, s0.acc: 99.1425, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0133, s1.acc: 98.8953, s1.loss_bbox: 0.0301, s2.loss_cls: 0.0102, s2.acc: 98.4009, s2.loss_bbox: 0.0272, loss: 0.1244, grad_norm: 4.4331\n",
            "2020-09-08 15:56:43,494 - mmdet - INFO - Epoch [18][704/5332]\tlr: 1.000e-05, eta: 8:54:41, time: 2.091, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0289, s0.acc: 98.8190, s0.loss_bbox: 0.0204, s1.loss_cls: 0.0173, s1.acc: 98.5352, s1.loss_bbox: 0.0318, s2.loss_cls: 0.0112, s2.acc: 97.9797, s2.loss_bbox: 0.0292, loss: 0.1475, grad_norm: 4.8218\n",
            "2020-09-08 15:58:57,047 - mmdet - INFO - Epoch [18][768/5332]\tlr: 1.000e-05, eta: 8:52:13, time: 2.087, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0257, s0.acc: 98.9319, s0.loss_bbox: 0.0141, s1.loss_cls: 0.0170, s1.acc: 98.6145, s1.loss_bbox: 0.0205, s2.loss_cls: 0.0111, s2.acc: 98.0530, s2.loss_bbox: 0.0178, loss: 0.1137, grad_norm: 4.3978\n",
            "2020-09-08 16:01:11,495 - mmdet - INFO - Epoch [18][832/5332]\tlr: 1.000e-05, eta: 8:50:03, time: 2.101, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0264, s0.acc: 98.9716, s0.loss_bbox: 0.0162, s1.loss_cls: 0.0180, s1.acc: 98.5352, s1.loss_bbox: 0.0322, s2.loss_cls: 0.0133, s2.acc: 97.8271, s2.loss_bbox: 0.0283, loss: 0.1424, grad_norm: 4.6088\n",
            "2020-09-08 16:03:27,878 - mmdet - INFO - Epoch [18][896/5332]\tlr: 1.000e-05, eta: 8:48:25, time: 2.131, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0221, s0.acc: 99.1516, s0.loss_bbox: 0.0149, s1.loss_cls: 0.0148, s1.acc: 98.7732, s1.loss_bbox: 0.0271, s2.loss_cls: 0.0109, s2.acc: 97.9828, s2.loss_bbox: 0.0227, loss: 0.1205, grad_norm: 4.1127\n",
            "2020-09-08 16:05:41,817 - mmdet - INFO - Epoch [18][960/5332]\tlr: 1.000e-05, eta: 8:46:04, time: 2.093, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0232, s0.acc: 99.1089, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0145, s1.acc: 98.9288, s1.loss_bbox: 0.0249, s2.loss_cls: 0.0096, s2.acc: 98.4711, s2.loss_bbox: 0.0240, loss: 0.1203, grad_norm: 4.0526\n",
            "2020-09-08 16:07:56,737 - mmdet - INFO - Epoch [18][1024/5332]\tlr: 1.000e-05, eta: 8:43:58, time: 2.108, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0270, s0.acc: 98.9685, s0.loss_bbox: 0.0177, s1.loss_cls: 0.0174, s1.acc: 98.6908, s1.loss_bbox: 0.0271, s2.loss_cls: 0.0111, s2.acc: 98.2758, s2.loss_bbox: 0.0230, loss: 0.1315, grad_norm: 4.6136\n",
            "2020-09-08 16:10:10,861 - mmdet - INFO - Epoch [18][1088/5332]\tlr: 1.000e-05, eta: 8:41:40, time: 2.096, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0217, s0.acc: 99.1211, s0.loss_bbox: 0.0159, s1.loss_cls: 0.0134, s1.acc: 98.9258, s1.loss_bbox: 0.0285, s2.loss_cls: 0.0087, s2.acc: 98.6633, s2.loss_bbox: 0.0275, loss: 0.1237, grad_norm: 4.6609\n",
            "2020-09-08 16:12:26,167 - mmdet - INFO - Epoch [18][1152/5332]\tlr: 1.000e-05, eta: 8:39:37, time: 2.114, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0234, s0.acc: 99.0479, s0.loss_bbox: 0.0169, s1.loss_cls: 0.0158, s1.acc: 98.6298, s1.loss_bbox: 0.0266, s2.loss_cls: 0.0107, s2.acc: 97.9828, s2.loss_bbox: 0.0225, loss: 0.1263, grad_norm: 4.1093\n",
            "2020-09-08 16:14:41,244 - mmdet - INFO - Epoch [18][1216/5332]\tlr: 1.000e-05, eta: 8:37:31, time: 2.111, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0223, s0.acc: 99.1638, s0.loss_bbox: 0.0206, s1.loss_cls: 0.0139, s1.acc: 98.8586, s1.loss_bbox: 0.0316, s2.loss_cls: 0.0087, s2.acc: 98.7061, s2.loss_bbox: 0.0290, loss: 0.1334, grad_norm: 4.8420\n",
            "2020-09-08 16:16:56,931 - mmdet - INFO - Epoch [18][1280/5332]\tlr: 1.000e-05, eta: 8:35:30, time: 2.120, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0210, s0.acc: 99.2004, s0.loss_bbox: 0.0162, s1.loss_cls: 0.0134, s1.acc: 99.0753, s1.loss_bbox: 0.0288, s2.loss_cls: 0.0085, s2.acc: 98.7488, s2.loss_bbox: 0.0230, loss: 0.1185, grad_norm: 4.1725\n",
            "2020-09-08 16:19:11,091 - mmdet - INFO - Epoch [18][1344/5332]\tlr: 1.000e-05, eta: 8:33:12, time: 2.096, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0208, s0.acc: 99.1394, s0.loss_bbox: 0.0152, s1.loss_cls: 0.0134, s1.acc: 98.9532, s1.loss_bbox: 0.0266, s2.loss_cls: 0.0097, s2.acc: 98.4680, s2.loss_bbox: 0.0230, loss: 0.1161, grad_norm: 4.4132\n",
            "2020-09-08 16:21:24,636 - mmdet - INFO - Epoch [18][1408/5332]\tlr: 1.000e-05, eta: 8:30:48, time: 2.087, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0280, s0.acc: 98.8068, s0.loss_bbox: 0.0203, s1.loss_cls: 0.0189, s1.acc: 98.3856, s1.loss_bbox: 0.0314, s2.loss_cls: 0.0118, s2.acc: 97.8943, s2.loss_bbox: 0.0271, loss: 0.1455, grad_norm: 5.3407\n",
            "2020-09-08 16:23:40,744 - mmdet - INFO - Epoch [18][1472/5332]\tlr: 1.000e-05, eta: 8:28:49, time: 2.127, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0062, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0230, s0.acc: 99.1394, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0148, s1.acc: 98.8190, s1.loss_bbox: 0.0314, s2.loss_cls: 0.0093, s2.acc: 98.3093, s2.loss_bbox: 0.0249, loss: 0.1321, grad_norm: 4.4724\n",
            "2020-09-08 16:25:55,499 - mmdet - INFO - Epoch [18][1536/5332]\tlr: 1.000e-05, eta: 8:26:37, time: 2.106, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0252, s0.acc: 98.9380, s0.loss_bbox: 0.0141, s1.loss_cls: 0.0165, s1.acc: 98.5748, s1.loss_bbox: 0.0233, s2.loss_cls: 0.0093, s2.acc: 98.5474, s2.loss_bbox: 0.0187, loss: 0.1152, grad_norm: 4.4439\n",
            "2020-09-08 16:28:08,804 - mmdet - INFO - Epoch [18][1600/5332]\tlr: 1.000e-05, eta: 8:24:11, time: 2.083, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0241, s0.acc: 98.9716, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0158, s1.acc: 98.6084, s1.loss_bbox: 0.0282, s2.loss_cls: 0.0092, s2.acc: 98.3826, s2.loss_bbox: 0.0224, loss: 0.1256, grad_norm: 4.4303\n",
            "2020-09-08 16:30:24,433 - mmdet - INFO - Epoch [18][1664/5332]\tlr: 1.000e-05, eta: 8:22:07, time: 2.119, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0236, s0.acc: 99.1119, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0141, s1.acc: 98.9349, s1.loss_bbox: 0.0281, s2.loss_cls: 0.0087, s2.acc: 98.6359, s2.loss_bbox: 0.0207, loss: 0.1227, grad_norm: 4.0466\n",
            "2020-09-08 16:32:39,511 - mmdet - INFO - Epoch [18][1728/5332]\tlr: 1.000e-05, eta: 8:19:57, time: 2.111, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0238, s0.acc: 98.9990, s0.loss_bbox: 0.0146, s1.loss_cls: 0.0134, s1.acc: 98.9380, s1.loss_bbox: 0.0291, s2.loss_cls: 0.0089, s2.acc: 98.6542, s2.loss_bbox: 0.0252, loss: 0.1247, grad_norm: 4.5451\n",
            "2020-09-08 16:34:54,328 - mmdet - INFO - Epoch [18][1792/5332]\tlr: 1.000e-05, eta: 8:17:44, time: 2.107, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0284, s0.acc: 98.9105, s0.loss_bbox: 0.0187, s1.loss_cls: 0.0189, s1.acc: 98.4711, s1.loss_bbox: 0.0303, s2.loss_cls: 0.0128, s2.acc: 97.7661, s2.loss_bbox: 0.0254, loss: 0.1439, grad_norm: 4.9009\n",
            "2020-09-08 16:37:09,037 - mmdet - INFO - Epoch [18][1856/5332]\tlr: 1.000e-05, eta: 8:15:31, time: 2.105, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0063, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0240, s0.acc: 99.0143, s0.loss_bbox: 0.0161, s1.loss_cls: 0.0167, s1.acc: 98.6664, s1.loss_bbox: 0.0263, s2.loss_cls: 0.0111, s2.acc: 98.1232, s2.loss_bbox: 0.0223, loss: 0.1275, grad_norm: 4.5641\n",
            "2020-09-08 16:39:24,599 - mmdet - INFO - Epoch [18][1920/5332]\tlr: 1.000e-05, eta: 8:13:23, time: 2.118, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0257, s0.acc: 98.9624, s0.loss_bbox: 0.0184, s1.loss_cls: 0.0166, s1.acc: 98.7091, s1.loss_bbox: 0.0313, s2.loss_cls: 0.0112, s2.acc: 98.1506, s2.loss_bbox: 0.0255, loss: 0.1360, grad_norm: 4.4769\n",
            "2020-09-08 16:41:40,218 - mmdet - INFO - Epoch [18][1984/5332]\tlr: 1.000e-05, eta: 8:11:16, time: 2.119, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0266, s0.acc: 99.0234, s0.loss_bbox: 0.0157, s1.loss_cls: 0.0170, s1.acc: 98.7518, s1.loss_bbox: 0.0276, s2.loss_cls: 0.0112, s2.acc: 98.2391, s2.loss_bbox: 0.0238, loss: 0.1277, grad_norm: 4.5170\n",
            "2020-09-08 16:43:55,062 - mmdet - INFO - Epoch [18][2048/5332]\tlr: 1.000e-05, eta: 8:09:03, time: 2.107, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0222, s0.acc: 99.1425, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0149, s1.acc: 98.8617, s1.loss_bbox: 0.0278, s2.loss_cls: 0.0099, s2.acc: 98.4802, s2.loss_bbox: 0.0194, loss: 0.1210, grad_norm: 4.2444\n",
            "2020-09-08 16:46:09,423 - mmdet - INFO - Epoch [18][2112/5332]\tlr: 1.000e-05, eta: 8:06:46, time: 2.099, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0184, s0.acc: 99.2950, s0.loss_bbox: 0.0115, s1.loss_cls: 0.0120, s1.acc: 99.1486, s1.loss_bbox: 0.0218, s2.loss_cls: 0.0076, s2.acc: 98.9380, s2.loss_bbox: 0.0216, loss: 0.0995, grad_norm: 3.9170\n",
            "2020-09-08 16:48:25,435 - mmdet - INFO - Epoch [18][2176/5332]\tlr: 1.000e-05, eta: 8:04:40, time: 2.125, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0256, s0.acc: 98.9197, s0.loss_bbox: 0.0149, s1.loss_cls: 0.0160, s1.acc: 98.6389, s1.loss_bbox: 0.0266, s2.loss_cls: 0.0102, s2.acc: 98.2025, s2.loss_bbox: 0.0227, loss: 0.1229, grad_norm: 4.7713\n",
            "2020-09-08 16:50:40,971 - mmdet - INFO - Epoch [18][2240/5332]\tlr: 1.000e-05, eta: 8:02:31, time: 2.118, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0222, s0.acc: 99.1943, s0.loss_bbox: 0.0149, s1.loss_cls: 0.0140, s1.acc: 98.9197, s1.loss_bbox: 0.0276, s2.loss_cls: 0.0081, s2.acc: 98.6206, s2.loss_bbox: 0.0236, loss: 0.1171, grad_norm: 4.0448\n",
            "2020-09-08 16:52:55,898 - mmdet - INFO - Epoch [18][2304/5332]\tlr: 1.000e-05, eta: 8:00:18, time: 2.108, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0229, s0.acc: 99.0448, s0.loss_bbox: 0.0146, s1.loss_cls: 0.0147, s1.acc: 98.6511, s1.loss_bbox: 0.0250, s2.loss_cls: 0.0095, s2.acc: 98.1659, s2.loss_bbox: 0.0226, loss: 0.1172, grad_norm: 4.4845\n",
            "2020-09-08 16:55:10,920 - mmdet - INFO - Epoch [18][2368/5332]\tlr: 1.000e-05, eta: 7:58:05, time: 2.110, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0064, s0.loss_cls: 0.0209, s0.acc: 99.1882, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0142, s1.acc: 98.8464, s1.loss_bbox: 0.0273, s2.loss_cls: 0.0105, s2.acc: 98.1812, s2.loss_bbox: 0.0222, loss: 0.1217, grad_norm: 4.3950\n",
            "2020-09-08 16:57:26,359 - mmdet - INFO - Epoch [18][2432/5332]\tlr: 1.000e-05, eta: 7:55:54, time: 2.116, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0234, s0.acc: 99.0814, s0.loss_bbox: 0.0164, s1.loss_cls: 0.0149, s1.acc: 98.8647, s1.loss_bbox: 0.0287, s2.loss_cls: 0.0097, s2.acc: 98.3429, s2.loss_bbox: 0.0257, loss: 0.1264, grad_norm: 4.7336\n",
            "2020-09-08 16:59:40,247 - mmdet - INFO - Epoch [18][2496/5332]\tlr: 1.000e-05, eta: 7:53:35, time: 2.092, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0195, s0.acc: 99.2279, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0125, s1.acc: 98.9594, s1.loss_bbox: 0.0330, s2.loss_cls: 0.0087, s2.acc: 98.5107, s2.loss_bbox: 0.0303, loss: 0.1277, grad_norm: 4.8278\n",
            "2020-09-08 17:01:52,368 - mmdet - INFO - Epoch [18][2560/5332]\tlr: 1.000e-05, eta: 7:51:07, time: 2.064, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0224, s0.acc: 99.0784, s0.loss_bbox: 0.0166, s1.loss_cls: 0.0147, s1.acc: 98.6786, s1.loss_bbox: 0.0319, s2.loss_cls: 0.0097, s2.acc: 98.4100, s2.loss_bbox: 0.0246, loss: 0.1280, grad_norm: 4.7206\n",
            "2020-09-08 17:04:07,596 - mmdet - INFO - Epoch [18][2624/5332]\tlr: 1.000e-05, eta: 7:48:55, time: 2.113, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0259, s0.acc: 98.9899, s0.loss_bbox: 0.0178, s1.loss_cls: 0.0157, s1.acc: 98.7427, s1.loss_bbox: 0.0273, s2.loss_cls: 0.0090, s2.acc: 98.5077, s2.loss_bbox: 0.0215, loss: 0.1261, grad_norm: 4.5855\n",
            "2020-09-08 17:06:23,694 - mmdet - INFO - Epoch [18][2688/5332]\tlr: 1.000e-05, eta: 7:46:47, time: 2.126, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0215, s0.acc: 99.1699, s0.loss_bbox: 0.0151, s1.loss_cls: 0.0146, s1.acc: 98.7518, s1.loss_bbox: 0.0270, s2.loss_cls: 0.0092, s2.acc: 98.6847, s2.loss_bbox: 0.0241, loss: 0.1204, grad_norm: 4.6478\n",
            "2020-09-08 17:08:38,043 - mmdet - INFO - Epoch [18][2752/5332]\tlr: 1.000e-05, eta: 7:44:31, time: 2.099, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0260, s0.acc: 98.9075, s0.loss_bbox: 0.0187, s1.loss_cls: 0.0175, s1.acc: 98.5748, s1.loss_bbox: 0.0299, s2.loss_cls: 0.0113, s2.acc: 97.8821, s2.loss_bbox: 0.0236, loss: 0.1329, grad_norm: 4.5098\n",
            "2020-09-08 17:10:51,707 - mmdet - INFO - Epoch [18][2816/5332]\tlr: 1.000e-05, eta: 7:42:12, time: 2.088, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0221, s0.acc: 99.0448, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0147, s1.acc: 98.7946, s1.loss_bbox: 0.0300, s2.loss_cls: 0.0099, s2.acc: 98.4894, s2.loss_bbox: 0.0220, loss: 0.1233, grad_norm: 4.5460\n",
            "2020-09-08 17:13:06,526 - mmdet - INFO - Epoch [18][2880/5332]\tlr: 1.000e-05, eta: 7:39:58, time: 2.107, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0061, loss_rpn_bbox: 0.0062, s0.loss_cls: 0.0242, s0.acc: 99.0234, s0.loss_bbox: 0.0181, s1.loss_cls: 0.0155, s1.acc: 98.7610, s1.loss_bbox: 0.0300, s2.loss_cls: 0.0097, s2.acc: 98.4283, s2.loss_bbox: 0.0253, loss: 0.1350, grad_norm: 4.4038\n",
            "2020-09-08 17:15:22,626 - mmdet - INFO - Epoch [18][2944/5332]\tlr: 1.000e-05, eta: 7:37:49, time: 2.127, data_time: 0.005, memory: 7868, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0242, s0.acc: 99.0601, s0.loss_bbox: 0.0166, s1.loss_cls: 0.0159, s1.acc: 98.7701, s1.loss_bbox: 0.0333, s2.loss_cls: 0.0100, s2.acc: 98.4161, s2.loss_bbox: 0.0302, loss: 0.1373, grad_norm: 4.8362\n",
            "2020-09-08 17:17:38,174 - mmdet - INFO - Epoch [18][3008/5332]\tlr: 1.000e-05, eta: 7:35:38, time: 2.118, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0222, s0.acc: 99.1180, s0.loss_bbox: 0.0149, s1.loss_cls: 0.0163, s1.acc: 98.8708, s1.loss_bbox: 0.0233, s2.loss_cls: 0.0107, s2.acc: 98.4222, s2.loss_bbox: 0.0178, loss: 0.1130, grad_norm: 4.0414\n",
            "2020-09-08 17:19:53,881 - mmdet - INFO - Epoch [18][3072/5332]\tlr: 1.000e-05, eta: 7:33:28, time: 2.120, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0025, s0.loss_cls: 0.0216, s0.acc: 99.0753, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0144, s1.acc: 98.7854, s1.loss_bbox: 0.0278, s2.loss_cls: 0.0090, s2.acc: 98.3734, s2.loss_bbox: 0.0241, loss: 0.1186, grad_norm: 4.2991\n",
            "2020-09-08 17:22:08,787 - mmdet - INFO - Epoch [18][3136/5332]\tlr: 1.000e-05, eta: 7:31:14, time: 2.108, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0062, loss_rpn_bbox: 0.0063, s0.loss_cls: 0.0269, s0.acc: 99.0143, s0.loss_bbox: 0.0190, s1.loss_cls: 0.0143, s1.acc: 98.9471, s1.loss_bbox: 0.0330, s2.loss_cls: 0.0082, s2.acc: 98.8953, s2.loss_bbox: 0.0312, loss: 0.1451, grad_norm: 4.8534\n",
            "2020-09-08 17:24:26,417 - mmdet - INFO - Epoch [18][3200/5332]\tlr: 1.000e-05, eta: 7:29:10, time: 2.150, data_time: 0.034, memory: 7868, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0221, s0.acc: 99.0997, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0146, s1.acc: 98.7701, s1.loss_bbox: 0.0300, s2.loss_cls: 0.0098, s2.acc: 98.3521, s2.loss_bbox: 0.0250, loss: 0.1248, grad_norm: 4.6745\n",
            "2020-09-08 17:26:39,022 - mmdet - INFO - Epoch [18][3264/5332]\tlr: 1.000e-05, eta: 7:26:47, time: 2.072, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0067, loss_rpn_bbox: 0.0082, s0.loss_cls: 0.0273, s0.acc: 98.9105, s0.loss_bbox: 0.0213, s1.loss_cls: 0.0169, s1.acc: 98.6481, s1.loss_bbox: 0.0346, s2.loss_cls: 0.0114, s2.acc: 98.1232, s2.loss_bbox: 0.0252, loss: 0.1515, grad_norm: 4.6412\n",
            "2020-09-08 17:28:51,850 - mmdet - INFO - Epoch [18][3328/5332]\tlr: 1.000e-05, eta: 7:24:25, time: 2.075, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0208, s0.acc: 99.1364, s0.loss_bbox: 0.0157, s1.loss_cls: 0.0138, s1.acc: 98.9807, s1.loss_bbox: 0.0293, s2.loss_cls: 0.0090, s2.acc: 98.5687, s2.loss_bbox: 0.0243, loss: 0.1220, grad_norm: 4.2269\n",
            "2020-09-08 17:31:07,842 - mmdet - INFO - Epoch [18][3392/5332]\tlr: 1.000e-05, eta: 7:22:15, time: 2.125, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0213, s0.acc: 99.1821, s0.loss_bbox: 0.0161, s1.loss_cls: 0.0142, s1.acc: 98.8831, s1.loss_bbox: 0.0279, s2.loss_cls: 0.0092, s2.acc: 98.6847, s2.loss_bbox: 0.0253, loss: 0.1222, grad_norm: 4.1494\n",
            "2020-09-08 17:33:22,979 - mmdet - INFO - Epoch [18][3456/5332]\tlr: 1.000e-05, eta: 7:20:02, time: 2.112, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0091, s0.loss_cls: 0.0280, s0.acc: 98.8708, s0.loss_bbox: 0.0221, s1.loss_cls: 0.0168, s1.acc: 98.7335, s1.loss_bbox: 0.0297, s2.loss_cls: 0.0105, s2.acc: 98.2239, s2.loss_bbox: 0.0250, loss: 0.1476, grad_norm: 4.7373\n",
            "2020-09-08 17:35:36,486 - mmdet - INFO - Epoch [18][3520/5332]\tlr: 1.000e-05, eta: 7:17:43, time: 2.086, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0256, s0.acc: 99.0631, s0.loss_bbox: 0.0182, s1.loss_cls: 0.0159, s1.acc: 98.8037, s1.loss_bbox: 0.0316, s2.loss_cls: 0.0122, s2.acc: 98.2391, s2.loss_bbox: 0.0267, loss: 0.1384, grad_norm: 4.4927\n",
            "2020-09-08 17:37:50,327 - mmdet - INFO - Epoch [18][3584/5332]\tlr: 1.000e-05, eta: 7:15:25, time: 2.091, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0247, s0.acc: 99.0417, s0.loss_bbox: 0.0161, s1.loss_cls: 0.0158, s1.acc: 98.8464, s1.loss_bbox: 0.0263, s2.loss_cls: 0.0110, s2.acc: 98.1964, s2.loss_bbox: 0.0237, loss: 0.1261, grad_norm: 4.6666\n",
            "2020-09-08 17:40:06,559 - mmdet - INFO - Epoch [18][3648/5332]\tlr: 1.000e-05, eta: 7:13:15, time: 2.129, data_time: 0.005, memory: 7868, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0282, s0.acc: 98.9441, s0.loss_bbox: 0.0205, s1.loss_cls: 0.0181, s1.acc: 98.5901, s1.loss_bbox: 0.0335, s2.loss_cls: 0.0118, s2.acc: 98.1262, s2.loss_bbox: 0.0265, loss: 0.1484, grad_norm: 5.0588\n",
            "2020-09-08 17:42:21,382 - mmdet - INFO - Epoch [18][3712/5332]\tlr: 1.000e-05, eta: 7:11:01, time: 2.107, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0259, s0.acc: 99.0082, s0.loss_bbox: 0.0189, s1.loss_cls: 0.0166, s1.acc: 98.7000, s1.loss_bbox: 0.0281, s2.loss_cls: 0.0094, s2.acc: 98.5168, s2.loss_bbox: 0.0228, loss: 0.1307, grad_norm: 4.3284\n",
            "2020-09-08 17:44:35,110 - mmdet - INFO - Epoch [18][3776/5332]\tlr: 1.000e-05, eta: 7:08:43, time: 2.089, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0228, s0.acc: 99.1791, s0.loss_bbox: 0.0152, s1.loss_cls: 0.0145, s1.acc: 99.0082, s1.loss_bbox: 0.0229, s2.loss_cls: 0.0088, s2.acc: 98.5565, s2.loss_bbox: 0.0174, loss: 0.1084, grad_norm: 3.7257\n",
            "2020-09-08 17:46:49,978 - mmdet - INFO - Epoch [18][3840/5332]\tlr: 1.000e-05, eta: 7:06:29, time: 2.107, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0258, s0.acc: 99.0448, s0.loss_bbox: 0.0199, s1.loss_cls: 0.0172, s1.acc: 98.6420, s1.loss_bbox: 0.0315, s2.loss_cls: 0.0109, s2.acc: 98.4253, s2.loss_bbox: 0.0253, loss: 0.1385, grad_norm: 5.1807\n",
            "2020-09-08 17:49:04,502 - mmdet - INFO - Epoch [18][3904/5332]\tlr: 1.000e-05, eta: 7:04:13, time: 2.102, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0196, s0.acc: 99.2004, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0134, s1.acc: 98.9044, s1.loss_bbox: 0.0269, s2.loss_cls: 0.0083, s2.acc: 98.5748, s2.loss_bbox: 0.0223, loss: 0.1167, grad_norm: 4.1669\n",
            "2020-09-08 17:51:20,699 - mmdet - INFO - Epoch [18][3968/5332]\tlr: 1.000e-05, eta: 7:02:03, time: 2.128, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0225, s0.acc: 99.1089, s0.loss_bbox: 0.0188, s1.loss_cls: 0.0155, s1.acc: 98.7091, s1.loss_bbox: 0.0305, s2.loss_cls: 0.0098, s2.acc: 98.2208, s2.loss_bbox: 0.0265, loss: 0.1352, grad_norm: 4.4631\n",
            "2020-09-08 17:53:36,749 - mmdet - INFO - Epoch [18][4032/5332]\tlr: 1.000e-05, eta: 6:59:52, time: 2.126, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0205, s0.acc: 99.1760, s0.loss_bbox: 0.0137, s1.loss_cls: 0.0128, s1.acc: 98.8983, s1.loss_bbox: 0.0242, s2.loss_cls: 0.0081, s2.acc: 98.6176, s2.loss_bbox: 0.0218, loss: 0.1065, grad_norm: 4.4958\n",
            "2020-09-08 17:55:52,018 - mmdet - INFO - Epoch [18][4096/5332]\tlr: 1.000e-05, eta: 6:57:39, time: 2.114, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0189, s0.acc: 99.2493, s0.loss_bbox: 0.0127, s1.loss_cls: 0.0128, s1.acc: 99.0204, s1.loss_bbox: 0.0215, s2.loss_cls: 0.0077, s2.acc: 98.8129, s2.loss_bbox: 0.0198, loss: 0.1004, grad_norm: 4.1115\n",
            "2020-09-08 17:58:06,825 - mmdet - INFO - Epoch [18][4160/5332]\tlr: 1.000e-05, eta: 6:55:24, time: 2.106, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0211, s0.acc: 99.1577, s0.loss_bbox: 0.0151, s1.loss_cls: 0.0140, s1.acc: 98.8617, s1.loss_bbox: 0.0260, s2.loss_cls: 0.0089, s2.acc: 98.5260, s2.loss_bbox: 0.0227, loss: 0.1137, grad_norm: 4.5877\n",
            "2020-09-08 18:00:19,015 - mmdet - INFO - Epoch [18][4224/5332]\tlr: 1.000e-05, eta: 6:53:02, time: 2.065, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0259, s0.acc: 98.9319, s0.loss_bbox: 0.0199, s1.loss_cls: 0.0158, s1.acc: 98.5168, s1.loss_bbox: 0.0304, s2.loss_cls: 0.0104, s2.acc: 98.1567, s2.loss_bbox: 0.0237, loss: 0.1334, grad_norm: 4.7842\n",
            "2020-09-08 18:02:34,488 - mmdet - INFO - Epoch [18][4288/5332]\tlr: 1.000e-05, eta: 6:50:49, time: 2.117, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0078, loss_rpn_bbox: 0.0063, s0.loss_cls: 0.0248, s0.acc: 99.0387, s0.loss_bbox: 0.0136, s1.loss_cls: 0.0176, s1.acc: 98.7762, s1.loss_bbox: 0.0228, s2.loss_cls: 0.0106, s2.acc: 98.6115, s2.loss_bbox: 0.0217, loss: 0.1253, grad_norm: 5.2632\n",
            "2020-09-08 18:04:48,451 - mmdet - INFO - Epoch [18][4352/5332]\tlr: 1.000e-05, eta: 6:48:33, time: 2.093, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0232, s0.acc: 99.0173, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0165, s1.acc: 98.6267, s1.loss_bbox: 0.0351, s2.loss_cls: 0.0101, s2.acc: 98.1201, s2.loss_bbox: 0.0291, loss: 0.1410, grad_norm: 4.8525\n",
            "2020-09-08 18:07:03,800 - mmdet - INFO - Epoch [18][4416/5332]\tlr: 1.000e-05, eta: 6:46:19, time: 2.115, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0266, s0.acc: 98.9227, s0.loss_bbox: 0.0160, s1.loss_cls: 0.0180, s1.acc: 98.5138, s1.loss_bbox: 0.0260, s2.loss_cls: 0.0109, s2.acc: 97.9706, s2.loss_bbox: 0.0195, loss: 0.1247, grad_norm: 4.7463\n",
            "2020-09-08 18:09:18,756 - mmdet - INFO - Epoch [18][4480/5332]\tlr: 1.000e-05, eta: 6:44:05, time: 2.109, data_time: 0.005, memory: 7868, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0065, s0.loss_cls: 0.0212, s0.acc: 99.1364, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0127, s1.acc: 99.0356, s1.loss_bbox: 0.0255, s2.loss_cls: 0.0089, s2.acc: 98.5535, s2.loss_bbox: 0.0191, loss: 0.1152, grad_norm: 3.7144\n",
            "2020-09-08 18:11:33,407 - mmdet - INFO - Epoch [18][4544/5332]\tlr: 1.000e-05, eta: 6:41:50, time: 2.104, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0269, s0.acc: 98.8586, s0.loss_bbox: 0.0185, s1.loss_cls: 0.0169, s1.acc: 98.5718, s1.loss_bbox: 0.0314, s2.loss_cls: 0.0106, s2.acc: 98.3307, s2.loss_bbox: 0.0242, loss: 0.1352, grad_norm: 4.9708\n",
            "2020-09-08 18:13:47,290 - mmdet - INFO - Epoch [18][4608/5332]\tlr: 1.000e-05, eta: 6:39:33, time: 2.092, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0231, s0.acc: 99.0845, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0165, s1.acc: 98.6786, s1.loss_bbox: 0.0269, s2.loss_cls: 0.0106, s2.acc: 98.1659, s2.loss_bbox: 0.0242, loss: 0.1242, grad_norm: 4.8404\n",
            "2020-09-08 18:16:00,310 - mmdet - INFO - Epoch [18][4672/5332]\tlr: 1.000e-05, eta: 6:37:15, time: 2.078, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0247, s0.acc: 99.0540, s0.loss_bbox: 0.0188, s1.loss_cls: 0.0148, s1.acc: 98.8831, s1.loss_bbox: 0.0255, s2.loss_cls: 0.0097, s2.acc: 98.5077, s2.loss_bbox: 0.0201, loss: 0.1190, grad_norm: 4.3878\n",
            "2020-09-08 18:18:13,910 - mmdet - INFO - Epoch [18][4736/5332]\tlr: 1.000e-05, eta: 6:34:57, time: 2.087, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0257, s0.acc: 98.9532, s0.loss_bbox: 0.0157, s1.loss_cls: 0.0167, s1.acc: 98.6481, s1.loss_bbox: 0.0250, s2.loss_cls: 0.0101, s2.acc: 98.2971, s2.loss_bbox: 0.0199, loss: 0.1246, grad_norm: 4.7385\n",
            "2020-09-08 18:20:28,489 - mmdet - INFO - Epoch [18][4800/5332]\tlr: 1.000e-05, eta: 6:32:42, time: 2.103, data_time: 0.005, memory: 7868, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0226, s0.acc: 99.0479, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0147, s1.acc: 98.8892, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0101, s2.acc: 98.4009, s2.loss_bbox: 0.0256, loss: 0.1240, grad_norm: 4.4381\n",
            "2020-09-08 18:22:42,936 - mmdet - INFO - Epoch [18][4864/5332]\tlr: 1.000e-05, eta: 6:30:27, time: 2.101, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0099, loss_rpn_bbox: 0.0070, s0.loss_cls: 0.0317, s0.acc: 98.8037, s0.loss_bbox: 0.0212, s1.loss_cls: 0.0173, s1.acc: 98.7244, s1.loss_bbox: 0.0327, s2.loss_cls: 0.0103, s2.acc: 98.3673, s2.loss_bbox: 0.0270, loss: 0.1570, grad_norm: 4.9532\n",
            "2020-09-08 18:24:55,256 - mmdet - INFO - Epoch [18][4928/5332]\tlr: 1.000e-05, eta: 6:28:07, time: 2.068, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0209, s0.acc: 99.2126, s0.loss_bbox: 0.0150, s1.loss_cls: 0.0148, s1.acc: 98.8037, s1.loss_bbox: 0.0261, s2.loss_cls: 0.0092, s2.acc: 98.4222, s2.loss_bbox: 0.0205, loss: 0.1156, grad_norm: 4.2823\n",
            "2020-09-08 18:27:09,600 - mmdet - INFO - Epoch [18][4992/5332]\tlr: 1.000e-05, eta: 6:25:52, time: 2.099, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0249, s0.acc: 99.0082, s0.loss_bbox: 0.0193, s1.loss_cls: 0.0149, s1.acc: 98.8312, s1.loss_bbox: 0.0294, s2.loss_cls: 0.0098, s2.acc: 98.3856, s2.loss_bbox: 0.0234, loss: 0.1285, grad_norm: 4.4261\n",
            "2020-09-08 18:29:25,823 - mmdet - INFO - Epoch [18][5056/5332]\tlr: 1.000e-05, eta: 6:23:40, time: 2.128, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0240, s0.acc: 99.0234, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0152, s1.acc: 98.7885, s1.loss_bbox: 0.0284, s2.loss_cls: 0.0097, s2.acc: 98.4406, s2.loss_bbox: 0.0242, loss: 0.1292, grad_norm: 4.9361\n",
            "2020-09-08 18:31:39,448 - mmdet - INFO - Epoch [18][5120/5332]\tlr: 1.000e-05, eta: 6:21:23, time: 2.088, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0071, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0329, s0.acc: 98.8068, s0.loss_bbox: 0.0226, s1.loss_cls: 0.0207, s1.acc: 98.5382, s1.loss_bbox: 0.0324, s2.loss_cls: 0.0137, s2.acc: 97.9126, s2.loss_bbox: 0.0253, loss: 0.1590, grad_norm: 5.0957\n",
            "2020-09-08 18:33:54,054 - mmdet - INFO - Epoch [18][5184/5332]\tlr: 1.000e-05, eta: 6:19:09, time: 2.103, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0254, s0.acc: 98.9655, s0.loss_bbox: 0.0190, s1.loss_cls: 0.0157, s1.acc: 98.8007, s1.loss_bbox: 0.0309, s2.loss_cls: 0.0090, s2.acc: 98.5687, s2.loss_bbox: 0.0277, loss: 0.1370, grad_norm: 4.6759\n",
            "2020-09-08 18:36:07,779 - mmdet - INFO - Epoch [18][5248/5332]\tlr: 1.000e-05, eta: 6:16:52, time: 2.089, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0072, s0.loss_cls: 0.0240, s0.acc: 99.0692, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0159, s1.acc: 98.6511, s1.loss_bbox: 0.0299, s2.loss_cls: 0.0109, s2.acc: 98.1140, s2.loss_bbox: 0.0225, loss: 0.1313, grad_norm: 4.6270\n",
            "2020-09-08 18:38:21,927 - mmdet - INFO - Epoch [18][5312/5332]\tlr: 1.000e-05, eta: 6:14:36, time: 2.096, data_time: 0.004, memory: 7868, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0072, s0.loss_cls: 0.0259, s0.acc: 98.9532, s0.loss_bbox: 0.0194, s1.loss_cls: 0.0170, s1.acc: 98.6481, s1.loss_bbox: 0.0330, s2.loss_cls: 0.0107, s2.acc: 98.1262, s2.loss_bbox: 0.0288, loss: 0.1458, grad_norm: 4.8470\n",
            "2020-09-08 18:39:04,192 - mmdet - INFO - Saving checkpoint at 18 epochs\n",
            "[>>] 667/667, 0.5 task/s, elapsed: 1215s, ETA:     0s2020-09-08 18:59:27,261 - mmdet - INFO - \n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 82  | 230  | 0.841  | 0.575 |\n",
            "| 3     | 22  | 93   | 0.727  | 0.636 |\n",
            "| 4     | 529 | 1158 | 0.924  | 0.831 |\n",
            "| 5     | 78  | 169  | 0.897  | 0.800 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.710 |\n",
            "+-------+-----+------+--------+-------+\n",
            "2020-09-08 18:59:27,265 - mmdet - INFO - Epoch(val) [18][5332]\tmAP: 0.7104\n",
            "2020-09-08 19:01:45,071 - mmdet - INFO - Epoch [19][64/5332]\tlr: 1.000e-05, eta: 6:10:23, time: 2.153, data_time: 0.037, memory: 7868, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0248, s0.acc: 99.0417, s0.loss_bbox: 0.0171, s1.loss_cls: 0.0167, s1.acc: 98.6603, s1.loss_bbox: 0.0289, s2.loss_cls: 0.0108, s2.acc: 98.1537, s2.loss_bbox: 0.0236, loss: 0.1321, grad_norm: 4.7792\n",
            "Process Process-7:\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f51cbc440e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/local/lib/python3.7/threading.py\", line 1044, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/local/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCP-WgQGK11k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28389e43-73a8-460f-9445-724363ecad05"
      },
      "source": [
        "!python tools/train.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py --resume-from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_18.pth"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-09 04:44:26,401 - mmdet - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.7.6 (default, Jan  8 2020, 19:59:22) [GCC 7.3.0]\n",
            "CUDA available: True\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
            "GPU 0: Tesla P100-PCIE-16GB\n",
            "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "PyTorch: 1.4.0\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CUDA Runtime 10.0\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.1\n",
            "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "TorchVision: 0.5.0\n",
            "OpenCV: 4.4.0\n",
            "MMCV: 1.1.2\n",
            "MMDetection: 2.3.0+\n",
            "MMDetection Compiler: GCC 7.5\n",
            "MMDetection CUDA Compiler: 10.1\n",
            "------------------------------------------------------------\n",
            "\n",
            "2020-09-09 04:44:27,233 - mmdet - INFO - Distributed training: False\n",
            "2020-09-09 04:44:28,093 - mmdet - INFO - Config:\n",
            "model = dict(\n",
            "    type='CascadeRCNN',\n",
            "    pretrained='open-mmlab://resnext101_32x4d',\n",
            "    backbone=dict(\n",
            "        type='DetectoRS_ResNeXt',\n",
            "        depth=101,\n",
            "        groups=32,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=True,\n",
            "        style='pytorch',\n",
            "        conv_cfg=dict(type='ConvAWS'),\n",
            "        sac=dict(type='SAC', use_deform=True),\n",
            "        stage_with_sac=(False, True, True, True),\n",
            "        output_img=True),\n",
            "    neck=dict(\n",
            "        type='RFP',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5,\n",
            "        rfp_steps=2,\n",
            "        aspp_out_channels=64,\n",
            "        aspp_dilations=(1, 3, 6, 1),\n",
            "        rfp_backbone=dict(\n",
            "            rfp_inplanes=256,\n",
            "            type='DetectoRS_ResNeXt',\n",
            "            depth=101,\n",
            "            num_stages=4,\n",
            "            out_indices=(0, 1, 2, 3),\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(type='BN', requires_grad=True),\n",
            "            norm_eval=True,\n",
            "            conv_cfg=dict(type='ConvAWS'),\n",
            "            sac=dict(type='SAC', use_deform=True),\n",
            "            stage_with_sac=(False, True, True, True),\n",
            "            pretrained='open-mmlab://resnext101_32x4d',\n",
            "            style='pytorch')),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(\n",
            "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='CascadeRoIHead',\n",
            "        num_stages=3,\n",
            "        stage_loss_weights=[1, 0.5, 0.25],\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='GenericRoIExtractor',\n",
            "            aggregation='sum',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32],\n",
            "            pre_cfg=dict(\n",
            "                type='ConvModule',\n",
            "                in_channels=256,\n",
            "                out_channels=256,\n",
            "                kernel_size=5,\n",
            "                padding=2,\n",
            "                inplace=False),\n",
            "            post_cfg=dict(\n",
            "                type='GeneralizedAttention',\n",
            "                in_channels=256,\n",
            "                spatial_range=-1,\n",
            "                num_heads=6,\n",
            "                attention_type='0100',\n",
            "                kv_stride=2)),\n",
            "        bbox_head=[\n",
            "            dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=10,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
            "                               loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=10,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
            "                               loss_weight=1.0)),\n",
            "            dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=10,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
            "        ]))\n",
            "train_cfg = dict(\n",
            "    rpn=dict(\n",
            "        assigner=dict(\n",
            "            type='MaxIoUAssigner',\n",
            "            pos_iou_thr=0.7,\n",
            "            neg_iou_thr=0.3,\n",
            "            min_pos_iou=0.3,\n",
            "            match_low_quality=True,\n",
            "            ignore_iof_thr=-1),\n",
            "        sampler=dict(\n",
            "            type='RandomSampler',\n",
            "            num=256,\n",
            "            pos_fraction=0.5,\n",
            "            neg_pos_ub=-1,\n",
            "            add_gt_as_proposals=False),\n",
            "        allowed_border=0,\n",
            "        pos_weight=-1,\n",
            "        debug=False),\n",
            "    rpn_proposal=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=2000,\n",
            "        nms_post=2000,\n",
            "        max_num=2000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=[\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.6,\n",
            "                neg_iou_thr=0.6,\n",
            "                min_pos_iou=0.6,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.7,\n",
            "                min_pos_iou=0.7,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)\n",
            "    ])\n",
            "test_cfg = dict(\n",
            "    rpn=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=1000,\n",
            "        nms_post=1000,\n",
            "        max_num=1000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=dict(\n",
            "        score_thr=0.05,\n",
            "        nms=dict(type='nms', iou_threshold=0.5),\n",
            "        max_per_img=100))\n",
            "dataset_type = 'CustomDataset'\n",
            "data_root = 'data/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "albu_train_transforms = [\n",
            "    dict(\n",
            "        type='ShiftScaleRotate',\n",
            "        shift_limit=0.0625,\n",
            "        scale_limit=0.0,\n",
            "        rotate_limit=0,\n",
            "        interpolation=1,\n",
            "        p=0.5),\n",
            "    dict(\n",
            "        type='RandomBrightnessContrast',\n",
            "        brightness_limit=[0.1, 0.3],\n",
            "        contrast_limit=[0.1, 0.3],\n",
            "        p=0.2),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='RGBShift',\n",
            "                r_shift_limit=10,\n",
            "                g_shift_limit=10,\n",
            "                b_shift_limit=10,\n",
            "                p=1.0),\n",
            "            dict(\n",
            "                type='HueSaturationValue',\n",
            "                hue_shift_limit=20,\n",
            "                sat_shift_limit=30,\n",
            "                val_shift_limit=20,\n",
            "                p=1.0)\n",
            "        ],\n",
            "        p=0.1),\n",
            "    dict(type='JpegCompression', quality_lower=85, quality_upper=95, p=0.2),\n",
            "    dict(type='ChannelShuffle', p=0.1),\n",
            "    dict(\n",
            "        type='OneOf',\n",
            "        transforms=[\n",
            "            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "        ],\n",
            "        p=0.1)\n",
            "]\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "    dict(\n",
            "        type='Resize',\n",
            "        multiscale_mode='range',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        keep_ratio=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(\n",
            "        type='Albu',\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='ShiftScaleRotate',\n",
            "                shift_limit=0.0625,\n",
            "                scale_limit=0.0,\n",
            "                rotate_limit=0,\n",
            "                interpolation=1,\n",
            "                p=0.5),\n",
            "            dict(\n",
            "                type='RandomBrightnessContrast',\n",
            "                brightness_limit=[0.1, 0.3],\n",
            "                contrast_limit=[0.1, 0.3],\n",
            "                p=0.2),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='RGBShift',\n",
            "                        r_shift_limit=10,\n",
            "                        g_shift_limit=10,\n",
            "                        b_shift_limit=10,\n",
            "                        p=1.0),\n",
            "                    dict(\n",
            "                        type='HueSaturationValue',\n",
            "                        hue_shift_limit=20,\n",
            "                        sat_shift_limit=30,\n",
            "                        val_shift_limit=20,\n",
            "                        p=1.0)\n",
            "                ],\n",
            "                p=0.1),\n",
            "            dict(\n",
            "                type='JpegCompression',\n",
            "                quality_lower=85,\n",
            "                quality_upper=95,\n",
            "                p=0.2),\n",
            "            dict(type='ChannelShuffle', p=0.1),\n",
            "            dict(\n",
            "                type='OneOf',\n",
            "                transforms=[\n",
            "                    dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                    dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                ],\n",
            "                p=0.1)\n",
            "        ],\n",
            "        bbox_params=dict(\n",
            "            type='BboxParams',\n",
            "            format='pascal_voc',\n",
            "            label_fields=['gt_labels'],\n",
            "            min_visibility=0.0,\n",
            "            filter_lost_elements=True),\n",
            "        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "        update_pad_shape=False,\n",
            "        skip_img_without_anno=True),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(\n",
            "        type='Collect',\n",
            "        keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "        meta_keys=('filename', 'ori_shape', 'img_shape', 'img_norm_cfg',\n",
            "                   'pad_shape', 'scale_factor'))\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=[(1333, 800), (1333, 1200)],\n",
            "        transforms=[\n",
            "            dict(type='Resize', multiscale_mode='range', keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=1.0),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=1,\n",
            "    workers_per_gpu=1,\n",
            "    train=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/train_80_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "            dict(\n",
            "                type='Resize',\n",
            "                multiscale_mode='range',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                keep_ratio=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(\n",
            "                type='Albu',\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='ShiftScaleRotate',\n",
            "                        shift_limit=0.0625,\n",
            "                        scale_limit=0.0,\n",
            "                        rotate_limit=0,\n",
            "                        interpolation=1,\n",
            "                        p=0.5),\n",
            "                    dict(\n",
            "                        type='RandomBrightnessContrast',\n",
            "                        brightness_limit=[0.1, 0.3],\n",
            "                        contrast_limit=[0.1, 0.3],\n",
            "                        p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(\n",
            "                                type='RGBShift',\n",
            "                                r_shift_limit=10,\n",
            "                                g_shift_limit=10,\n",
            "                                b_shift_limit=10,\n",
            "                                p=1.0),\n",
            "                            dict(\n",
            "                                type='HueSaturationValue',\n",
            "                                hue_shift_limit=20,\n",
            "                                sat_shift_limit=30,\n",
            "                                val_shift_limit=20,\n",
            "                                p=1.0)\n",
            "                        ],\n",
            "                        p=0.1),\n",
            "                    dict(\n",
            "                        type='JpegCompression',\n",
            "                        quality_lower=75,\n",
            "                        quality_upper=95,\n",
            "                        p=0.2),\n",
            "                    dict(type='ChannelShuffle', p=0.2),\n",
            "                    dict(\n",
            "                        type='OneOf',\n",
            "                        transforms=[\n",
            "                            dict(type='Blur', blur_limit=3, p=1.0),\n",
            "                            dict(type='MedianBlur', blur_limit=3, p=1.0)\n",
            "                        ],\n",
            "                        p=0.1)\n",
            "                ],\n",
            "                bbox_params=dict(\n",
            "                    type='BboxParams',\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=['gt_labels'],\n",
            "                    min_visibility=0.0,\n",
            "                    filter_lost_elements=True),\n",
            "                keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
            "                update_pad_shape=False,\n",
            "                skip_img_without_anno=True),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(\n",
            "                type='Collect',\n",
            "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'],\n",
            "                meta_keys=('filename', 'ori_shape', 'img_shape',\n",
            "                           'img_norm_cfg', 'pad_shape', 'scale_factor'))\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/val_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 800), (1666, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='CustomDataset',\n",
            "        ann_file='data/test_10_mmdetection.pkl',\n",
            "        img_prefix='data/train/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=[(1333, 200), (1999, 1000)],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='Resize',\n",
            "                        multiscale_mode='range',\n",
            "                        keep_ratio=True),\n",
            "                    dict(type='RandomFlip', flip_ratio=1.0),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "evaluation = dict(interval=1, metric='mAP')\n",
            "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.3333333333333333,\n",
            "    step=[8, 11])\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=64, hooks=[dict(type='TextLoggerHook')])\n",
            "total_epochs = 20\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "work_dir = './work_dirs/cascade_rcnn_x101_32x4d_fpn_1x'\n",
            "load_from = None\n",
            "resume_from = 'work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_18.pth'\n",
            "workflow = [('train', 1)]\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "2020-09-09 04:44:33,113 - mmdet - INFO - load model from: open-mmlab://resnext101_32x4d\n",
            "Downloading: \"https://openmmlab.oss-accelerate.aliyuncs.com/pretrain/third_party/resnext101_32x4d-a5af3160.pth\" to /root/.cache/torch/checkpoints/resnext101_32x4d-a5af3160.pth\n",
            "100% 161M/161M [00:06<00:00, 26.4MB/s]\n",
            "2020-09-09 04:44:40,692 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "2020-09-09 04:44:41,263 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
            "size mismatch for layer1.0.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.0.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.1.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.1.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer1.2.conv1.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
            "size mismatch for layer1.2.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv2.weight: copying a param with shape torch.Size([128, 4, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
            "size mismatch for layer1.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "size mismatch for layer1.2.conv3.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n",
            "size mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
            "size mismatch for layer2.0.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.0.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.0.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.1.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.1.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.1.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.2.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.2.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.2.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.2.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer2.3.conv1.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
            "size mismatch for layer2.3.bn1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv2.weight: copying a param with shape torch.Size([256, 8, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
            "size mismatch for layer2.3.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "size mismatch for layer2.3.conv3.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 1, 1]).\n",
            "size mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
            "size mismatch for layer3.0.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.0.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.0.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.1.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.1.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.2.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.2.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.2.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.2.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.3.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.3.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.3.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.3.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.4.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.4.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.4.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.4.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.5.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.5.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.5.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.5.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.6.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.6.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.6.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.6.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.7.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.7.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.7.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.7.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.8.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.8.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.8.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.8.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.9.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.9.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.9.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.9.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.10.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.10.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.10.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.10.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.11.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.11.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.11.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.11.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.12.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.12.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.12.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.12.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.13.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.13.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.13.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.13.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.14.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.14.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.14.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.14.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.15.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.15.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.15.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.15.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.16.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.16.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.16.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.16.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.17.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.17.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.17.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.17.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.18.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.18.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.18.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.18.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.19.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.19.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.19.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.19.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.20.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.20.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.20.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.20.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.21.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.21.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.21.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.21.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer3.22.conv1.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
            "size mismatch for layer3.22.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv2.weight: copying a param with shape torch.Size([512, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n",
            "size mismatch for layer3.22.bn2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.bn2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "size mismatch for layer3.22.conv3.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 256, 1, 1]).\n",
            "size mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([1024, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
            "size mismatch for layer4.0.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.0.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.0.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.1.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.1.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.1.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "size mismatch for layer4.2.conv1.weight: copying a param with shape torch.Size([1024, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
            "size mismatch for layer4.2.bn1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv2.weight: copying a param with shape torch.Size([1024, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n",
            "size mismatch for layer4.2.bn2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.bn2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "size mismatch for layer4.2.conv3.weight: copying a param with shape torch.Size([2048, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1, 1]).\n",
            "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
            "\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2020-09-09 04:44:47,141 - mmdet - INFO - load checkpoint from work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_18.pth\n",
            "2020-09-09 04:45:10,322 - mmdet - INFO - resumed epoch 18, iter 95976\n",
            "2020-09-09 04:45:10,333 - mmdet - INFO - Start running, host: root@0de708cffc46, work_dir: /content/drive/My Drive/mmdetection-master/work_dirs/cascade_rcnn_x101_32x4d_fpn_1x\n",
            "2020-09-09 04:45:10,333 - mmdet - INFO - workflow: [('train', 1)], max: 20 epochs\n",
            "2020-09-09 04:47:28,843 - mmdet - INFO - Epoch [19][64/5332]\tlr: 1.000e-05, eta: 6:22:18, time: 2.164, data_time: 0.053, memory: 8778, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0233, s0.acc: 99.0295, s0.loss_bbox: 0.0157, s1.loss_cls: 0.0142, s1.acc: 98.8831, s1.loss_bbox: 0.0249, s2.loss_cls: 0.0091, s2.acc: 98.5565, s2.loss_bbox: 0.0211, loss: 0.1156, grad_norm: 4.1241\n",
            "2020-09-09 04:49:39,272 - mmdet - INFO - Epoch [19][128/5332]\tlr: 1.000e-05, eta: 6:08:55, time: 2.038, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0225, s0.acc: 99.1364, s0.loss_bbox: 0.0161, s1.loss_cls: 0.0142, s1.acc: 98.9349, s1.loss_bbox: 0.0271, s2.loss_cls: 0.0092, s2.acc: 98.5107, s2.loss_bbox: 0.0247, loss: 0.1199, grad_norm: 4.5621\n",
            "2020-09-09 04:51:52,058 - mmdet - INFO - Epoch [19][192/5332]\tlr: 1.000e-05, eta: 6:05:09, time: 2.075, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0228, s0.acc: 99.1333, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0149, s1.acc: 98.8800, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0098, s2.acc: 98.4924, s2.loss_bbox: 0.0282, loss: 0.1297, grad_norm: 4.5733\n",
            "2020-09-09 04:54:04,619 - mmdet - INFO - Epoch [19][256/5332]\tlr: 1.000e-05, eta: 6:02:01, time: 2.071, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0257, s0.acc: 98.9746, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0155, s1.acc: 98.7549, s1.loss_bbox: 0.0306, s2.loss_cls: 0.0091, s2.acc: 98.4100, s2.loss_bbox: 0.0267, loss: 0.1340, grad_norm: 4.7734\n",
            "2020-09-09 04:56:17,500 - mmdet - INFO - Epoch [19][320/5332]\tlr: 1.000e-05, eta: 5:59:25, time: 2.076, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0230, s0.acc: 99.0875, s0.loss_bbox: 0.0164, s1.loss_cls: 0.0152, s1.acc: 98.8831, s1.loss_bbox: 0.0308, s2.loss_cls: 0.0097, s2.acc: 98.4863, s2.loss_bbox: 0.0219, loss: 0.1274, grad_norm: 4.3453\n",
            "2020-09-09 04:58:30,719 - mmdet - INFO - Epoch [19][384/5332]\tlr: 1.000e-05, eta: 5:57:06, time: 2.082, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0201, s0.acc: 99.2371, s0.loss_bbox: 0.0151, s1.loss_cls: 0.0125, s1.acc: 99.0509, s1.loss_bbox: 0.0297, s2.loss_cls: 0.0098, s2.acc: 98.2880, s2.loss_bbox: 0.0237, loss: 0.1189, grad_norm: 4.4055\n",
            "2020-09-09 05:00:44,162 - mmdet - INFO - Epoch [19][448/5332]\tlr: 1.000e-05, eta: 5:54:54, time: 2.085, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0222, s0.acc: 99.1028, s0.loss_bbox: 0.0170, s1.loss_cls: 0.0156, s1.acc: 98.7274, s1.loss_bbox: 0.0319, s2.loss_cls: 0.0103, s2.acc: 98.0988, s2.loss_bbox: 0.0286, loss: 0.1347, grad_norm: 4.8241\n",
            "2020-09-09 05:02:54,916 - mmdet - INFO - Epoch [19][512/5332]\tlr: 1.000e-05, eta: 5:51:48, time: 2.043, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0227, s0.acc: 99.0387, s0.loss_bbox: 0.0200, s1.loss_cls: 0.0144, s1.acc: 98.8434, s1.loss_bbox: 0.0321, s2.loss_cls: 0.0093, s2.acc: 98.5352, s2.loss_bbox: 0.0244, loss: 0.1311, grad_norm: 4.4103\n",
            "2020-09-09 05:05:06,112 - mmdet - INFO - Epoch [19][576/5332]\tlr: 1.000e-05, eta: 5:49:02, time: 2.050, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0255, s0.acc: 98.9197, s0.loss_bbox: 0.0169, s1.loss_cls: 0.0150, s1.acc: 98.7457, s1.loss_bbox: 0.0282, s2.loss_cls: 0.0102, s2.acc: 98.0835, s2.loss_bbox: 0.0239, loss: 0.1271, grad_norm: 4.7936\n",
            "2020-09-09 05:07:18,318 - mmdet - INFO - Epoch [19][640/5332]\tlr: 1.000e-05, eta: 5:46:39, time: 2.066, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0062, s0.loss_cls: 0.0271, s0.acc: 98.9471, s0.loss_bbox: 0.0209, s1.loss_cls: 0.0181, s1.acc: 98.5413, s1.loss_bbox: 0.0330, s2.loss_cls: 0.0114, s2.acc: 98.1323, s2.loss_bbox: 0.0289, loss: 0.1495, grad_norm: 5.3256\n",
            "2020-09-09 05:09:29,284 - mmdet - INFO - Epoch [19][704/5332]\tlr: 1.000e-05, eta: 5:44:00, time: 2.046, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0243, s0.acc: 99.0906, s0.loss_bbox: 0.0178, s1.loss_cls: 0.0152, s1.acc: 98.7640, s1.loss_bbox: 0.0277, s2.loss_cls: 0.0081, s2.acc: 98.7549, s2.loss_bbox: 0.0212, loss: 0.1228, grad_norm: 4.0760\n",
            "2020-09-09 05:11:42,063 - mmdet - INFO - Epoch [19][768/5332]\tlr: 1.000e-05, eta: 5:41:49, time: 2.075, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0176, s0.acc: 99.3835, s0.loss_bbox: 0.0138, s1.loss_cls: 0.0109, s1.acc: 99.2065, s1.loss_bbox: 0.0259, s2.loss_cls: 0.0072, s2.acc: 98.7976, s2.loss_bbox: 0.0220, loss: 0.1069, grad_norm: 3.9653\n",
            "2020-09-09 05:13:54,735 - mmdet - INFO - Epoch [19][832/5332]\tlr: 1.000e-05, eta: 5:39:37, time: 2.073, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0219, s0.acc: 99.1791, s0.loss_bbox: 0.0174, s1.loss_cls: 0.0146, s1.acc: 98.8068, s1.loss_bbox: 0.0276, s2.loss_cls: 0.0096, s2.acc: 98.3490, s2.loss_bbox: 0.0241, loss: 0.1239, grad_norm: 4.2763\n",
            "2020-09-09 05:16:06,802 - mmdet - INFO - Epoch [19][896/5332]\tlr: 1.000e-05, eta: 5:37:18, time: 2.064, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0066, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0292, s0.acc: 98.9105, s0.loss_bbox: 0.0194, s1.loss_cls: 0.0196, s1.acc: 98.5718, s1.loss_bbox: 0.0337, s2.loss_cls: 0.0115, s2.acc: 98.1934, s2.loss_bbox: 0.0266, loss: 0.1522, grad_norm: 4.9762\n",
            "2020-09-09 05:18:19,476 - mmdet - INFO - Epoch [19][960/5332]\tlr: 1.000e-05, eta: 5:35:06, time: 2.073, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0185, s0.acc: 99.2249, s0.loss_bbox: 0.0132, s1.loss_cls: 0.0120, s1.acc: 99.0936, s1.loss_bbox: 0.0234, s2.loss_cls: 0.0079, s2.acc: 98.7244, s2.loss_bbox: 0.0228, loss: 0.1036, grad_norm: 4.1276\n",
            "2020-09-09 05:20:32,766 - mmdet - INFO - Epoch [19][1024/5332]\tlr: 1.000e-05, eta: 5:33:00, time: 2.083, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0062, s0.loss_cls: 0.0296, s0.acc: 98.8861, s0.loss_bbox: 0.0198, s1.loss_cls: 0.0185, s1.acc: 98.6694, s1.loss_bbox: 0.0299, s2.loss_cls: 0.0115, s2.acc: 98.4131, s2.loss_bbox: 0.0256, loss: 0.1466, grad_norm: 4.9440\n",
            "2020-09-09 05:22:44,393 - mmdet - INFO - Epoch [19][1088/5332]\tlr: 1.000e-05, eta: 5:30:38, time: 2.057, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0060, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0296, s0.acc: 98.8678, s0.loss_bbox: 0.0211, s1.loss_cls: 0.0183, s1.acc: 98.5901, s1.loss_bbox: 0.0340, s2.loss_cls: 0.0113, s2.acc: 98.2361, s2.loss_bbox: 0.0238, loss: 0.1499, grad_norm: 4.3673\n",
            "2020-09-09 05:24:55,740 - mmdet - INFO - Epoch [19][1152/5332]\tlr: 1.000e-05, eta: 5:28:15, time: 2.052, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0060, s0.loss_cls: 0.0257, s0.acc: 99.0112, s0.loss_bbox: 0.0239, s1.loss_cls: 0.0184, s1.acc: 98.5870, s1.loss_bbox: 0.0334, s2.loss_cls: 0.0102, s2.acc: 98.3490, s2.loss_bbox: 0.0267, loss: 0.1484, grad_norm: 4.6152\n",
            "2020-09-09 05:27:08,926 - mmdet - INFO - Epoch [19][1216/5332]\tlr: 1.000e-05, eta: 5:26:08, time: 2.081, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0073, s0.loss_cls: 0.0300, s0.acc: 98.8373, s0.loss_bbox: 0.0220, s1.loss_cls: 0.0205, s1.acc: 98.2910, s1.loss_bbox: 0.0371, s2.loss_cls: 0.0130, s2.acc: 97.7753, s2.loss_bbox: 0.0260, loss: 0.1610, grad_norm: 4.8526\n",
            "2020-09-09 05:29:23,228 - mmdet - INFO - Epoch [19][1280/5332]\tlr: 1.000e-05, eta: 5:24:08, time: 2.098, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0258, s0.acc: 98.9075, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0177, s1.acc: 98.6786, s1.loss_bbox: 0.0269, s2.loss_cls: 0.0120, s2.acc: 98.0835, s2.loss_bbox: 0.0215, loss: 0.1281, grad_norm: 3.9155\n",
            "2020-09-09 05:31:36,737 - mmdet - INFO - Epoch [19][1344/5332]\tlr: 1.000e-05, eta: 5:22:02, time: 2.086, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0210, s0.acc: 99.1852, s0.loss_bbox: 0.0137, s1.loss_cls: 0.0139, s1.acc: 98.9288, s1.loss_bbox: 0.0240, s2.loss_cls: 0.0098, s2.acc: 98.1049, s2.loss_bbox: 0.0213, loss: 0.1099, grad_norm: 4.5778\n",
            "2020-09-09 05:33:48,927 - mmdet - INFO - Epoch [19][1408/5332]\tlr: 1.000e-05, eta: 5:19:46, time: 2.065, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0234, s0.acc: 99.0753, s0.loss_bbox: 0.0161, s1.loss_cls: 0.0151, s1.acc: 98.8403, s1.loss_bbox: 0.0284, s2.loss_cls: 0.0096, s2.acc: 98.4283, s2.loss_bbox: 0.0245, loss: 0.1268, grad_norm: 4.7532\n",
            "2020-09-09 05:36:00,357 - mmdet - INFO - Epoch [19][1472/5332]\tlr: 1.000e-05, eta: 5:17:25, time: 2.054, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0066, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0226, s0.acc: 99.1455, s0.loss_bbox: 0.0147, s1.loss_cls: 0.0148, s1.acc: 98.9716, s1.loss_bbox: 0.0251, s2.loss_cls: 0.0092, s2.acc: 98.4833, s2.loss_bbox: 0.0215, loss: 0.1198, grad_norm: 4.3908\n",
            "2020-09-09 05:38:28,963 - mmdet - INFO - Epoch [19][1536/5332]\tlr: 1.000e-05, eta: 5:16:48, time: 2.322, data_time: 0.237, memory: 8778, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0207, s0.acc: 99.1974, s0.loss_bbox: 0.0159, s1.loss_cls: 0.0144, s1.acc: 98.7885, s1.loss_bbox: 0.0275, s2.loss_cls: 0.0088, s2.acc: 98.7427, s2.loss_bbox: 0.0250, loss: 0.1206, grad_norm: 4.0973\n",
            "2020-09-09 05:40:39,666 - mmdet - INFO - Epoch [19][1600/5332]\tlr: 1.000e-05, eta: 5:14:20, time: 2.042, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0204, s0.acc: 99.1974, s0.loss_bbox: 0.0146, s1.loss_cls: 0.0138, s1.acc: 98.9319, s1.loss_bbox: 0.0277, s2.loss_cls: 0.0094, s2.acc: 98.4283, s2.loss_bbox: 0.0230, loss: 0.1164, grad_norm: 4.1848\n",
            "2020-09-09 05:42:52,902 - mmdet - INFO - Epoch [19][1664/5332]\tlr: 1.000e-05, eta: 5:12:07, time: 2.082, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0277, s0.acc: 98.9258, s0.loss_bbox: 0.0195, s1.loss_cls: 0.0173, s1.acc: 98.7610, s1.loss_bbox: 0.0314, s2.loss_cls: 0.0096, s2.acc: 98.5046, s2.loss_bbox: 0.0278, loss: 0.1403, grad_norm: 4.7474\n",
            "2020-09-09 05:45:06,938 - mmdet - INFO - Epoch [19][1728/5332]\tlr: 1.000e-05, eta: 5:09:58, time: 2.094, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0028, s0.loss_cls: 0.0287, s0.acc: 98.8464, s0.loss_bbox: 0.0194, s1.loss_cls: 0.0177, s1.acc: 98.4100, s1.loss_bbox: 0.0320, s2.loss_cls: 0.0114, s2.acc: 98.0286, s2.loss_bbox: 0.0238, loss: 0.1398, grad_norm: 4.6333\n",
            "2020-09-09 05:47:19,456 - mmdet - INFO - Epoch [19][1792/5332]\tlr: 1.000e-05, eta: 5:07:42, time: 2.071, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0246, s0.acc: 99.0479, s0.loss_bbox: 0.0153, s1.loss_cls: 0.0161, s1.acc: 98.8098, s1.loss_bbox: 0.0256, s2.loss_cls: 0.0103, s2.acc: 98.5413, s2.loss_bbox: 0.0223, loss: 0.1198, grad_norm: 4.4431\n",
            "2020-09-09 05:49:31,617 - mmdet - INFO - Epoch [19][1856/5332]\tlr: 1.000e-05, eta: 5:05:24, time: 2.065, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0252, s0.acc: 99.0387, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0163, s1.acc: 98.7152, s1.loss_bbox: 0.0225, s2.loss_cls: 0.0096, s2.acc: 98.4009, s2.loss_bbox: 0.0187, loss: 0.1150, grad_norm: 4.2741\n",
            "2020-09-09 05:51:45,845 - mmdet - INFO - Epoch [19][1920/5332]\tlr: 1.000e-05, eta: 5:03:16, time: 2.097, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0065, s0.loss_cls: 0.0319, s0.acc: 98.7640, s0.loss_bbox: 0.0171, s1.loss_cls: 0.0197, s1.acc: 98.5992, s1.loss_bbox: 0.0285, s2.loss_cls: 0.0117, s2.acc: 98.4131, s2.loss_bbox: 0.0246, loss: 0.1453, grad_norm: 4.8266\n",
            "2020-09-09 05:53:59,279 - mmdet - INFO - Epoch [19][1984/5332]\tlr: 1.000e-05, eta: 5:01:04, time: 2.085, data_time: 0.016, memory: 8778, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0223, s0.acc: 99.0723, s0.loss_bbox: 0.0152, s1.loss_cls: 0.0171, s1.acc: 98.4955, s1.loss_bbox: 0.0243, s2.loss_cls: 0.0113, s2.acc: 97.8699, s2.loss_bbox: 0.0223, loss: 0.1186, grad_norm: 4.5980\n",
            "2020-09-09 05:56:12,106 - mmdet - INFO - Epoch [19][2048/5332]\tlr: 1.000e-05, eta: 4:58:49, time: 2.075, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0232, s0.acc: 99.1455, s0.loss_bbox: 0.0150, s1.loss_cls: 0.0179, s1.acc: 98.5779, s1.loss_bbox: 0.0254, s2.loss_cls: 0.0114, s2.acc: 97.8485, s2.loss_bbox: 0.0207, loss: 0.1218, grad_norm: 4.2268\n",
            "2020-09-09 05:58:25,130 - mmdet - INFO - Epoch [19][2112/5332]\tlr: 1.000e-05, eta: 4:56:35, time: 2.078, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0262, s0.acc: 98.9410, s0.loss_bbox: 0.0174, s1.loss_cls: 0.0172, s1.acc: 98.5870, s1.loss_bbox: 0.0299, s2.loss_cls: 0.0106, s2.acc: 98.1812, s2.loss_bbox: 0.0276, loss: 0.1347, grad_norm: 4.6804\n",
            "2020-09-09 06:00:37,072 - mmdet - INFO - Epoch [19][2176/5332]\tlr: 1.000e-05, eta: 4:54:17, time: 2.062, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0239, s0.acc: 99.0570, s0.loss_bbox: 0.0177, s1.loss_cls: 0.0154, s1.acc: 98.7885, s1.loss_bbox: 0.0302, s2.loss_cls: 0.0114, s2.acc: 98.2788, s2.loss_bbox: 0.0251, loss: 0.1312, grad_norm: 4.3071\n",
            "2020-09-09 06:02:50,226 - mmdet - INFO - Epoch [19][2240/5332]\tlr: 1.000e-05, eta: 4:52:04, time: 2.081, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0214, s0.acc: 99.2096, s0.loss_bbox: 0.0160, s1.loss_cls: 0.0145, s1.acc: 98.9380, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0090, s2.acc: 98.6481, s2.loss_bbox: 0.0245, loss: 0.1200, grad_norm: 4.5801\n",
            "2020-09-09 06:05:01,910 - mmdet - INFO - Epoch [19][2304/5332]\tlr: 1.000e-05, eta: 4:49:45, time: 2.058, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0224, s0.acc: 99.0906, s0.loss_bbox: 0.0182, s1.loss_cls: 0.0163, s1.acc: 98.6664, s1.loss_bbox: 0.0269, s2.loss_cls: 0.0105, s2.acc: 98.2269, s2.loss_bbox: 0.0213, loss: 0.1239, grad_norm: 4.4323\n",
            "2020-09-09 06:07:15,930 - mmdet - INFO - Epoch [19][2368/5332]\tlr: 1.000e-05, eta: 4:47:36, time: 2.094, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0240, s0.acc: 99.0906, s0.loss_bbox: 0.0178, s1.loss_cls: 0.0143, s1.acc: 98.8495, s1.loss_bbox: 0.0334, s2.loss_cls: 0.0102, s2.acc: 98.3215, s2.loss_bbox: 0.0295, loss: 0.1365, grad_norm: 4.8360\n",
            "2020-09-09 06:09:27,581 - mmdet - INFO - Epoch [19][2432/5332]\tlr: 1.000e-05, eta: 4:45:18, time: 2.057, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0072, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0281, s0.acc: 98.8251, s0.loss_bbox: 0.0198, s1.loss_cls: 0.0177, s1.acc: 98.5535, s1.loss_bbox: 0.0302, s2.loss_cls: 0.0111, s2.acc: 98.1171, s2.loss_bbox: 0.0239, loss: 0.1420, grad_norm: 4.8482\n",
            "2020-09-09 06:11:43,361 - mmdet - INFO - Epoch [19][2496/5332]\tlr: 1.000e-05, eta: 4:43:13, time: 2.122, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0067, s0.loss_cls: 0.0272, s0.acc: 98.8251, s0.loss_bbox: 0.0206, s1.loss_cls: 0.0178, s1.acc: 98.5443, s1.loss_bbox: 0.0300, s2.loss_cls: 0.0111, s2.acc: 98.2849, s2.loss_bbox: 0.0209, loss: 0.1393, grad_norm: 4.7408\n",
            "2020-09-09 06:13:54,888 - mmdet - INFO - Epoch [19][2560/5332]\tlr: 1.000e-05, eta: 4:40:55, time: 2.055, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0247, s0.acc: 99.0387, s0.loss_bbox: 0.0176, s1.loss_cls: 0.0170, s1.acc: 98.6542, s1.loss_bbox: 0.0280, s2.loss_cls: 0.0120, s2.acc: 97.8821, s2.loss_bbox: 0.0231, loss: 0.1295, grad_norm: 4.6410\n",
            "2020-09-09 06:16:06,898 - mmdet - INFO - Epoch [19][2624/5332]\tlr: 1.000e-05, eta: 4:38:38, time: 2.063, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0184, s0.acc: 99.2737, s0.loss_bbox: 0.0128, s1.loss_cls: 0.0113, s1.acc: 99.1791, s1.loss_bbox: 0.0247, s2.loss_cls: 0.0069, s2.acc: 99.0875, s2.loss_bbox: 0.0258, loss: 0.1074, grad_norm: 4.2920\n",
            "2020-09-09 06:18:19,390 - mmdet - INFO - Epoch [19][2688/5332]\tlr: 1.000e-05, eta: 4:36:24, time: 2.070, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0279, s0.acc: 98.8678, s0.loss_bbox: 0.0185, s1.loss_cls: 0.0186, s1.acc: 98.5565, s1.loss_bbox: 0.0321, s2.loss_cls: 0.0110, s2.acc: 98.2635, s2.loss_bbox: 0.0248, loss: 0.1431, grad_norm: 4.7360\n",
            "2020-09-09 06:20:33,244 - mmdet - INFO - Epoch [19][2752/5332]\tlr: 1.000e-05, eta: 4:34:13, time: 2.091, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0220, s0.acc: 99.1028, s0.loss_bbox: 0.0178, s1.loss_cls: 0.0148, s1.acc: 98.7976, s1.loss_bbox: 0.0292, s2.loss_cls: 0.0099, s2.acc: 98.2117, s2.loss_bbox: 0.0227, loss: 0.1245, grad_norm: 4.6883\n",
            "2020-09-09 06:22:47,010 - mmdet - INFO - Epoch [19][2816/5332]\tlr: 1.000e-05, eta: 4:32:02, time: 2.090, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0213, s0.acc: 99.1791, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0126, s1.acc: 99.0021, s1.loss_bbox: 0.0295, s2.loss_cls: 0.0079, s2.acc: 98.8708, s2.loss_bbox: 0.0258, loss: 0.1218, grad_norm: 4.0214\n",
            "2020-09-09 06:25:02,685 - mmdet - INFO - Epoch [19][2880/5332]\tlr: 1.000e-05, eta: 4:29:55, time: 2.120, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0251, s0.acc: 99.0448, s0.loss_bbox: 0.0197, s1.loss_cls: 0.0151, s1.acc: 98.7885, s1.loss_bbox: 0.0300, s2.loss_cls: 0.0088, s2.acc: 98.5687, s2.loss_bbox: 0.0247, loss: 0.1329, grad_norm: 4.5485\n",
            "2020-09-09 06:27:16,069 - mmdet - INFO - Epoch [19][2944/5332]\tlr: 1.000e-05, eta: 4:27:43, time: 2.084, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0247, s0.acc: 98.9624, s0.loss_bbox: 0.0169, s1.loss_cls: 0.0169, s1.acc: 98.4985, s1.loss_bbox: 0.0288, s2.loss_cls: 0.0109, s2.acc: 98.2758, s2.loss_bbox: 0.0229, loss: 0.1309, grad_norm: 4.8353\n",
            "2020-09-09 06:29:26,865 - mmdet - INFO - Epoch [19][3008/5332]\tlr: 1.000e-05, eta: 4:25:24, time: 2.044, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0245, s0.acc: 99.0234, s0.loss_bbox: 0.0171, s1.loss_cls: 0.0146, s1.acc: 98.8861, s1.loss_bbox: 0.0341, s2.loss_cls: 0.0110, s2.acc: 97.9950, s2.loss_bbox: 0.0279, loss: 0.1361, grad_norm: 4.6943\n",
            "2020-09-09 06:31:38,733 - mmdet - INFO - Epoch [19][3072/5332]\tlr: 1.000e-05, eta: 4:23:07, time: 2.060, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0259, s0.acc: 98.9594, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0156, s1.acc: 98.8220, s1.loss_bbox: 0.0265, s2.loss_cls: 0.0105, s2.acc: 98.3368, s2.loss_bbox: 0.0222, loss: 0.1259, grad_norm: 4.6150\n",
            "2020-09-09 06:33:49,647 - mmdet - INFO - Epoch [19][3136/5332]\tlr: 1.000e-05, eta: 4:20:49, time: 2.046, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0063, loss_rpn_bbox: 0.0073, s0.loss_cls: 0.0252, s0.acc: 99.0631, s0.loss_bbox: 0.0181, s1.loss_cls: 0.0171, s1.acc: 98.7488, s1.loss_bbox: 0.0269, s2.loss_cls: 0.0096, s2.acc: 98.5718, s2.loss_bbox: 0.0189, loss: 0.1295, grad_norm: 4.3696\n",
            "2020-09-09 06:36:02,958 - mmdet - INFO - Epoch [19][3200/5332]\tlr: 1.000e-05, eta: 4:18:37, time: 2.083, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0201, s0.acc: 99.2004, s0.loss_bbox: 0.0149, s1.loss_cls: 0.0145, s1.acc: 98.8190, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0096, s2.acc: 98.2330, s2.loss_bbox: 0.0244, loss: 0.1206, grad_norm: 4.6207\n",
            "2020-09-09 06:38:15,670 - mmdet - INFO - Epoch [19][3264/5332]\tlr: 1.000e-05, eta: 4:16:23, time: 2.074, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0203, s0.acc: 99.2279, s0.loss_bbox: 0.0145, s1.loss_cls: 0.0127, s1.acc: 99.0936, s1.loss_bbox: 0.0266, s2.loss_cls: 0.0095, s2.acc: 98.5138, s2.loss_bbox: 0.0240, loss: 0.1150, grad_norm: 4.1125\n",
            "2020-09-09 06:40:28,664 - mmdet - INFO - Epoch [19][3328/5332]\tlr: 1.000e-05, eta: 4:14:10, time: 2.078, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0193, s0.acc: 99.2371, s0.loss_bbox: 0.0137, s1.loss_cls: 0.0126, s1.acc: 99.0997, s1.loss_bbox: 0.0240, s2.loss_cls: 0.0082, s2.acc: 98.7366, s2.loss_bbox: 0.0217, loss: 0.1061, grad_norm: 3.9113\n",
            "2020-09-09 06:42:40,976 - mmdet - INFO - Epoch [19][3392/5332]\tlr: 1.000e-05, eta: 4:11:55, time: 2.067, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0065, s0.loss_cls: 0.0223, s0.acc: 99.1425, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0124, s1.acc: 99.0997, s1.loss_bbox: 0.0267, s2.loss_cls: 0.0080, s2.acc: 98.8464, s2.loss_bbox: 0.0210, loss: 0.1171, grad_norm: 4.1626\n",
            "2020-09-09 06:44:51,139 - mmdet - INFO - Epoch [19][3456/5332]\tlr: 1.000e-05, eta: 4:09:36, time: 2.034, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0218, s0.acc: 99.1333, s0.loss_bbox: 0.0161, s1.loss_cls: 0.0141, s1.acc: 98.7549, s1.loss_bbox: 0.0264, s2.loss_cls: 0.0096, s2.acc: 98.2635, s2.loss_bbox: 0.0223, loss: 0.1170, grad_norm: 4.3752\n",
            "2020-09-09 06:47:04,524 - mmdet - INFO - Epoch [19][3520/5332]\tlr: 1.000e-05, eta: 4:07:24, time: 2.084, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0026, s0.loss_cls: 0.0219, s0.acc: 99.1669, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0115, s1.acc: 99.1974, s1.loss_bbox: 0.0295, s2.loss_cls: 0.0071, s2.acc: 98.9655, s2.loss_bbox: 0.0258, loss: 0.1167, grad_norm: 4.0836\n",
            "2020-09-09 06:49:16,494 - mmdet - INFO - Epoch [19][3584/5332]\tlr: 1.000e-05, eta: 4:05:09, time: 2.062, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0047, s0.loss_cls: 0.0202, s0.acc: 99.1638, s0.loss_bbox: 0.0145, s1.loss_cls: 0.0133, s1.acc: 98.8281, s1.loss_bbox: 0.0260, s2.loss_cls: 0.0097, s2.acc: 98.2880, s2.loss_bbox: 0.0192, loss: 0.1098, grad_norm: 4.1111\n",
            "2020-09-09 06:51:29,498 - mmdet - INFO - Epoch [19][3648/5332]\tlr: 1.000e-05, eta: 4:02:56, time: 2.078, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0257, s0.acc: 98.9166, s0.loss_bbox: 0.0183, s1.loss_cls: 0.0195, s1.acc: 98.3948, s1.loss_bbox: 0.0301, s2.loss_cls: 0.0126, s2.acc: 97.9431, s2.loss_bbox: 0.0250, loss: 0.1381, grad_norm: 4.7034\n",
            "2020-09-09 06:53:42,024 - mmdet - INFO - Epoch [19][3712/5332]\tlr: 1.000e-05, eta: 4:00:42, time: 2.071, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0061, s0.loss_cls: 0.0241, s0.acc: 99.0875, s0.loss_bbox: 0.0159, s1.loss_cls: 0.0165, s1.acc: 98.7305, s1.loss_bbox: 0.0258, s2.loss_cls: 0.0106, s2.acc: 98.2941, s2.loss_bbox: 0.0207, loss: 0.1235, grad_norm: 4.4398\n",
            "2020-09-09 06:55:53,333 - mmdet - INFO - Epoch [19][3776/5332]\tlr: 1.000e-05, eta: 3:58:26, time: 2.052, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0208, s0.acc: 99.1241, s0.loss_bbox: 0.0135, s1.loss_cls: 0.0144, s1.acc: 98.8861, s1.loss_bbox: 0.0239, s2.loss_cls: 0.0097, s2.acc: 98.4528, s2.loss_bbox: 0.0228, loss: 0.1125, grad_norm: 4.4167\n",
            "2020-09-09 06:58:04,778 - mmdet - INFO - Epoch [19][3840/5332]\tlr: 1.000e-05, eta: 3:56:11, time: 2.054, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0205, s0.acc: 99.1699, s0.loss_bbox: 0.0136, s1.loss_cls: 0.0139, s1.acc: 98.8342, s1.loss_bbox: 0.0266, s2.loss_cls: 0.0087, s2.acc: 98.4650, s2.loss_bbox: 0.0235, loss: 0.1141, grad_norm: 4.6766\n",
            "2020-09-09 07:00:17,046 - mmdet - INFO - Epoch [19][3904/5332]\tlr: 1.000e-05, eta: 3:53:57, time: 2.067, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0036, s0.loss_cls: 0.0282, s0.acc: 98.8464, s0.loss_bbox: 0.0191, s1.loss_cls: 0.0176, s1.acc: 98.5901, s1.loss_bbox: 0.0274, s2.loss_cls: 0.0110, s2.acc: 98.2361, s2.loss_bbox: 0.0237, loss: 0.1349, grad_norm: 4.1865\n",
            "2020-09-09 07:02:30,030 - mmdet - INFO - Epoch [19][3968/5332]\tlr: 1.000e-05, eta: 3:51:44, time: 2.078, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0287, s0.acc: 98.9746, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0195, s1.acc: 98.4680, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0115, s2.acc: 98.2666, s2.loss_bbox: 0.0258, loss: 0.1383, grad_norm: 4.7293\n",
            "2020-09-09 07:04:41,279 - mmdet - INFO - Epoch [19][4032/5332]\tlr: 1.000e-05, eta: 3:49:28, time: 2.051, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0183, s0.acc: 99.2859, s0.loss_bbox: 0.0158, s1.loss_cls: 0.0121, s1.acc: 99.0326, s1.loss_bbox: 0.0313, s2.loss_cls: 0.0084, s2.acc: 98.5077, s2.loss_bbox: 0.0287, loss: 0.1208, grad_norm: 4.4759\n",
            "2020-09-09 07:06:52,999 - mmdet - INFO - Epoch [19][4096/5332]\tlr: 1.000e-05, eta: 3:47:14, time: 2.058, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0285, s0.acc: 98.8434, s0.loss_bbox: 0.0184, s1.loss_cls: 0.0201, s1.acc: 98.4039, s1.loss_bbox: 0.0305, s2.loss_cls: 0.0111, s2.acc: 98.0957, s2.loss_bbox: 0.0257, loss: 0.1441, grad_norm: 5.2270\n",
            "2020-09-09 07:09:04,734 - mmdet - INFO - Epoch [19][4160/5332]\tlr: 1.000e-05, eta: 3:44:59, time: 2.058, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0208, s0.acc: 99.2188, s0.loss_bbox: 0.0166, s1.loss_cls: 0.0124, s1.acc: 99.0112, s1.loss_bbox: 0.0256, s2.loss_cls: 0.0083, s2.acc: 98.6023, s2.loss_bbox: 0.0230, loss: 0.1142, grad_norm: 4.5181\n",
            "2020-09-09 07:11:15,723 - mmdet - INFO - Epoch [19][4224/5332]\tlr: 1.000e-05, eta: 3:42:43, time: 2.047, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0220, s0.acc: 99.0753, s0.loss_bbox: 0.0147, s1.loss_cls: 0.0145, s1.acc: 98.8190, s1.loss_bbox: 0.0254, s2.loss_cls: 0.0092, s2.acc: 98.5077, s2.loss_bbox: 0.0223, loss: 0.1144, grad_norm: 4.3027\n",
            "2020-09-09 07:13:26,182 - mmdet - INFO - Epoch [19][4288/5332]\tlr: 1.000e-05, eta: 3:40:27, time: 2.038, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0061, s0.loss_cls: 0.0294, s0.acc: 98.8159, s0.loss_bbox: 0.0215, s1.loss_cls: 0.0188, s1.acc: 98.4558, s1.loss_bbox: 0.0307, s2.loss_cls: 0.0113, s2.acc: 98.1964, s2.loss_bbox: 0.0225, loss: 0.1430, grad_norm: 4.9773\n",
            "2020-09-09 07:15:38,290 - mmdet - INFO - Epoch [19][4352/5332]\tlr: 1.000e-05, eta: 3:38:13, time: 2.064, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0208, s0.acc: 99.1547, s0.loss_bbox: 0.0150, s1.loss_cls: 0.0128, s1.acc: 98.9471, s1.loss_bbox: 0.0256, s2.loss_cls: 0.0085, s2.acc: 98.6267, s2.loss_bbox: 0.0212, loss: 0.1121, grad_norm: 4.4150\n",
            "2020-09-09 07:17:51,475 - mmdet - INFO - Epoch [19][4416/5332]\tlr: 1.000e-05, eta: 3:36:01, time: 2.081, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0226, s0.acc: 99.1180, s0.loss_bbox: 0.0142, s1.loss_cls: 0.0138, s1.acc: 98.9471, s1.loss_bbox: 0.0220, s2.loss_cls: 0.0080, s2.acc: 98.8800, s2.loss_bbox: 0.0202, loss: 0.1088, grad_norm: 4.1553\n",
            "2020-09-09 07:20:02,625 - mmdet - INFO - Epoch [19][4480/5332]\tlr: 1.000e-05, eta: 3:33:46, time: 2.049, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0081, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0302, s0.acc: 98.9014, s0.loss_bbox: 0.0186, s1.loss_cls: 0.0160, s1.acc: 98.7183, s1.loss_bbox: 0.0276, s2.loss_cls: 0.0097, s2.acc: 98.5138, s2.loss_bbox: 0.0233, loss: 0.1391, grad_norm: 4.8720\n",
            "2020-09-09 07:22:15,236 - mmdet - INFO - Epoch [19][4544/5332]\tlr: 1.000e-05, eta: 3:31:33, time: 2.072, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0236, s0.acc: 98.9929, s0.loss_bbox: 0.0180, s1.loss_cls: 0.0144, s1.acc: 98.7427, s1.loss_bbox: 0.0291, s2.loss_cls: 0.0088, s2.acc: 98.4711, s2.loss_bbox: 0.0223, loss: 0.1262, grad_norm: 4.3442\n",
            "2020-09-09 07:24:27,308 - mmdet - INFO - Epoch [19][4608/5332]\tlr: 1.000e-05, eta: 3:29:20, time: 2.064, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0238, s0.acc: 99.0509, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0168, s1.acc: 98.6755, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0111, s2.acc: 98.0347, s2.loss_bbox: 0.0244, loss: 0.1278, grad_norm: 4.5745\n",
            "2020-09-09 07:26:37,139 - mmdet - INFO - Epoch [19][4672/5332]\tlr: 1.000e-05, eta: 3:27:03, time: 2.029, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0068, s0.loss_cls: 0.0205, s0.acc: 99.1821, s0.loss_bbox: 0.0168, s1.loss_cls: 0.0147, s1.acc: 98.8373, s1.loss_bbox: 0.0253, s2.loss_cls: 0.0097, s2.acc: 98.4253, s2.loss_bbox: 0.0191, loss: 0.1164, grad_norm: 3.8847\n",
            "2020-09-09 07:28:50,834 - mmdet - INFO - Epoch [19][4736/5332]\tlr: 1.000e-05, eta: 3:24:52, time: 2.089, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0269, s0.acc: 98.8647, s0.loss_bbox: 0.0224, s1.loss_cls: 0.0172, s1.acc: 98.6298, s1.loss_bbox: 0.0350, s2.loss_cls: 0.0122, s2.acc: 97.9065, s2.loss_bbox: 0.0251, loss: 0.1479, grad_norm: 5.1180\n",
            "2020-09-09 07:31:01,852 - mmdet - INFO - Epoch [19][4800/5332]\tlr: 1.000e-05, eta: 3:22:37, time: 2.047, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0061, s0.loss_cls: 0.0219, s0.acc: 99.0540, s0.loss_bbox: 0.0139, s1.loss_cls: 0.0143, s1.acc: 98.8434, s1.loss_bbox: 0.0230, s2.loss_cls: 0.0089, s2.acc: 98.5504, s2.loss_bbox: 0.0215, loss: 0.1133, grad_norm: 4.3204\n",
            "2020-09-09 07:33:14,821 - mmdet - INFO - Epoch [19][4864/5332]\tlr: 1.000e-05, eta: 3:20:25, time: 2.078, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0233, s0.acc: 99.0997, s0.loss_bbox: 0.0192, s1.loss_cls: 0.0150, s1.acc: 98.8525, s1.loss_bbox: 0.0313, s2.loss_cls: 0.0107, s2.acc: 98.3551, s2.loss_bbox: 0.0244, loss: 0.1311, grad_norm: 4.6905\n",
            "2020-09-09 07:35:28,034 - mmdet - INFO - Epoch [19][4928/5332]\tlr: 1.000e-05, eta: 3:18:12, time: 2.081, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0295, s0.acc: 98.8770, s0.loss_bbox: 0.0190, s1.loss_cls: 0.0181, s1.acc: 98.5443, s1.loss_bbox: 0.0308, s2.loss_cls: 0.0114, s2.acc: 98.2635, s2.loss_bbox: 0.0263, loss: 0.1435, grad_norm: 5.0840\n",
            "2020-09-09 07:37:39,742 - mmdet - INFO - Epoch [19][4992/5332]\tlr: 1.000e-05, eta: 3:15:59, time: 2.058, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0063, s0.loss_cls: 0.0219, s0.acc: 99.0662, s0.loss_bbox: 0.0168, s1.loss_cls: 0.0153, s1.acc: 98.6053, s1.loss_bbox: 0.0284, s2.loss_cls: 0.0114, s2.acc: 97.8424, s2.loss_bbox: 0.0236, loss: 0.1267, grad_norm: 4.8404\n",
            "2020-09-09 07:39:51,384 - mmdet - INFO - Epoch [19][5056/5332]\tlr: 1.000e-05, eta: 3:13:45, time: 2.057, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0238, s0.acc: 99.0906, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0142, s1.acc: 98.9655, s1.loss_bbox: 0.0259, s2.loss_cls: 0.0093, s2.acc: 98.3490, s2.loss_bbox: 0.0184, loss: 0.1161, grad_norm: 3.9996\n",
            "2020-09-09 07:42:03,282 - mmdet - INFO - Epoch [19][5120/5332]\tlr: 1.000e-05, eta: 3:11:31, time: 2.061, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0209, s0.acc: 99.1669, s0.loss_bbox: 0.0149, s1.loss_cls: 0.0139, s1.acc: 98.9044, s1.loss_bbox: 0.0243, s2.loss_cls: 0.0091, s2.acc: 98.5901, s2.loss_bbox: 0.0242, loss: 0.1149, grad_norm: 4.5833\n",
            "2020-09-09 07:44:16,280 - mmdet - INFO - Epoch [19][5184/5332]\tlr: 1.000e-05, eta: 3:09:19, time: 2.078, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0070, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0204, s0.acc: 99.2126, s0.loss_bbox: 0.0134, s1.loss_cls: 0.0124, s1.acc: 99.0417, s1.loss_bbox: 0.0277, s2.loss_cls: 0.0089, s2.acc: 98.4070, s2.loss_bbox: 0.0271, loss: 0.1223, grad_norm: 4.4002\n",
            "2020-09-09 07:46:27,971 - mmdet - INFO - Epoch [19][5248/5332]\tlr: 1.000e-05, eta: 3:07:05, time: 2.058, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0233, s0.acc: 99.1119, s0.loss_bbox: 0.0169, s1.loss_cls: 0.0143, s1.acc: 98.8739, s1.loss_bbox: 0.0281, s2.loss_cls: 0.0084, s2.acc: 98.6847, s2.loss_bbox: 0.0258, loss: 0.1264, grad_norm: 4.6023\n",
            "2020-09-09 07:48:46,574 - mmdet - INFO - Epoch [19][5312/5332]\tlr: 1.000e-05, eta: 3:04:59, time: 2.166, data_time: 0.102, memory: 8778, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0282, s0.acc: 98.7793, s0.loss_bbox: 0.0180, s1.loss_cls: 0.0176, s1.acc: 98.5443, s1.loss_bbox: 0.0288, s2.loss_cls: 0.0109, s2.acc: 98.1812, s2.loss_bbox: 0.0238, loss: 0.1376, grad_norm: 4.4294\n",
            "2020-09-09 07:49:27,862 - mmdet - INFO - Saving checkpoint at 19 epochs\n",
            "[>>] 667/667, 0.6 task/s, elapsed: 1198s, ETA:     0s2020-09-09 08:09:33,886 - mmdet - INFO - \n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 82  | 222  | 0.854  | 0.588 |\n",
            "| 3     | 22  | 92   | 0.818  | 0.714 |\n",
            "| 4     | 529 | 1143 | 0.917  | 0.827 |\n",
            "| 5     | 78  | 165  | 0.885  | 0.790 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.730 |\n",
            "+-------+-----+------+--------+-------+\n",
            "2020-09-09 08:09:33,891 - mmdet - INFO - Epoch(val) [19][5332]\tmAP: 0.7300\n",
            "2020-09-09 08:11:49,355 - mmdet - INFO - Epoch [20][64/5332]\tlr: 1.000e-05, eta: 3:01:27, time: 2.116, data_time: 0.038, memory: 8778, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0260, s0.acc: 99.0906, s0.loss_bbox: 0.0193, s1.loss_cls: 0.0160, s1.acc: 98.8983, s1.loss_bbox: 0.0312, s2.loss_cls: 0.0092, s2.acc: 98.6786, s2.loss_bbox: 0.0236, loss: 0.1349, grad_norm: 4.5236\n",
            "2020-09-09 08:14:01,101 - mmdet - INFO - Epoch [20][128/5332]\tlr: 1.000e-05, eta: 2:59:14, time: 2.059, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0237, s0.acc: 99.0967, s0.loss_bbox: 0.0164, s1.loss_cls: 0.0144, s1.acc: 98.9136, s1.loss_bbox: 0.0283, s2.loss_cls: 0.0110, s2.acc: 98.4344, s2.loss_bbox: 0.0201, loss: 0.1247, grad_norm: 4.6708\n",
            "2020-09-09 08:16:12,179 - mmdet - INFO - Epoch [20][192/5332]\tlr: 1.000e-05, eta: 2:57:00, time: 2.048, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0230, s0.acc: 99.0234, s0.loss_bbox: 0.0176, s1.loss_cls: 0.0154, s1.acc: 98.6359, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0099, s2.acc: 98.4955, s2.loss_bbox: 0.0192, loss: 0.1225, grad_norm: 4.6479\n",
            "2020-09-09 08:18:25,286 - mmdet - INFO - Epoch [20][256/5332]\tlr: 1.000e-05, eta: 2:54:49, time: 2.080, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0229, s0.acc: 99.1058, s0.loss_bbox: 0.0182, s1.loss_cls: 0.0145, s1.acc: 98.8556, s1.loss_bbox: 0.0312, s2.loss_cls: 0.0089, s2.acc: 98.5779, s2.loss_bbox: 0.0272, loss: 0.1326, grad_norm: 5.1423\n",
            "2020-09-09 08:20:35,640 - mmdet - INFO - Epoch [20][320/5332]\tlr: 1.000e-05, eta: 2:52:35, time: 2.037, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0213, s0.acc: 99.1760, s0.loss_bbox: 0.0163, s1.loss_cls: 0.0125, s1.acc: 98.9929, s1.loss_bbox: 0.0295, s2.loss_cls: 0.0087, s2.acc: 98.4467, s2.loss_bbox: 0.0232, loss: 0.1169, grad_norm: 4.3448\n",
            "2020-09-09 08:22:46,732 - mmdet - INFO - Epoch [20][384/5332]\tlr: 1.000e-05, eta: 2:50:22, time: 2.048, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0222, s0.acc: 99.1943, s0.loss_bbox: 0.0159, s1.loss_cls: 0.0135, s1.acc: 98.9197, s1.loss_bbox: 0.0283, s2.loss_cls: 0.0097, s2.acc: 98.3856, s2.loss_bbox: 0.0232, loss: 0.1211, grad_norm: 4.3581\n",
            "2020-09-09 08:24:58,279 - mmdet - INFO - Epoch [20][448/5332]\tlr: 1.000e-05, eta: 2:48:09, time: 2.055, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0048, s0.loss_cls: 0.0239, s0.acc: 99.0051, s0.loss_bbox: 0.0164, s1.loss_cls: 0.0171, s1.acc: 98.5870, s1.loss_bbox: 0.0310, s2.loss_cls: 0.0095, s2.acc: 98.6023, s2.loss_bbox: 0.0258, loss: 0.1325, grad_norm: 4.5597\n",
            "2020-09-09 08:27:10,248 - mmdet - INFO - Epoch [20][512/5332]\tlr: 1.000e-05, eta: 2:45:57, time: 2.062, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0059, s0.loss_cls: 0.0242, s0.acc: 99.0265, s0.loss_bbox: 0.0181, s1.loss_cls: 0.0153, s1.acc: 98.9014, s1.loss_bbox: 0.0280, s2.loss_cls: 0.0099, s2.acc: 98.3124, s2.loss_bbox: 0.0246, loss: 0.1285, grad_norm: 4.5094\n",
            "2020-09-09 08:29:23,462 - mmdet - INFO - Epoch [20][576/5332]\tlr: 1.000e-05, eta: 2:43:45, time: 2.081, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0256, s0.acc: 99.0173, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0163, s1.acc: 98.7152, s1.loss_bbox: 0.0287, s2.loss_cls: 0.0103, s2.acc: 98.3307, s2.loss_bbox: 0.0236, loss: 0.1269, grad_norm: 4.6460\n",
            "2020-09-09 08:31:36,334 - mmdet - INFO - Epoch [20][640/5332]\tlr: 1.000e-05, eta: 2:41:34, time: 2.076, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0276, s0.acc: 98.9410, s0.loss_bbox: 0.0194, s1.loss_cls: 0.0156, s1.acc: 98.7122, s1.loss_bbox: 0.0282, s2.loss_cls: 0.0103, s2.acc: 98.4558, s2.loss_bbox: 0.0227, loss: 0.1330, grad_norm: 4.5671\n",
            "2020-09-09 08:33:47,154 - mmdet - INFO - Epoch [20][704/5332]\tlr: 1.000e-05, eta: 2:39:20, time: 2.044, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0240, s0.acc: 98.9838, s0.loss_bbox: 0.0164, s1.loss_cls: 0.0143, s1.acc: 98.8220, s1.loss_bbox: 0.0272, s2.loss_cls: 0.0090, s2.acc: 98.4680, s2.loss_bbox: 0.0206, loss: 0.1190, grad_norm: 4.9006\n",
            "2020-09-09 08:35:59,719 - mmdet - INFO - Epoch [20][768/5332]\tlr: 1.000e-05, eta: 2:37:08, time: 2.071, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0185, s0.acc: 99.3011, s0.loss_bbox: 0.0148, s1.loss_cls: 0.0124, s1.acc: 98.9746, s1.loss_bbox: 0.0259, s2.loss_cls: 0.0086, s2.acc: 98.5199, s2.loss_bbox: 0.0221, loss: 0.1110, grad_norm: 4.1786\n",
            "2020-09-09 08:38:11,225 - mmdet - INFO - Epoch [20][832/5332]\tlr: 1.000e-05, eta: 2:34:56, time: 2.055, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0258, s0.acc: 99.0387, s0.loss_bbox: 0.0168, s1.loss_cls: 0.0172, s1.acc: 98.7061, s1.loss_bbox: 0.0254, s2.loss_cls: 0.0100, s2.acc: 98.4192, s2.loss_bbox: 0.0210, loss: 0.1240, grad_norm: 4.4925\n",
            "2020-09-09 08:40:22,843 - mmdet - INFO - Epoch [20][896/5332]\tlr: 1.000e-05, eta: 2:32:43, time: 2.057, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0242, s0.acc: 99.0570, s0.loss_bbox: 0.0201, s1.loss_cls: 0.0159, s1.acc: 98.7488, s1.loss_bbox: 0.0337, s2.loss_cls: 0.0102, s2.acc: 98.3612, s2.loss_bbox: 0.0256, loss: 0.1379, grad_norm: 4.8841\n",
            "2020-09-09 08:42:37,056 - mmdet - INFO - Epoch [20][960/5332]\tlr: 1.000e-05, eta: 2:30:32, time: 2.097, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0256, s0.acc: 99.0570, s0.loss_bbox: 0.0174, s1.loss_cls: 0.0161, s1.acc: 98.8373, s1.loss_bbox: 0.0268, s2.loss_cls: 0.0100, s2.acc: 98.3643, s2.loss_bbox: 0.0249, loss: 0.1287, grad_norm: 4.8960\n",
            "2020-09-09 08:44:48,642 - mmdet - INFO - Epoch [20][1024/5332]\tlr: 1.000e-05, eta: 2:28:19, time: 2.056, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0250, s0.acc: 98.9563, s0.loss_bbox: 0.0184, s1.loss_cls: 0.0166, s1.acc: 98.7579, s1.loss_bbox: 0.0305, s2.loss_cls: 0.0116, s2.acc: 98.3063, s2.loss_bbox: 0.0219, loss: 0.1300, grad_norm: 4.3380\n",
            "2020-09-09 08:47:01,523 - mmdet - INFO - Epoch [20][1088/5332]\tlr: 1.000e-05, eta: 2:26:08, time: 2.076, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0233, s0.acc: 99.0967, s0.loss_bbox: 0.0162, s1.loss_cls: 0.0145, s1.acc: 98.8922, s1.loss_bbox: 0.0260, s2.loss_cls: 0.0089, s2.acc: 98.5626, s2.loss_bbox: 0.0228, loss: 0.1198, grad_norm: 4.0783\n",
            "2020-09-09 08:49:13,510 - mmdet - INFO - Epoch [20][1152/5332]\tlr: 1.000e-05, eta: 2:23:55, time: 2.062, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0253, s0.acc: 98.8861, s0.loss_bbox: 0.0159, s1.loss_cls: 0.0166, s1.acc: 98.5931, s1.loss_bbox: 0.0232, s2.loss_cls: 0.0103, s2.acc: 98.3154, s2.loss_bbox: 0.0232, loss: 0.1231, grad_norm: 4.8077\n",
            "2020-09-09 08:51:25,951 - mmdet - INFO - Epoch [20][1216/5332]\tlr: 1.000e-05, eta: 2:21:43, time: 2.069, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0227, s0.acc: 99.0936, s0.loss_bbox: 0.0187, s1.loss_cls: 0.0139, s1.acc: 98.9105, s1.loss_bbox: 0.0304, s2.loss_cls: 0.0085, s2.acc: 98.6481, s2.loss_bbox: 0.0238, loss: 0.1265, grad_norm: 4.4879\n",
            "2020-09-09 08:53:39,295 - mmdet - INFO - Epoch [20][1280/5332]\tlr: 1.000e-05, eta: 2:19:32, time: 2.083, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0262, s0.acc: 98.9777, s0.loss_bbox: 0.0156, s1.loss_cls: 0.0156, s1.acc: 98.7549, s1.loss_bbox: 0.0269, s2.loss_cls: 0.0102, s2.acc: 98.2971, s2.loss_bbox: 0.0242, loss: 0.1257, grad_norm: 4.6745\n",
            "2020-09-09 08:55:51,279 - mmdet - INFO - Epoch [20][1344/5332]\tlr: 1.000e-05, eta: 2:17:19, time: 2.062, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0270, s0.acc: 98.9044, s0.loss_bbox: 0.0176, s1.loss_cls: 0.0177, s1.acc: 98.6328, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0110, s2.acc: 98.0835, s2.loss_bbox: 0.0237, loss: 0.1349, grad_norm: 5.1746\n",
            "2020-09-09 08:58:02,148 - mmdet - INFO - Epoch [20][1408/5332]\tlr: 1.000e-05, eta: 2:15:06, time: 2.045, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0239, s0.acc: 99.0479, s0.loss_bbox: 0.0158, s1.loss_cls: 0.0161, s1.acc: 98.7488, s1.loss_bbox: 0.0268, s2.loss_cls: 0.0101, s2.acc: 98.4772, s2.loss_bbox: 0.0247, loss: 0.1245, grad_norm: 4.6213\n",
            "2020-09-09 09:00:14,429 - mmdet - INFO - Epoch [20][1472/5332]\tlr: 1.000e-05, eta: 2:12:54, time: 2.067, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0211, s0.acc: 99.1882, s0.loss_bbox: 0.0158, s1.loss_cls: 0.0131, s1.acc: 99.0845, s1.loss_bbox: 0.0259, s2.loss_cls: 0.0087, s2.acc: 98.6053, s2.loss_bbox: 0.0235, loss: 0.1181, grad_norm: 4.2550\n",
            "2020-09-09 09:02:27,985 - mmdet - INFO - Epoch [20][1536/5332]\tlr: 1.000e-05, eta: 2:10:43, time: 2.087, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0045, s0.loss_cls: 0.0242, s0.acc: 98.9990, s0.loss_bbox: 0.0165, s1.loss_cls: 0.0158, s1.acc: 98.7701, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0106, s2.acc: 98.4467, s2.loss_bbox: 0.0226, loss: 0.1279, grad_norm: 4.2689\n",
            "2020-09-09 09:04:41,304 - mmdet - INFO - Epoch [20][1600/5332]\tlr: 1.000e-05, eta: 2:08:31, time: 2.083, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0322, s0.acc: 98.7823, s0.loss_bbox: 0.0178, s1.loss_cls: 0.0225, s1.acc: 98.3154, s1.loss_bbox: 0.0299, s2.loss_cls: 0.0137, s2.acc: 97.7264, s2.loss_bbox: 0.0277, loss: 0.1527, grad_norm: 5.3707\n",
            "2020-09-09 09:06:53,729 - mmdet - INFO - Epoch [20][1664/5332]\tlr: 1.000e-05, eta: 2:06:19, time: 2.069, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0221, s0.acc: 99.0784, s0.loss_bbox: 0.0174, s1.loss_cls: 0.0149, s1.acc: 98.8586, s1.loss_bbox: 0.0274, s2.loss_cls: 0.0098, s2.acc: 98.4894, s2.loss_bbox: 0.0245, loss: 0.1229, grad_norm: 4.7031\n",
            "2020-09-09 09:09:05,734 - mmdet - INFO - Epoch [20][1728/5332]\tlr: 1.000e-05, eta: 2:04:06, time: 2.063, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0181, s0.acc: 99.2706, s0.loss_bbox: 0.0125, s1.loss_cls: 0.0115, s1.acc: 99.0997, s1.loss_bbox: 0.0229, s2.loss_cls: 0.0074, s2.acc: 98.6603, s2.loss_bbox: 0.0206, loss: 0.0987, grad_norm: 3.7106\n",
            "2020-09-09 09:11:17,723 - mmdet - INFO - Epoch [20][1792/5332]\tlr: 1.000e-05, eta: 2:01:54, time: 2.062, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0193, s0.acc: 99.1974, s0.loss_bbox: 0.0146, s1.loss_cls: 0.0132, s1.acc: 98.8831, s1.loss_bbox: 0.0264, s2.loss_cls: 0.0090, s2.acc: 98.2849, s2.loss_bbox: 0.0230, loss: 0.1129, grad_norm: 4.3750\n",
            "2020-09-09 09:13:27,925 - mmdet - INFO - Epoch [20][1856/5332]\tlr: 1.000e-05, eta: 1:59:41, time: 2.034, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0076, s0.loss_cls: 0.0205, s0.acc: 99.2126, s0.loss_bbox: 0.0144, s1.loss_cls: 0.0125, s1.acc: 99.0509, s1.loss_bbox: 0.0260, s2.loss_cls: 0.0080, s2.acc: 98.6786, s2.loss_bbox: 0.0252, loss: 0.1180, grad_norm: 4.4097\n",
            "2020-09-09 09:15:41,877 - mmdet - INFO - Epoch [20][1920/5332]\tlr: 1.000e-05, eta: 1:57:29, time: 2.093, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0038, s0.loss_cls: 0.0233, s0.acc: 99.0784, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0163, s1.acc: 98.6908, s1.loss_bbox: 0.0320, s2.loss_cls: 0.0103, s2.acc: 98.3582, s2.loss_bbox: 0.0246, loss: 0.1327, grad_norm: 5.1026\n",
            "2020-09-09 09:17:56,224 - mmdet - INFO - Epoch [20][1984/5332]\tlr: 1.000e-05, eta: 1:55:18, time: 2.099, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0248, s0.acc: 99.0631, s0.loss_bbox: 0.0184, s1.loss_cls: 0.0160, s1.acc: 98.7152, s1.loss_bbox: 0.0274, s2.loss_cls: 0.0105, s2.acc: 98.2086, s2.loss_bbox: 0.0211, loss: 0.1250, grad_norm: 4.1766\n",
            "2020-09-09 09:20:07,935 - mmdet - INFO - Epoch [20][2048/5332]\tlr: 1.000e-05, eta: 1:53:06, time: 2.058, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0269, s0.acc: 98.8983, s0.loss_bbox: 0.0171, s1.loss_cls: 0.0177, s1.acc: 98.5382, s1.loss_bbox: 0.0278, s2.loss_cls: 0.0114, s2.acc: 97.9645, s2.loss_bbox: 0.0223, loss: 0.1328, grad_norm: 4.8447\n",
            "2020-09-09 09:22:23,077 - mmdet - INFO - Epoch [20][2112/5332]\tlr: 1.000e-05, eta: 1:50:55, time: 2.112, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0026, s0.loss_cls: 0.0227, s0.acc: 99.1455, s0.loss_bbox: 0.0162, s1.loss_cls: 0.0140, s1.acc: 98.8220, s1.loss_bbox: 0.0252, s2.loss_cls: 0.0085, s2.acc: 98.6206, s2.loss_bbox: 0.0178, loss: 0.1102, grad_norm: 4.2517\n",
            "2020-09-09 09:24:37,433 - mmdet - INFO - Epoch [20][2176/5332]\tlr: 1.000e-05, eta: 1:48:43, time: 2.099, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0067, s0.loss_cls: 0.0287, s0.acc: 98.9014, s0.loss_bbox: 0.0207, s1.loss_cls: 0.0188, s1.acc: 98.5352, s1.loss_bbox: 0.0319, s2.loss_cls: 0.0118, s2.acc: 98.1598, s2.loss_bbox: 0.0270, loss: 0.1496, grad_norm: 5.1742\n",
            "2020-09-09 09:26:50,345 - mmdet - INFO - Epoch [20][2240/5332]\tlr: 1.000e-05, eta: 1:46:31, time: 2.077, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0062, s0.loss_cls: 0.0223, s0.acc: 99.1394, s0.loss_bbox: 0.0171, s1.loss_cls: 0.0129, s1.acc: 99.0265, s1.loss_bbox: 0.0299, s2.loss_cls: 0.0089, s2.acc: 98.6084, s2.loss_bbox: 0.0271, loss: 0.1292, grad_norm: 4.3127\n",
            "2020-09-09 09:29:01,630 - mmdet - INFO - Epoch [20][2304/5332]\tlr: 1.000e-05, eta: 1:44:18, time: 2.051, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0055, s0.loss_cls: 0.0212, s0.acc: 99.2004, s0.loss_bbox: 0.0138, s1.loss_cls: 0.0142, s1.acc: 98.9014, s1.loss_bbox: 0.0216, s2.loss_cls: 0.0094, s2.acc: 98.5291, s2.loss_bbox: 0.0162, loss: 0.1066, grad_norm: 3.8520\n",
            "2020-09-09 09:31:14,537 - mmdet - INFO - Epoch [20][2368/5332]\tlr: 1.000e-05, eta: 1:42:06, time: 2.077, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0225, s0.acc: 99.0906, s0.loss_bbox: 0.0167, s1.loss_cls: 0.0141, s1.acc: 98.8342, s1.loss_bbox: 0.0277, s2.loss_cls: 0.0095, s2.acc: 98.4100, s2.loss_bbox: 0.0222, loss: 0.1200, grad_norm: 4.0973\n",
            "2020-09-09 09:33:26,128 - mmdet - INFO - Epoch [20][2432/5332]\tlr: 1.000e-05, eta: 1:39:54, time: 2.056, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0054, s0.loss_cls: 0.0251, s0.acc: 99.0387, s0.loss_bbox: 0.0151, s1.loss_cls: 0.0143, s1.acc: 99.0265, s1.loss_bbox: 0.0259, s2.loss_cls: 0.0092, s2.acc: 98.5809, s2.loss_bbox: 0.0219, loss: 0.1218, grad_norm: 4.2197\n",
            "2020-09-09 09:35:37,884 - mmdet - INFO - Epoch [20][2496/5332]\tlr: 1.000e-05, eta: 1:37:41, time: 2.059, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0283, s0.acc: 98.9349, s0.loss_bbox: 0.0211, s1.loss_cls: 0.0206, s1.acc: 98.3002, s1.loss_bbox: 0.0339, s2.loss_cls: 0.0129, s2.acc: 97.7753, s2.loss_bbox: 0.0202, loss: 0.1450, grad_norm: 4.2694\n",
            "2020-09-09 09:37:50,886 - mmdet - INFO - Epoch [20][2560/5332]\tlr: 1.000e-05, eta: 1:35:29, time: 2.078, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0062, loss_rpn_bbox: 0.0051, s0.loss_cls: 0.0229, s0.acc: 99.1058, s0.loss_bbox: 0.0175, s1.loss_cls: 0.0147, s1.acc: 98.8861, s1.loss_bbox: 0.0267, s2.loss_cls: 0.0091, s2.acc: 98.5840, s2.loss_bbox: 0.0234, loss: 0.1256, grad_norm: 4.4879\n",
            "2020-09-09 09:40:02,498 - mmdet - INFO - Epoch [20][2624/5332]\tlr: 1.000e-05, eta: 1:33:17, time: 2.056, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0187, s0.acc: 99.2584, s0.loss_bbox: 0.0155, s1.loss_cls: 0.0123, s1.acc: 99.0753, s1.loss_bbox: 0.0250, s2.loss_cls: 0.0089, s2.acc: 98.4528, s2.loss_bbox: 0.0185, loss: 0.1081, grad_norm: 4.0001\n",
            "2020-09-09 09:42:13,611 - mmdet - INFO - Epoch [20][2688/5332]\tlr: 1.000e-05, eta: 1:31:04, time: 2.049, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0043, s0.loss_cls: 0.0257, s0.acc: 98.9288, s0.loss_bbox: 0.0193, s1.loss_cls: 0.0179, s1.acc: 98.5229, s1.loss_bbox: 0.0310, s2.loss_cls: 0.0108, s2.acc: 98.2086, s2.loss_bbox: 0.0270, loss: 0.1392, grad_norm: 5.1874\n",
            "2020-09-09 09:44:26,077 - mmdet - INFO - Epoch [20][2752/5332]\tlr: 1.000e-05, eta: 1:28:52, time: 2.070, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0222, s0.acc: 99.0845, s0.loss_bbox: 0.0150, s1.loss_cls: 0.0153, s1.acc: 98.7152, s1.loss_bbox: 0.0231, s2.loss_cls: 0.0096, s2.acc: 98.3002, s2.loss_bbox: 0.0185, loss: 0.1102, grad_norm: 4.3183\n",
            "2020-09-09 09:46:36,749 - mmdet - INFO - Epoch [20][2816/5332]\tlr: 1.000e-05, eta: 1:26:39, time: 2.042, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0030, s0.loss_cls: 0.0225, s0.acc: 99.1302, s0.loss_bbox: 0.0131, s1.loss_cls: 0.0153, s1.acc: 98.6481, s1.loss_bbox: 0.0235, s2.loss_cls: 0.0091, s2.acc: 98.5504, s2.loss_bbox: 0.0219, loss: 0.1132, grad_norm: 4.2933\n",
            "2020-09-09 09:48:49,497 - mmdet - INFO - Epoch [20][2880/5332]\tlr: 1.000e-05, eta: 1:24:27, time: 2.074, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0056, s0.loss_cls: 0.0249, s0.acc: 99.0509, s0.loss_bbox: 0.0177, s1.loss_cls: 0.0144, s1.acc: 98.9410, s1.loss_bbox: 0.0297, s2.loss_cls: 0.0089, s2.acc: 98.4528, s2.loss_bbox: 0.0250, loss: 0.1297, grad_norm: 4.5202\n",
            "2020-09-09 09:51:01,608 - mmdet - INFO - Epoch [20][2944/5332]\tlr: 1.000e-05, eta: 1:22:15, time: 2.064, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0082, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0236, s0.acc: 99.1058, s0.loss_bbox: 0.0158, s1.loss_cls: 0.0147, s1.acc: 98.8281, s1.loss_bbox: 0.0264, s2.loss_cls: 0.0112, s2.acc: 98.1567, s2.loss_bbox: 0.0200, loss: 0.1252, grad_norm: 4.2353\n",
            "2020-09-09 09:53:13,762 - mmdet - INFO - Epoch [20][3008/5332]\tlr: 1.000e-05, eta: 1:20:02, time: 2.065, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0230, s0.acc: 99.0387, s0.loss_bbox: 0.0192, s1.loss_cls: 0.0151, s1.acc: 98.7244, s1.loss_bbox: 0.0349, s2.loss_cls: 0.0094, s2.acc: 98.3337, s2.loss_bbox: 0.0305, loss: 0.1392, grad_norm: 4.4734\n",
            "2020-09-09 09:55:27,359 - mmdet - INFO - Epoch [20][3072/5332]\tlr: 1.000e-05, eta: 1:17:51, time: 2.087, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0028, s0.loss_cls: 0.0219, s0.acc: 99.0784, s0.loss_bbox: 0.0162, s1.loss_cls: 0.0143, s1.acc: 98.9166, s1.loss_bbox: 0.0261, s2.loss_cls: 0.0097, s2.acc: 98.4497, s2.loss_bbox: 0.0218, loss: 0.1160, grad_norm: 4.2379\n",
            "2020-09-09 09:57:41,447 - mmdet - INFO - Epoch [20][3136/5332]\tlr: 1.000e-05, eta: 1:15:39, time: 2.095, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0026, s0.loss_cls: 0.0200, s0.acc: 99.1852, s0.loss_bbox: 0.0127, s1.loss_cls: 0.0134, s1.acc: 98.8281, s1.loss_bbox: 0.0263, s2.loss_cls: 0.0091, s2.acc: 98.4009, s2.loss_bbox: 0.0274, loss: 0.1136, grad_norm: 4.7048\n",
            "2020-09-09 09:59:53,330 - mmdet - INFO - Epoch [20][3200/5332]\tlr: 1.000e-05, eta: 1:13:26, time: 2.061, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0039, s0.loss_cls: 0.0236, s0.acc: 99.0326, s0.loss_bbox: 0.0171, s1.loss_cls: 0.0161, s1.acc: 98.6725, s1.loss_bbox: 0.0258, s2.loss_cls: 0.0100, s2.acc: 98.2666, s2.loss_bbox: 0.0207, loss: 0.1210, grad_norm: 4.3682\n",
            "2020-09-09 10:02:04,628 - mmdet - INFO - Epoch [20][3264/5332]\tlr: 1.000e-05, eta: 1:11:14, time: 2.052, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0034, s0.loss_cls: 0.0217, s0.acc: 99.1089, s0.loss_bbox: 0.0151, s1.loss_cls: 0.0136, s1.acc: 98.8800, s1.loss_bbox: 0.0265, s2.loss_cls: 0.0082, s2.acc: 98.7732, s2.loss_bbox: 0.0239, loss: 0.1154, grad_norm: 4.3376\n",
            "2020-09-09 10:04:17,567 - mmdet - INFO - Epoch [20][3328/5332]\tlr: 1.000e-05, eta: 1:09:02, time: 2.077, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0073, loss_rpn_bbox: 0.0064, s0.loss_cls: 0.0312, s0.acc: 98.8739, s0.loss_bbox: 0.0192, s1.loss_cls: 0.0203, s1.acc: 98.4863, s1.loss_bbox: 0.0333, s2.loss_cls: 0.0113, s2.acc: 98.0865, s2.loss_bbox: 0.0243, loss: 0.1534, grad_norm: 5.3957\n",
            "2020-09-09 10:06:30,806 - mmdet - INFO - Epoch [20][3392/5332]\tlr: 1.000e-05, eta: 1:06:50, time: 2.082, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0027, s0.loss_cls: 0.0212, s0.acc: 99.2279, s0.loss_bbox: 0.0139, s1.loss_cls: 0.0150, s1.acc: 98.9105, s1.loss_bbox: 0.0218, s2.loss_cls: 0.0089, s2.acc: 98.7030, s2.loss_bbox: 0.0165, loss: 0.1025, grad_norm: 3.6774\n",
            "2020-09-09 10:08:41,755 - mmdet - INFO - Epoch [20][3456/5332]\tlr: 1.000e-05, eta: 1:04:37, time: 2.046, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0233, s0.acc: 99.1516, s0.loss_bbox: 0.0149, s1.loss_cls: 0.0148, s1.acc: 98.8312, s1.loss_bbox: 0.0298, s2.loss_cls: 0.0092, s2.acc: 98.6389, s2.loss_bbox: 0.0264, loss: 0.1254, grad_norm: 4.6370\n",
            "2020-09-09 10:10:54,535 - mmdet - INFO - Epoch [20][3520/5332]\tlr: 1.000e-05, eta: 1:02:25, time: 2.075, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0256, s0.acc: 98.9655, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0171, s1.acc: 98.7152, s1.loss_bbox: 0.0297, s2.loss_cls: 0.0108, s2.acc: 98.3215, s2.loss_bbox: 0.0244, loss: 0.1325, grad_norm: 4.7700\n",
            "2020-09-09 10:13:07,931 - mmdet - INFO - Epoch [20][3584/5332]\tlr: 1.000e-05, eta: 1:00:13, time: 2.084, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0058, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0257, s0.acc: 99.0295, s0.loss_bbox: 0.0220, s1.loss_cls: 0.0164, s1.acc: 98.7885, s1.loss_bbox: 0.0357, s2.loss_cls: 0.0110, s2.acc: 98.1873, s2.loss_bbox: 0.0279, loss: 0.1502, grad_norm: 5.1821\n",
            "2020-09-09 10:15:19,202 - mmdet - INFO - Epoch [20][3648/5332]\tlr: 1.000e-05, eta: 0:58:00, time: 2.051, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0267, s0.acc: 98.8708, s0.loss_bbox: 0.0180, s1.loss_cls: 0.0184, s1.acc: 98.4344, s1.loss_bbox: 0.0294, s2.loss_cls: 0.0114, s2.acc: 97.9645, s2.loss_bbox: 0.0221, loss: 0.1331, grad_norm: 4.4925\n",
            "2020-09-09 10:17:31,661 - mmdet - INFO - Epoch [20][3712/5332]\tlr: 1.000e-05, eta: 0:55:48, time: 2.070, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0081, s0.loss_cls: 0.0300, s0.acc: 98.9563, s0.loss_bbox: 0.0209, s1.loss_cls: 0.0171, s1.acc: 98.8403, s1.loss_bbox: 0.0350, s2.loss_cls: 0.0095, s2.acc: 98.5291, s2.loss_bbox: 0.0271, loss: 0.1536, grad_norm: 4.8811\n",
            "2020-09-09 10:19:43,233 - mmdet - INFO - Epoch [20][3776/5332]\tlr: 1.000e-05, eta: 0:53:36, time: 2.056, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0044, s0.loss_cls: 0.0259, s0.acc: 98.9288, s0.loss_bbox: 0.0191, s1.loss_cls: 0.0169, s1.acc: 98.6389, s1.loss_bbox: 0.0286, s2.loss_cls: 0.0108, s2.acc: 98.2361, s2.loss_bbox: 0.0243, loss: 0.1323, grad_norm: 4.8566\n",
            "2020-09-09 10:21:57,619 - mmdet - INFO - Epoch [20][3840/5332]\tlr: 1.000e-05, eta: 0:51:24, time: 2.100, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0042, s0.loss_cls: 0.0234, s0.acc: 99.1241, s0.loss_bbox: 0.0173, s1.loss_cls: 0.0147, s1.acc: 98.8312, s1.loss_bbox: 0.0290, s2.loss_cls: 0.0095, s2.acc: 98.4497, s2.loss_bbox: 0.0260, loss: 0.1261, grad_norm: 4.3235\n",
            "2020-09-09 10:24:11,099 - mmdet - INFO - Epoch [20][3904/5332]\tlr: 1.000e-05, eta: 0:49:12, time: 2.086, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0040, s0.loss_cls: 0.0188, s0.acc: 99.2096, s0.loss_bbox: 0.0137, s1.loss_cls: 0.0118, s1.acc: 99.0112, s1.loss_bbox: 0.0243, s2.loss_cls: 0.0080, s2.acc: 98.8495, s2.loss_bbox: 0.0220, loss: 0.1048, grad_norm: 4.2218\n",
            "2020-09-09 10:26:23,805 - mmdet - INFO - Epoch [20][3968/5332]\tlr: 1.000e-05, eta: 0:46:59, time: 2.074, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0214, s0.acc: 99.0936, s0.loss_bbox: 0.0172, s1.loss_cls: 0.0133, s1.acc: 98.8678, s1.loss_bbox: 0.0327, s2.loss_cls: 0.0096, s2.acc: 98.3521, s2.loss_bbox: 0.0238, loss: 0.1272, grad_norm: 4.8697\n",
            "2020-09-09 10:28:37,194 - mmdet - INFO - Epoch [20][4032/5332]\tlr: 1.000e-05, eta: 0:44:47, time: 2.084, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0067, s0.loss_cls: 0.0217, s0.acc: 99.0814, s0.loss_bbox: 0.0201, s1.loss_cls: 0.0170, s1.acc: 98.5352, s1.loss_bbox: 0.0318, s2.loss_cls: 0.0119, s2.acc: 97.9645, s2.loss_bbox: 0.0239, loss: 0.1373, grad_norm: 4.6693\n",
            "2020-09-09 10:30:50,451 - mmdet - INFO - Epoch [20][4096/5332]\tlr: 1.000e-05, eta: 0:42:35, time: 2.082, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0050, s0.loss_cls: 0.0235, s0.acc: 99.0967, s0.loss_bbox: 0.0131, s1.loss_cls: 0.0146, s1.acc: 98.9441, s1.loss_bbox: 0.0239, s2.loss_cls: 0.0101, s2.acc: 98.4406, s2.loss_bbox: 0.0224, loss: 0.1158, grad_norm: 4.7305\n",
            "2020-09-09 10:33:03,926 - mmdet - INFO - Epoch [20][4160/5332]\tlr: 1.000e-05, eta: 0:40:23, time: 2.086, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0057, s0.loss_cls: 0.0216, s0.acc: 99.1577, s0.loss_bbox: 0.0178, s1.loss_cls: 0.0135, s1.acc: 98.9014, s1.loss_bbox: 0.0321, s2.loss_cls: 0.0085, s2.acc: 98.5504, s2.loss_bbox: 0.0265, loss: 0.1295, grad_norm: 4.7115\n",
            "2020-09-09 10:35:16,593 - mmdet - INFO - Epoch [20][4224/5332]\tlr: 1.000e-05, eta: 0:38:10, time: 2.073, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0058, loss_rpn_bbox: 0.0046, s0.loss_cls: 0.0275, s0.acc: 98.8586, s0.loss_bbox: 0.0203, s1.loss_cls: 0.0158, s1.acc: 98.7946, s1.loss_bbox: 0.0289, s2.loss_cls: 0.0089, s2.acc: 98.6938, s2.loss_bbox: 0.0225, loss: 0.1344, grad_norm: 4.6807\n",
            "2020-09-09 10:37:31,042 - mmdet - INFO - Epoch [20][4288/5332]\tlr: 1.000e-05, eta: 0:35:58, time: 2.101, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0029, s0.loss_cls: 0.0211, s0.acc: 99.1699, s0.loss_bbox: 0.0152, s1.loss_cls: 0.0136, s1.acc: 98.9502, s1.loss_bbox: 0.0257, s2.loss_cls: 0.0086, s2.acc: 98.6603, s2.loss_bbox: 0.0245, loss: 0.1135, grad_norm: 4.3523\n",
            "2020-09-09 10:39:44,119 - mmdet - INFO - Epoch [20][4352/5332]\tlr: 1.000e-05, eta: 0:33:46, time: 2.079, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0053, loss_rpn_bbox: 0.0081, s0.loss_cls: 0.0332, s0.acc: 98.6053, s0.loss_bbox: 0.0218, s1.loss_cls: 0.0237, s1.acc: 98.0621, s1.loss_bbox: 0.0424, s2.loss_cls: 0.0155, s2.acc: 97.2900, s2.loss_bbox: 0.0330, loss: 0.1830, grad_norm: 5.5022\n",
            "2020-09-09 10:41:57,260 - mmdet - INFO - Epoch [20][4416/5332]\tlr: 1.000e-05, eta: 0:31:34, time: 2.080, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0214, s0.acc: 99.0875, s0.loss_bbox: 0.0159, s1.loss_cls: 0.0134, s1.acc: 98.8770, s1.loss_bbox: 0.0259, s2.loss_cls: 0.0094, s2.acc: 98.4680, s2.loss_bbox: 0.0204, loss: 0.1148, grad_norm: 4.2199\n",
            "2020-09-09 10:44:09,851 - mmdet - INFO - Epoch [20][4480/5332]\tlr: 1.000e-05, eta: 0:29:22, time: 2.072, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0219, s0.acc: 99.1821, s0.loss_bbox: 0.0140, s1.loss_cls: 0.0153, s1.acc: 98.7793, s1.loss_bbox: 0.0271, s2.loss_cls: 0.0107, s2.acc: 98.3002, s2.loss_bbox: 0.0232, loss: 0.1220, grad_norm: 4.9344\n",
            "2020-09-09 10:46:24,267 - mmdet - INFO - Epoch [20][4544/5332]\tlr: 1.000e-05, eta: 0:27:09, time: 2.100, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0035, s0.loss_cls: 0.0211, s0.acc: 99.1974, s0.loss_bbox: 0.0136, s1.loss_cls: 0.0120, s1.acc: 99.1486, s1.loss_bbox: 0.0238, s2.loss_cls: 0.0083, s2.acc: 98.9044, s2.loss_bbox: 0.0224, loss: 0.1073, grad_norm: 4.1083\n",
            "2020-09-09 10:48:37,621 - mmdet - INFO - Epoch [20][4608/5332]\tlr: 1.000e-05, eta: 0:24:57, time: 2.084, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0041, s0.loss_cls: 0.0238, s0.acc: 98.9929, s0.loss_bbox: 0.0168, s1.loss_cls: 0.0161, s1.acc: 98.6633, s1.loss_bbox: 0.0296, s2.loss_cls: 0.0101, s2.acc: 98.2361, s2.loss_bbox: 0.0228, loss: 0.1257, grad_norm: 4.5588\n",
            "2020-09-09 10:50:48,946 - mmdet - INFO - Epoch [20][4672/5332]\tlr: 1.000e-05, eta: 0:22:45, time: 2.052, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0052, s0.loss_cls: 0.0214, s0.acc: 99.0997, s0.loss_bbox: 0.0154, s1.loss_cls: 0.0145, s1.acc: 98.8708, s1.loss_bbox: 0.0265, s2.loss_cls: 0.0104, s2.acc: 98.2574, s2.loss_bbox: 0.0241, loss: 0.1221, grad_norm: 4.5953\n",
            "2020-09-09 10:53:00,383 - mmdet - INFO - Epoch [20][4736/5332]\tlr: 1.000e-05, eta: 0:20:32, time: 2.054, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0058, s0.loss_cls: 0.0260, s0.acc: 98.9624, s0.loss_bbox: 0.0191, s1.loss_cls: 0.0181, s1.acc: 98.6115, s1.loss_bbox: 0.0302, s2.loss_cls: 0.0114, s2.acc: 98.0408, s2.loss_bbox: 0.0242, loss: 0.1399, grad_norm: 5.1393\n",
            "2020-09-09 10:55:14,192 - mmdet - INFO - Epoch [20][4800/5332]\tlr: 1.000e-05, eta: 0:18:20, time: 2.091, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0053, s0.loss_cls: 0.0217, s0.acc: 99.1272, s0.loss_bbox: 0.0174, s1.loss_cls: 0.0124, s1.acc: 99.0082, s1.loss_bbox: 0.0318, s2.loss_cls: 0.0080, s2.acc: 98.6603, s2.loss_bbox: 0.0264, loss: 0.1266, grad_norm: 4.6599\n",
            "2020-09-09 10:57:25,640 - mmdet - INFO - Epoch [20][4864/5332]\tlr: 1.000e-05, eta: 0:16:07, time: 2.054, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0037, s0.loss_cls: 0.0249, s0.acc: 99.0570, s0.loss_bbox: 0.0140, s1.loss_cls: 0.0169, s1.acc: 98.7366, s1.loss_bbox: 0.0232, s2.loss_cls: 0.0101, s2.acc: 98.4955, s2.loss_bbox: 0.0202, loss: 0.1161, grad_norm: 4.1332\n",
            "2020-09-09 10:59:37,888 - mmdet - INFO - Epoch [20][4928/5332]\tlr: 1.000e-05, eta: 0:13:55, time: 2.066, data_time: 0.006, memory: 8778, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0065, s0.loss_cls: 0.0278, s0.acc: 98.9349, s0.loss_bbox: 0.0179, s1.loss_cls: 0.0204, s1.acc: 98.3276, s1.loss_bbox: 0.0315, s2.loss_cls: 0.0118, s2.acc: 98.1079, s2.loss_bbox: 0.0246, loss: 0.1453, grad_norm: 5.1907\n",
            "2020-09-09 11:01:49,478 - mmdet - INFO - Epoch [20][4992/5332]\tlr: 1.000e-05, eta: 0:11:43, time: 2.056, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0033, s0.loss_cls: 0.0241, s0.acc: 99.0509, s0.loss_bbox: 0.0162, s1.loss_cls: 0.0154, s1.acc: 98.7518, s1.loss_bbox: 0.0296, s2.loss_cls: 0.0111, s2.acc: 98.1110, s2.loss_bbox: 0.0256, loss: 0.1298, grad_norm: 4.5486\n",
            "2020-09-09 11:04:01,512 - mmdet - INFO - Epoch [20][5056/5332]\tlr: 1.000e-05, eta: 0:09:30, time: 2.063, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0049, s0.loss_cls: 0.0272, s0.acc: 98.9471, s0.loss_bbox: 0.0164, s1.loss_cls: 0.0168, s1.acc: 98.7061, s1.loss_bbox: 0.0240, s2.loss_cls: 0.0092, s2.acc: 98.6053, s2.loss_bbox: 0.0210, loss: 0.1240, grad_norm: 4.8058\n",
            "2020-09-09 11:06:11,154 - mmdet - INFO - Epoch [20][5120/5332]\tlr: 1.000e-05, eta: 0:07:18, time: 2.026, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0032, s0.loss_cls: 0.0239, s0.acc: 99.0173, s0.loss_bbox: 0.0171, s1.loss_cls: 0.0146, s1.acc: 98.8861, s1.loss_bbox: 0.0278, s2.loss_cls: 0.0096, s2.acc: 98.3948, s2.loss_bbox: 0.0209, loss: 0.1200, grad_norm: 4.0445\n",
            "2020-09-09 11:08:22,379 - mmdet - INFO - Epoch [20][5184/5332]\tlr: 1.000e-05, eta: 0:05:06, time: 2.050, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0065, s0.loss_cls: 0.0212, s0.acc: 99.1547, s0.loss_bbox: 0.0176, s1.loss_cls: 0.0129, s1.acc: 99.0143, s1.loss_bbox: 0.0312, s2.loss_cls: 0.0086, s2.acc: 98.6694, s2.loss_bbox: 0.0305, loss: 0.1311, grad_norm: 4.4470\n",
            "2020-09-09 11:10:34,299 - mmdet - INFO - Epoch [20][5248/5332]\tlr: 1.000e-05, eta: 0:02:53, time: 2.061, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0052, loss_rpn_bbox: 0.0061, s0.loss_cls: 0.0249, s0.acc: 99.0417, s0.loss_bbox: 0.0181, s1.loss_cls: 0.0156, s1.acc: 98.7518, s1.loss_bbox: 0.0314, s2.loss_cls: 0.0099, s2.acc: 98.3887, s2.loss_bbox: 0.0275, loss: 0.1387, grad_norm: 4.9649\n",
            "2020-09-09 11:12:45,312 - mmdet - INFO - Epoch [20][5312/5332]\tlr: 1.000e-05, eta: 0:00:41, time: 2.047, data_time: 0.005, memory: 8778, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0061, s0.loss_cls: 0.0230, s0.acc: 99.0845, s0.loss_bbox: 0.0158, s1.loss_cls: 0.0137, s1.acc: 98.9197, s1.loss_bbox: 0.0317, s2.loss_cls: 0.0088, s2.acc: 98.4558, s2.loss_bbox: 0.0278, loss: 0.1307, grad_norm: 5.2515\n",
            "2020-09-09 11:13:26,950 - mmdet - INFO - Saving checkpoint at 20 epochs\n",
            "[>>] 667/667, 0.6 task/s, elapsed: 1210s, ETA:     0s2020-09-09 11:33:44,673 - mmdet - INFO - \n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 82  | 224  | 0.841  | 0.573 |\n",
            "| 3     | 22  | 93   | 0.818  | 0.711 |\n",
            "| 4     | 529 | 1132 | 0.917  | 0.826 |\n",
            "| 5     | 78  | 166  | 0.897  | 0.793 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.726 |\n",
            "+-------+-----+------+--------+-------+\n",
            "2020-09-09 11:33:44,677 - mmdet - INFO - Epoch(val) [20][5332]\tmAP: 0.7259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JThGj0yRoeR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "44b69571-b225-4ee6-a8a2-ba2f16812ab2"
      },
      "source": [
        "!python tools/test.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_20.pth --eval mAP"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "[>>] 667/667, 0.6 task/s, elapsed: 1187s, ETA:     0s\n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 86  | 286  | 0.802  | 0.637 |\n",
            "| 3     | 20  | 68   | 0.850  | 0.820 |\n",
            "| 4     | 547 | 1274 | 0.918  | 0.826 |\n",
            "| 5     | 64  | 152  | 0.984  | 0.924 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.802 |\n",
            "+-------+-----+------+--------+-------+\n",
            "{'mAP': 0.8017439842224121}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIo-JwufuZIa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "ec6a8169-0d04-4d5c-a8ae-62f35fd01397"
      },
      "source": [
        "!python tools/test.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_19.pth --eval mAP"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "[>>] 667/667, 0.6 task/s, elapsed: 1212s, ETA:     0s\n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 86  | 292  | 0.814  | 0.643 |\n",
            "| 3     | 20  | 72   | 0.850  | 0.839 |\n",
            "| 4     | 547 | 1281 | 0.921  | 0.828 |\n",
            "| 5     | 64  | 158  | 0.984  | 0.926 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.809 |\n",
            "+-------+-----+------+--------+-------+\n",
            "{'mAP': 0.8089427947998047}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h17yGls0zans",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "de930915-8e94-4b15-8212-97e900ebe391"
      },
      "source": [
        "!python tools/test.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_16.pth --eval mAP"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "[>>] 667/667, 0.6 task/s, elapsed: 1198s, ETA:     0s\n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 86  | 287  | 0.791  | 0.634 |\n",
            "| 3     | 20  | 74   | 0.850  | 0.820 |\n",
            "| 4     | 547 | 1299 | 0.923  | 0.829 |\n",
            "| 5     | 64  | 161  | 0.969  | 0.921 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.801 |\n",
            "+-------+-----+------+--------+-------+\n",
            "{'mAP': 0.801253616809845}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4Nql2604qxy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "ecb2b97c-9746-4491-99bf-0bb78e4b7e02"
      },
      "source": [
        "!python tools/test.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_13.pth --eval mAP"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "[>>] 667/667, 0.6 task/s, elapsed: 1196s, ETA:     0s\n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 86  | 289  | 0.826  | 0.642 |\n",
            "| 3     | 20  | 74   | 0.850  | 0.839 |\n",
            "| 4     | 547 | 1308 | 0.927  | 0.831 |\n",
            "| 5     | 64  | 165  | 0.969  | 0.920 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.808 |\n",
            "+-------+-----+------+--------+-------+\n",
            "{'mAP': 0.8079061508178711}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX87SpY5XFIm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "651d9c85-4e41-4110-d637-e2c131df7978"
      },
      "source": [
        "!python tools/test.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_17.pth --eval mAP"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "[>>] 667/667, 0.5 task/s, elapsed: 1225s, ETA:     0s\n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 86  | 285  | 0.802  | 0.636 |\n",
            "| 3     | 20  | 73   | 0.850  | 0.839 |\n",
            "| 4     | 547 | 1315 | 0.921  | 0.827 |\n",
            "| 5     | 64  | 162  | 0.984  | 0.926 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.807 |\n",
            "+-------+-----+------+--------+-------+\n",
            "{'mAP': 0.8067739009857178}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnkAaBixAxIE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "269905f6-a65f-491a-b656-c9c198959f7b"
      },
      "source": [
        "!python tools/test.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_14.pth --eval mAP"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "[>>] 667/667, 0.6 task/s, elapsed: 1208s, ETA:     0s\n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 86  | 292  | 0.814  | 0.638 |\n",
            "| 3     | 20  | 68   | 0.850  | 0.839 |\n",
            "| 4     | 547 | 1314 | 0.927  | 0.831 |\n",
            "| 5     | 64  | 168  | 0.969  | 0.918 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.806 |\n",
            "+-------+-----+------+--------+-------+\n",
            "{'mAP': 0.8064379096031189}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9IppT5wGUya",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "8bfe53fe-ca22-416a-fb0b-ae757f535a67"
      },
      "source": [
        "!python tools/test.py configs/cascade_rcnn_x101_32x4d_fpn_1x.py work_dirs/cascade_rcnn_x101_32x4d_fpn_1x/epoch_18.pth --eval mAP"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mmcv/utils/registry.py:64: UserWarning: The old API of register_module(module, force=False) is deprecated and will be removed, please use the new API register_module(name=None, force=False, module=None) instead.\n",
            "  'The old API of register_module(module, force=False) '\n",
            "[>>] 667/667, 0.5 task/s, elapsed: 1264s, ETA:     0s\n",
            "+-------+-----+------+--------+-------+\n",
            "| class | gts | dets | recall | ap    |\n",
            "+-------+-----+------+--------+-------+\n",
            "| 0     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 1     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 2     | 86  | 289  | 0.814  | 0.642 |\n",
            "| 3     | 20  | 70   | 0.850  | 0.821 |\n",
            "| 4     | 547 | 1272 | 0.920  | 0.825 |\n",
            "| 5     | 64  | 158  | 0.969  | 0.916 |\n",
            "| 6     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 7     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 8     | 0   | 0    | 0.000  | 0.000 |\n",
            "| 9     | 0   | 0    | 0.000  | 0.000 |\n",
            "+-------+-----+------+--------+-------+\n",
            "| mAP   |     |      |        | 0.801 |\n",
            "+-------+-----+------+--------+-------+\n",
            "{'mAP': 0.8007608652114868}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}